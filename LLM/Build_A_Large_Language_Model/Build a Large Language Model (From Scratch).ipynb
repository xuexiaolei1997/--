{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 理解大语言模型 - Large Language Model (LLM)\n",
    "\n",
    "> 主要结构如下：\n",
    "从raw data中进行预训练，得出基础模型（这一部分可以了解一下元学习的概念），这个基础模型所拥有的基础能力为文本补全、短时任务的推理能力。</br>\n",
    "> 在基础模型之上，可以导入自己标记的数据进行训练，这一部分可以成为微调（finetune），得到自己的LLM，可以用于分类，总结，翻译，个人助理等任务。\n",
    "\n",
    "![1716275709784](image/从零开始构建LLM/1716275709784.png)\n",
    "\n",
    "> **Transformer** 结构概览</br>\n",
    "1、输入需要被翻译的文本</br>\n",
    "2、预处理文本</br>\n",
    "3、编码器将输入文本进行编码</br>\n",
    "4、将编码部分送入解码器</br>\n",
    "5、模型每次只完成一个单词的翻译</br>\n",
    "6、预处理文本</br>\n",
    "7、解码器生成一个单词</br>\n",
    "8、完成翻译</br>\n",
    "\n",
    "![1716275687724](image/从零开始构建LLM/1716275687724.png)\n",
    "\n",
    "> BERT与GPT区别：BERT更多的使用于文本填空，GPT则是预测下一个单词。\n",
    "\n",
    "![1716275758151](image/从零开始构建LLM/1716275758151.png)\n",
    "\n",
    "> **构建大模型步骤**</br>\n",
    "\n",
    "|阶段|子项|\n",
    "|---|---|\n",
    "|一|准备数据和样本|\n",
    "||实现注意力机制|\n",
    "||实现LLM结构|\n",
    "|二|训练|\n",
    "||模型评估|\n",
    "||加载预训练模型权重|\n",
    "|三|微调自己的模型|\n",
    "\n",
    "![1716275818354](image/从零开始构建LLM/1716275818354.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 文本数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 词嵌入\n",
    "词嵌入的根本目的是为了**将非数值数据转换为向量**，这样才能放入计算机进行运算。常见词嵌入的有**Word2Vec**。在GPT架构中，没有使用这一技术，GPT3的嵌入大小达到了12288维。其中，GPT将词嵌入作为训练模型，不断调整。也就是说，**GPT将词嵌入这一部分也进行训练**。\n",
    "\n",
    "![1716433691383](image/从零开始构建LLM/1716433691383.png)\n",
    "\n",
    "## 2.2 标记文本\n",
    "标记文本就是将文本进行拆分，拆分为单个单词后，对每个单词进行唯一映射。可以使用字典进行标记，将每个单词映射为token id，再使用token id进行词嵌入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Total number of character: 20479\n",
      ">> raw text: I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n",
      "\n",
      ">> preprocessed: ['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n",
      ">> length: 4690\n",
      "\n",
      ">> size of vocab after removed duplicate words: 1130\n",
      ">> vocab: front 20 items\n",
      "! 0\n",
      "\" 1\n",
      "' 2\n",
      "( 3\n",
      ") 4\n",
      ", 5\n",
      "-- 6\n",
      ". 7\n",
      ": 8\n",
      "; 9\n",
      "? 10\n",
      "A 11\n",
      "Ah 12\n",
      "Among 13\n",
      "And 14\n",
      "Are 15\n",
      "Arrt 16\n",
      "As 17\n",
      "At 18\n",
      "Be 19\n",
      "Begin 20\n"
     ]
    }
   ],
   "source": [
    "filepath = os.path.join('data', 'the-verdict.txt')\n",
    "assert os.path.exists(filepath), f\"{filepath} is not exists.\"\n",
    "with open(filepath) as f:\n",
    "    raw_text = f.read()\n",
    "print(\">> Total number of character:\", len(raw_text))\n",
    "print(\">> raw text:\", raw_text[:100])\n",
    "print()\n",
    "\n",
    "# split raw text\n",
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]  # remove empty string\n",
    "print(\">> preprocessed:\", preprocessed[:30])\n",
    "print(\">> length:\", len(preprocessed))\n",
    "print()\n",
    "\n",
    "# remove duplicate words\n",
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "print(\">> size of vocab after removed duplicate words:\", vocab_size)\n",
    "\n",
    "# create vocab\n",
    "vocab = {token:integer for integer,token in enumerate(all_words)}\n",
    "print(\">> vocab: front 20 items\")\n",
    "for tok, i in vocab.items():\n",
    "    if i > 20:\n",
    "        break\n",
    "    print(tok, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1716433945337](image/从零开始构建LLM/1716433945337.png)\n",
    "\n",
    "字典表的创建方式可以通过自己创建，通过创建后的字典表，可以实现文本与token id之间的互相转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> original text:  \"It's the last he painted, you know,\" \n",
      "           Mrs. Gisburn said with pardonable pride.\n",
      ">> encoded data: [1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n",
      ">> decoded data: \" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):  # our vocab\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}  # reverse k, v\n",
    "    \n",
    "    def encode(self, text):  # our text\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()  # remove empty string\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text\n",
    "\n",
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "print(\">> original text: \", text)\n",
    "\n",
    "ids = tokenizer.encode(text)\n",
    "print(\">> encoded data:\", ids)\n",
    "\n",
    "decoded_text = tokenizer.decode(ids)\n",
    "print(\">> decoded data:\", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1716434053588](image/从零开始构建LLM/1716434053588.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 特殊处理\n",
    "正如一般的数据预处理流程，文本中的异常数据也应当注意。当上述字典表覆盖不全面时，针对不在字典表中的字符就需要特殊处理，并且不同句子之间，也需要分割符。</br>\n",
    "\n",
    "**为未知单词加入一些特殊标记**是非常有用的。作用如下：\n",
    "\n",
    "* 使用特殊标记来帮助 LLM 提供额外的上下文\n",
    "* 注：一些特殊标记如下<br/>\n",
    "    1. [BOS] Beginning of sequence. 文本开始<br/>\n",
    "    2. [EOS] end of sequence. 文本结束<br/>\n",
    "    3. [PAD] padding. 使训练文本长度统一<br/>\n",
    "    [UNK] 未知字符，不在字典表中<br/>\n",
    "* GPT-2中仅使用`<|endoftext|>`减少复杂性，`<|endoftext|>`与`[EOS]`用法类似。GPT-2同时使用`<|endoftext|>`来进行PAD操作。\n",
    "* 对于未知单词，GPT-2未使用[UNK]进行替代，而是使用字节对编码-(byte-pair encoding, BPE)将单词进行分解。\n",
    "\n",
    "因此在上述V1版本上，我们需要进行改进，将未知字符与分割符加入字典表中：\n",
    "\n",
    "`all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])`\n",
    "\n",
    "![1716455910828](image/从零开始构建LLM/1716455910828.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> size of vocab after removed duplicate words: 1161\n",
      ">> vocab: last 5 items\n",
      "('younger', 1156)\n",
      "('your', 1157)\n",
      "('yourself', 1158)\n",
      "('<|endoftext|>', 1159)\n",
      "('<|unk|>', 1160)\n"
     ]
    }
   ],
   "source": [
    "# preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)  # pre version\n",
    "preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "\n",
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(\">> size of vocab after removed duplicate words:\", vocab_size)\n",
    "\n",
    "print(\">> vocab: last 5 items\")\n",
    "for i, tok in enumerate(list(vocab.items())[-5:]):\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> input text: Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n",
      ">> encoded data: [1160, 5, 362, 1155, 642, 1000, 10, 1159, 57, 1013, 981, 1009, 738, 1013, 1160, 7]\n",
      ">> decoded data: <|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int \n",
    "            else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text\n",
    "\n",
    "\n",
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "\n",
    "print(\">> input text:\", text)\n",
    "\n",
    "ids = tokenizer.encode(text)\n",
    "print(\">> encoded data:\", ids)\n",
    "\n",
    "decoded_text = tokenizer.decode(ids)\n",
    "print(\">> decoded data:\", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 字节对编码\n",
    "\n",
    "`pip install tiktoken`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simpleNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tiktoken in d:\\python\\python39\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\python\\python39\\lib\\site-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\python\\python39\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\python\\python39\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python\\python39\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\python\\python39\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\python39\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> encoded data: [15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 617, 34680, 27271, 13]\n",
      ">> decoded data: Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\"\n",
    "\n",
    "ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(\">> encoded data:\", ids)\n",
    "\n",
    "decoded_text = tokenizer.decode(ids)\n",
    "print(\">> decoded data:\", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BPE会将未知单词拆分成独立个体的单词\n",
    "\n",
    "![1716778401378](image/从零开始构建LLM/1716778401378.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 使用滑窗进行数据采样\n",
    "\n",
    "![1716778580547](image/从零开始构建LLM/1716778580547.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> x: [290, 4920, 2241, 287]\n",
      ">> y: [4920, 2241, 287, 257]\n",
      "\n",
      ">> tokenizer encode in one context:\n",
      ">> [290] --> 4920\n",
      ">> [290, 4920] --> 2241\n",
      ">> [290, 4920, 2241] --> 287\n",
      ">> [290, 4920, 2241, 287] --> 257\n",
      "\n",
      ">> tokenizer decode in one context:\n",
      ">>  and -->  established\n",
      ">>  and established -->  himself\n",
      ">>  and established himself -->  in\n",
      ">>  and established himself in -->  a\n"
     ]
    }
   ],
   "source": [
    "enc_text = tokenizer.encode(raw_text)\n",
    "enc_sample = enc_text[50:]\n",
    "\n",
    "context_size = 4\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size + 1]\n",
    "print(f\">> x: {x}\")\n",
    "print(f\">> y: {y}\")\n",
    "print()\n",
    "\n",
    "print(\">> tokenizer encode in one context:\")\n",
    "for i in range(1, context_size + 1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(f\">> {context} --> {desired}\")\n",
    "print()\n",
    "\n",
    "print(\">> tokenizer decode in one context:\")\n",
    "for i in range(1, context_size + 1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(f\">> {tokenizer.decode(context)} --> {tokenizer.decode([desired])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，我们主要关心的只有两个向量，输入和输出\n",
    "\n",
    "![1716778596288](image/从零开始构建LLM/1716778596288.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: torch in d:\\python\\python39\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: filelock in d:\\python\\python39\\lib\\site-packages (from torch) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions in d:\\python\\python39\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in d:\\python\\python39\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\python\\python39\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\python\\python39\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in d:\\python\\python39\\lib\\site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\python\\python39\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\python\\python39\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> [tensor([[  40,  367, 2885, 1464],\n",
      "        [2885, 1464, 1807, 3619]]), tensor([[ 367, 2885, 1464, 1807],\n",
      "        [1464, 1807, 3619,  402]])]\n"
     ]
    }
   ],
   "source": [
    "# modify: batch_size, max_length, stride\n",
    "# will get different data\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=2, max_length=4, stride=2, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "data = next(data_iter)\n",
    "print(f\">> {data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 创建token嵌入\n",
    "\n",
    "这一部分将token id转换为嵌入向量\n",
    "\n",
    "![1716778710812](image/从零开始构建LLM/1716778710812.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n",
      ">> tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Simple Example\n",
    "input_ids = torch.tensor([2, 3, 5, 1])\n",
    "\n",
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "print(f\">> {embedding_layer.weight}\")\n",
    "\n",
    "print(f\">> {embedding_layer(input_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 编码位置向量\n",
    "当token id一致时，使用同一个词嵌入会得到相同输出，如下图所示：\n",
    "\n",
    "![1716778847577](image/从零开始构建LLM/1716778847577.png)\n",
    "\n",
    "为了解决这一问题，引入了位置编码，这样可以保证每一个编码是独一无二的\n",
    "\n",
    "![1716778935403](image/从零开始构建LLM/1716778935403.png)\n",
    "\n",
    "最后，所有的数据处理流程如下：\n",
    "\n",
    "![1716778990725](image/从零开始构建LLM/1716778990725.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      ">> Inputs shape: torch.Size([8, 4])\n",
      ">> torch.Size([8, 4, 256])\n",
      ">> pos embeddings's shape: torch.Size([4, 256])\n",
      ">> input embeddings's shape: torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "\n",
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=max_length, stride=max_length, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "\n",
    "inputs, targets = next(data_iter)\n",
    "print(f\">> Token IDs:\\n {inputs}\")\n",
    "print(f\">> Inputs shape: {inputs.shape}\")\n",
    "\n",
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(f\">> {token_embeddings.shape}\")\n",
    "# >> (8, 4, 256) -> 8: batch_size, 4: max_length, 256: output_dim\n",
    "\n",
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(f\">> pos embeddings's shape: {pos_embeddings.shape}\")\n",
    "\n",
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(f\">> input embeddings's shape: {input_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 编码注意力机制\n",
    "\n",
    "主要流程如下：\n",
    "1. 一个简单的自注意力\n",
    "2. LLM中使用的注意力机制\n",
    "3. 因果关系的注意力机制\n",
    "4. 多头注意力机制\n",
    "\n",
    "![1716780422961](image/从零开始构建LLM/1716780422961.png)\n",
    "\n",
    "## 3.1 长时序建模的问题\n",
    "\n",
    "主要问题是上下文丢失。如RNN不能在解码阶段直接从编码器中访问早期的隐藏状态。因此，它只依赖于当前的隐藏状态，它封装了所有相关的信息。这可能会导致上下文的丢失，特别是在依赖关系可能跨越较长距离的复杂句子中。\n",
    "\n",
    "## 3.2 使用注意机制捕获数据依赖关系\n",
    "\n",
    "早期为了解决RNN对于长时序问题，研究者提出以下结构，被成为*Bahdanau attention*，这一机制使得解码阶段能够访问编码早期状态。\n",
    "\n",
    "![1718697183686](image/从零开始构建LLM/1718697183686.png)\n",
    "\n",
    "之后根据*Bahdanau attention*得到启发，提出了早期的*Transformer*结构。\n",
    "\n",
    "![1716877433399](image/从零开始构建LLM/1716877433399.png)\n",
    "\n",
    "## 3.3 自注意输入的不同部分\n",
    "\n",
    "自注意力是LLM中Transformer的基石。\n",
    "在自注意力中，“自我”是指该机制通过关联单个输入序列中的不同位置来计算注意权重的能力。它关注的是本身不同部分的关系和依赖。而传统的注意力机制则是关注两个序列之间的关系\n",
    "\n",
    "### 3.3.1 一个简单的自我注意机制，没有训练权重\n",
    "\n",
    "自注意的目标是为每个输入元素计算一个上下文向量，它结合了来自所有其他输入元素的信息。在自注意力中，我们的目标是为每一个输入元素${x^{(i)}}$计算上下文向量${z^{(i)}}$。一个上下文向量可以被解释为一个丰富的嵌入向量。</br>\n",
    "如下图所示，*Your journey starts with one step*为输入句子，现在关注${x^{(2)}}$与${z^{(2)}}$，${z^{(2)}}$包含了从${x^{(1)}}$到${x^{(T)}}$之间的所有信息。\n",
    "在自注意过程中，上下文向量起着至关重要的作用。它们的目的是通过在序列中合并来自所有其他元素的信息，在输入序列中（如句子）中创建每个元素的丰富表示，如下图所示。\n",
    "\n",
    "![1716879045635](image/从零开始构建LLM/1716879045635.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1716881565809](image/从零开始构建LLM/1716881565809.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "\n",
    "query = inputs[1]  # 2nd input token is the query\n",
    "\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query) # dot product (transpose not necessary here since they are 1-dim vectors)\n",
    "\n",
    "print(f\">> {attn_scores_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 上述操作可以理解为矩阵的乘法 dot product，其中值越大，表示相关性越高\n",
    "\n",
    "紧接着需要对其进行归一化操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> attn_scores for x^2: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      ">> attn_scores's sum for x^2: 1.0000001192092896\n"
     ]
    }
   ],
   "source": [
    "attn_scores_2 = attn_scores_2 / attn_scores_2.sum()\n",
    "print(f\">> attn_scores for x^2: {attn_scores_2}\")\n",
    "print(f\">> attn_scores's sum for x^2: {attn_scores_2.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 在实际中，更多的是使用softmax操作，这一操作在处理极值和梯度时有更好的表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> attn_weights_naive for x^2: tensor([0.1630, 0.1770, 0.1765, 0.1603, 0.1570, 0.1663])\n",
      ">> attn_weights_naive's sum for x^2: 1.0\n",
      "\n",
      ">> attn_weights for x^2: tensor([0.1630, 0.1770, 0.1765, 0.1603, 0.1570, 0.1663])\n",
      ">> attn_weights's sum for x^2: 1.0\n"
     ]
    }
   ],
   "source": [
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "\n",
    "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
    "print(f\">> attn_weights_naive for x^2: {attn_weights_2_naive}\")\n",
    "print(f\">> attn_weights_naive's sum for x^2: {attn_weights_2_naive.sum()}\")\n",
    "print()\n",
    "\n",
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "print(f\">> attn_weights for x^2: {attn_weights_2}\")\n",
    "print(f\">> attn_weights's sum for x^2: {attn_weights_2.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> context_vec: tensor([0.4325, 0.5937, 0.5349])\n"
     ]
    }
   ],
   "source": [
    "# Above All\n",
    "query = inputs[1]\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i] * x_i\n",
    "print(f\">> context_vec: {context_vec_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 为所有输入计算权重\n",
    "\n",
    "![1716945187106](image/从零开始构建LLM/1716945187106.png)\n",
    "\n",
    "计算流程与之前一致\n",
    "\n",
    "![1716945198064](image/从零开始构建LLM/1716945198064.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> attn scores: tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n",
      ">> attn scores: tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n",
      ">> attn weights (softmax): tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "# >> attention scores\n",
    "# method 1\n",
    "attn_scores = torch.empty(6, 6)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    for j, x_j in enumerate(inputs):\n",
    "        attn_scores[i, j] = torch.dot(x_i, x_j)\n",
    "print(f\">> attn scores: {attn_scores}\")\n",
    "\n",
    "# method 2\n",
    "attn_scores = torch.matmul(inputs, inputs.T)\n",
    "print(f\">> attn scores: {attn_scores}\")\n",
    "\n",
    "# >> attention weights (softmax)\n",
    "attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "print(f\">> attn weights (softmax): {attn_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 使用训练权重实现自注意力\n",
    "\n",
    "### 3.4.1 一步一步计算注意力权重\n",
    "\n",
    "这里引入了三个权重${W_q}$, ${W_k}$, ${W_v}$，这三个权重矩阵用于将输入token ${x^i}$ 映射为查询，键， 值向量。\n",
    "\n",
    "![1716947702233](image/从零开始构建LLM/1716947702233.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4676)\n"
     ]
    }
   ],
   "source": [
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2\n",
    "\n",
    "# requires_grad=False to reduce clutter in the outputs for illustration purposes\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "\n",
    "query_2 = torch.matmul(x_2, W_query)\n",
    "key_2 = torch.matmul(x_2, W_key)\n",
    "value_2 = torch.matmul(x_2, W_value)\n",
    "\n",
    "attn_scores_22 = torch.dot(query_2, key_2)\n",
    "print(attn_scores_22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 权重与注意力权重的区别：</br>\n",
    "权重 ${W}$ 是指神经网络中的权重，在训练过程中被优化的部分。<br/>\n",
    "注意权重决定了上下文向量依赖于输入的不同部分的程度。<br/>\n",
    "<br/>\n",
    "总的来说，权重参数是定义神经网络的基础的、可学习的参数，而注意里权重是上下文特定的、动态的值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> keys shape: torch.Size([6, 2])\n",
      ">> values shape: torch.Size([6, 2])\n",
      ">> attn weights for x_2: tensor([0.1545, 0.2136, 0.2123, 0.1320, 0.1419, 0.1457])\n",
      ">> context vector for x_2: tensor([0.3341, 1.0655])\n"
     ]
    }
   ],
   "source": [
    "keys = torch.matmul(inputs, W_key)\n",
    "values = torch.matmul(inputs, W_value)\n",
    "\n",
    "print(f\">> keys shape: {keys.shape}\")\n",
    "print(f\">> values shape: {values.shape}\")\n",
    "\n",
    "attn_scores_2 = torch.matmul(query_2, keys.T)\n",
    "\n",
    "d_k = keys.shape[-1]\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k ** 0.5, dim=-1)\n",
    "print(f\">> attn weights for x_2: {attn_weights_2}\")\n",
    "\n",
    "context_vec_2 = torch.matmul(attn_weights_2, values)\n",
    "print(f\">> context vector for x_2: {context_vec_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 实现一个紧凑的自注意类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "  \n",
    "    def forward(self, x):\n",
    "        keys = torch.matmul(x, self.W_key)\n",
    "        values = torch.matmul(x, self.W_value)\n",
    "        queries = torch.matmul(x, self.W_query)\n",
    "\n",
    "        attn_scores = torch.matmul(queries, keys.T)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        context_vec = torch.matmul(attn_weights, values)\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1717397936262](image/从零开始构建LLM/1717397936262.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> context: tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "print(f\">> context: {sa_v1(inputs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 `nn.Linear` ，除了可以有效计算矩阵外，它还优化了权值初始化方案，有助于模型训练更加稳定和有效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = torch.matmul(queries, keys.T)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        context_vec = torch.matmul(attn_weights, values)\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> context: tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(f\">> context: {sa_v2(inputs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 用因果关系的注意力来隐藏未来的词语\n",
    "\n",
    "![1717401849186](image/从零开始构建LLM/1717401849186.png)\n",
    "\n",
    "### 3.5.1 应用因果注意力掩码\n",
    "\n",
    "![1717401901352](image/从零开始构建LLM/1717401901352.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> attn weights: tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
      "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
      "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      ">> mask:  tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n",
      ">> masked:  tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<MulBackward0>)\n",
      ">> masked norm:  tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa_v2.W_query(inputs)\n",
    "keys = sa_v2.W_key(inputs)\n",
    "\n",
    "attn_scores = torch.matmul(queries, keys.T)\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "print(\">> attn weights:\", attn_weights)\n",
    "\n",
    "context_length = attn_scores.shape[0]\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "print(\">> mask: \", mask_simple)\n",
    "\n",
    "masked_simple = attn_weights * mask_simple\n",
    "print(\">> masked: \", masked_simple)\n",
    "\n",
    "row_sums = torch.sum(masked_simple, dim=-1, keepdim=True)\n",
    "masked_simple_norm = masked_simple / row_sums\n",
    "print(\">> masked norm: \", masked_simple_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **信息泄露**</br>\n",
    "当应用掩码时，由于计算的权重已经进行了softmax，因此会有影响。然而，当我们在mask之后重新调整注意力权重时，本质是在一个更小的子集上重新计算softmax，因此mask位置对于softmax没有贡献。</br>\n",
    "\n",
    "因此可以将流程简化为：\n",
    "\n",
    "![1717402483387](image/从零开始构建LLM/1717402483387.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> mask:  tensor([[0., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      ">> masked:  tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      ">> attn weights:  tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "print(\">> mask: \", mask)\n",
    "\n",
    "masked = torch.masked_fill(attn_scores, mask.bool(), -torch.inf)\n",
    "print(\">> masked: \", masked)\n",
    "\n",
    "attn_weights = torch.softmax(masked / keys.shape[-1] ** 0.5, dim=1)\n",
    "print(\">> attn weights: \", attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 用dropout来掩盖额外的注意权重\n",
    "\n",
    "在transformer架构中，dropout通常用在两个地方：计算注意力分数之后或者应用注意力权重之前\n",
    "\n",
    "![1717558177482](image/从零开始构建LLM/1717558177482.png)\n",
    "\n",
    "需要注意的是，dropout时，会将原数值进行放大，这样能够保证注意力权重的平衡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> dropout rate (0.5):  tensor([[2., 2., 2., 2., 2., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 2., 0.],\n",
      "        [2., 2., 0., 0., 0., 2.],\n",
      "        [2., 0., 0., 0., 0., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.]])\n",
      ">> dropout attn weights:  tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6206, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4921, 0.0000, 0.4638, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3966, 0.3968, 0.3775, 0.3941, 0.0000],\n",
      "        [0.3869, 0.3327, 0.0000, 0.0000, 0.3331, 0.3058]],\n",
      "       grad_fn=<MulBackward0>)\n",
      ">> dropout rate (0.1):  tensor([[1.1111, 1.1111, 1.1111, 1.1111, 1.1111, 1.1111],\n",
      "        [1.1111, 1.1111, 1.1111, 1.1111, 1.1111, 0.0000],\n",
      "        [0.0000, 1.1111, 1.1111, 1.1111, 1.1111, 1.1111],\n",
      "        [1.1111, 1.1111, 1.1111, 0.0000, 1.1111, 1.1111],\n",
      "        [1.1111, 1.1111, 0.0000, 1.1111, 1.1111, 1.1111],\n",
      "        [1.1111, 1.1111, 1.1111, 1.1111, 1.1111, 1.1111]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5)\n",
    "example = torch.ones(6, 6)\n",
    "print(\">> dropout rate (0.5): \", dropout(example))\n",
    "\n",
    "print(\">> dropout attn weights: \", dropout(attn_weights))\n",
    "\n",
    "dropout = torch.nn.Dropout(0.1)\n",
    "example = torch.ones(6, 6)\n",
    "print(\">> dropout rate (0.1): \", dropout(example))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 实现一个紧凑的因果注意力类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = torch.matmul(queries, keys.transpose(1, 2))\n",
    "        attn_scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_vec = torch.matmul(attn_weights, values)\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> batch shape:  torch.Size([2, 6, 3])\n",
      ">> context_vecs:  tensor([[[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]],\n",
      "\n",
      "        [[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>)\n",
      ">> context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(\">> batch shape: \", batch.shape) # 2 inputs with 6 tokens each, and each token has embedding dimension 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "context_length = batch.shape[1]\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "\n",
    "context_vecs = ca(batch)\n",
    "\n",
    "print(\">> context_vecs: \", context_vecs)\n",
    "print(\">> context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 将单个注意力扩展到多头注意力\n",
    "\n",
    "### 3.6.1 将多头注意力扩展到多头注意力\n",
    "\n",
    "![1717567513041](image/从零开始构建LLM/1717567513041.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias) \n",
    "             for _ in range(num_heads)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> context_vecs: tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
      ">> context_vecs.shape: torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "context_length = batch.shape[1] # This is the number of tokens\n",
    "d_in, d_out = 3, 2\n",
    "mha = MultiHeadAttentionWrapper(\n",
    "    d_in, d_out, context_length, 0.0, num_heads=2\n",
    ")\n",
    "\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(\">> context_vecs:\", context_vecs)\n",
    "print(\">> context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2 通过权重分割实现多头注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False) -> None:\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = torch.matmul(queries, keys.transpose(2, 3))\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        context_vec = torch.matmul(attn_weights, values).transpose(1, 2)\n",
    "\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1718186662363](image/从零开始构建LLM/1718186662363.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> context_vecs: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]],\n",
      "\n",
      "        [[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n",
      ">> context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(\">> context_vecs:\", context_vecs)\n",
    "print(\">> context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 实现GPT并生成文本\n",
    "\n",
    "## 4.1 实现一个LLM结构\n",
    "\n",
    "LLM总体框架图如下：\n",
    "1. 词嵌入\n",
    "2. 多头注意力\n",
    "3. 输出层\n",
    "\n",
    "![1718247386638](image/从零开始构建LLM/1718247386638.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 parameter\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 根据下图，一步一步编写GPT模型\n",
    "\n",
    "![1718258629553](image/从零开始构建LLM/1718258629553.png)\n",
    "\n",
    "编写代码如下所示，但是并没有编写归一化与具体的Transformer块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(*[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "  \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "  \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5) -> None:\n",
    "        super().__init__()\n",
    "  \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> GPT数据流\n",
    "\n",
    "![1718262314570](image/从零开始构建LLM/1718262314570.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> batch:  tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      ">> out shape:  torch.Size([2, 4, 50257])\n",
      ">> out:  tensor([[[-1.1947,  0.1392, -0.8616,  ..., -1.4987, -0.0314, -0.4490],\n",
      "         [ 0.0497,  0.3861, -0.3281,  ..., -0.1826,  1.3084,  0.9867],\n",
      "         [ 0.7005,  1.4747, -0.4149,  ...,  1.7756, -0.2280,  0.5384],\n",
      "         [ 0.4885,  1.7545, -0.6707,  ...,  1.1501, -0.1143, -0.9368]],\n",
      "\n",
      "        [[-1.1947,  0.1392, -0.8616,  ..., -1.4987, -0.0314, -0.4490],\n",
      "         [-0.5591,  0.5797, -0.1296,  ...,  0.2691,  0.3151,  1.4046],\n",
      "         [ 0.8524,  1.2833, -0.1786,  ..., -0.1982,  0.1097,  0.2812],\n",
      "         [-0.0190, -0.8277,  0.2299,  ...,  1.7974, -0.1646, -0.1049]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(\">> batch: \", batch)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\">> out shape: \", logits.shape)\n",
    "print(\">> out: \", logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 使用layer normalization进行归一化激活\n",
    "\n",
    "> 由于梯度消失或爆炸等问题，训练多层深度神经网络有时会具有挑战性。这些问题导致了不稳定的训练动态，使网络难以有效地调整其权值，这意味着学习过程很难为神经网络找到一组参数（权值），以最小化损失函数。换句话说，该网络很难学习数据中的潜在模式，其程度将使其能够做出准确的预测或决策。</br>\n",
    "\n",
    "> 层归一化背后的主要思想是调整神经网络层的激活（输出），使其均值为0，方差为1，也称为单位方差。这种调整加速了收敛到有效的权重，并确保了一致、可靠的训练。</br>\n",
    "\n",
    "> **层归一化通常在多头注意模块前后和最终输出层之前应用。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_printoptions(sci_mode=True)  # set float number\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "  \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 使用层归一化实现前向神经网络\n",
    "\n",
    "**GeLU**激活函数\n",
    "\n",
    "在神经网络中，使用最广泛的是ReLU函数，但是在LLM，除了ReLU外，还有两种显著的激活函数：GELU (Gaussian Error Linear Unit) 和 SwiGLU (Sigmoid-Weighted Linear Unit)。GELU和SwiGLU分别是更复杂和光滑的包含高斯单元和s型门控线性单位的激活函数。他们可以表现的更好。\n",
    "\n",
    "$$\n",
    "\\text{GELU}(x) \\approx 0.5 \\cdot x \\cdot \\left(1 + \\tanh\\left[\\sqrt{\\frac{2}{\\pi}} \\cdot \\left(x + 0.044715 \\cdot x^3\\right)\\right]\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * ( 1 + torch.tanh(torch.sqrt(torch.tensor(2 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GELU Test\n",
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], ['GELU', \"ReLU\"])):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 在此基础上实现一个前馈网络，这个前馈网络至关重要，主要解决非线性问题，并且可以探索更丰富的空间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> ffn out size:  torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = ffn(x)\n",
    "print(\">> ffn out size: \", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 增加短连接\n",
    "\n",
    "short connection通过跳过一个或多个层来创建一个梯度通过网络的更短路径，这是通过将一个层的输出添加到后面一个层的输出来实现的。这就是为什么这些连接也被称为跳过连接。在训练过程中，它们在保持梯度的流动方面起着至关重要的作用。\n",
    "\n",
    "![1718273582034](image/从零开始构建LLM/1718273582034.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut) -> None:\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU()),\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(x)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "model_without_shorcut = ExampleDeepNeuralNetwork(layer_sizes, False)\n",
    "\n",
    "def print_gradients(model, x):\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\">> {name} has gradient mean of {param.grad.abs()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> layers.0.0.weight has gradient mean of tensor([[0.0018, 0.0000, 0.0018],\n",
      "        [0.0010, 0.0000, 0.0010],\n",
      "        [0.0065, 0.0000, 0.0065]])\n",
      ">> layers.1.0.weight has gradient mean of tensor([[6.3482e-07, 3.8762e-07, 7.6243e-06],\n",
      "        [1.5987e-04, 9.7618e-05, 1.9201e-03],\n",
      "        [8.4790e-05, 5.1773e-05, 1.0183e-03]])\n",
      ">> layers.2.0.weight has gradient mean of tensor([[0.0039, 0.0031, 0.0015],\n",
      "        [0.0041, 0.0033, 0.0015],\n",
      "        [0.0050, 0.0040, 0.0019]])\n",
      ">> layers.3.0.weight has gradient mean of tensor([[0.0491, 0.0031, 0.0283],\n",
      "        [0.0257, 0.0016, 0.0148],\n",
      "        [0.0465, 0.0029, 0.0268]])\n",
      ">> layers.4.0.weight has gradient mean of tensor([[0.0417, 0.0856, 0.0110]])\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shorcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> layers.0.0.weight has gradient mean of tensor([[3.2044e-06, 0.0000e+00, 3.2044e-06],\n",
      "        [1.8830e-03, 0.0000e+00, 1.8830e-03],\n",
      "        [3.0898e-03, 0.0000e+00, 3.0898e-03]])\n",
      ">> layers.1.0.weight has gradient mean of tensor([[1.5119e-04, 1.8919e-05, 1.4878e-04],\n",
      "        [8.6263e-04, 1.0795e-04, 8.4891e-04],\n",
      "        [2.0144e-04, 2.5207e-05, 1.9824e-04]])\n",
      ">> layers.2.0.weight has gradient mean of tensor([[2.1789e-04, 6.5373e-06, 2.5559e-04],\n",
      "        [1.2170e-03, 3.6514e-05, 1.4276e-03],\n",
      "        [4.6673e-05, 1.4003e-06, 5.4749e-05]])\n",
      ">> layers.3.0.weight has gradient mean of tensor([[1.8056e-04, 2.5326e-05, 2.2459e-04],\n",
      "        [3.3904e-03, 4.7555e-04, 4.2170e-03],\n",
      "        [1.9221e-03, 2.6960e-04, 2.3907e-03]])\n",
      ">> layers.4.0.weight has gradient mean of tensor([[0.0184, 0.0108, 0.0193]])\n"
     ]
    }
   ],
   "source": [
    "model_without_shorcut = ExampleDeepNeuralNetwork(layer_sizes, True)\n",
    "print_gradients(model_without_shorcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 连接注意力层和线性层\n",
    "\n",
    "**transformer block的说明**\n",
    "\n",
    "![1718347509428](image/从零开始构建LLM/1718347509428.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg) -> None:\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(d_in=cfg[\"emb_dim\"], \n",
    "                                      d_out=cfg[\"emb_dim\"],\n",
    "                                      context_length=cfg[\"context_length\"], \n",
    "                                      num_heads=cfg[\"n_heads\"],\n",
    "                                      dropout=cfg[\"drop_rate\"],\n",
    "                                      qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_resid = nn.Dropout(cfg[\"drop_rate\"])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_resid(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_resid(x)\n",
    "        x = x + shortcut\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 编码GPT模型\n",
    "\n",
    "![1718352064601](image/从零开始构建LLM/1718352064601.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> input batch:  tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      ">> output shape:  torch.Size([2, 4, 50257])\n",
      ">> out:  tensor([[[ 0.2159,  1.7803, -1.3144,  ...,  0.1518,  0.3433, -0.2426],\n",
      "         [-0.4640,  0.0124, -0.0818,  ...,  0.1752,  0.8148,  0.2054],\n",
      "         [-0.3823,  0.1988,  0.2054,  ...,  0.0659, -0.1415,  0.1057],\n",
      "         [-0.1542,  0.7591, -0.2797,  ..., -0.2908,  0.6896, -0.1746]],\n",
      "\n",
      "        [[-0.2024,  1.6316, -0.9047,  ...,  0.1310,  0.5152, -0.3395],\n",
      "         [-0.0648,  0.8608, -0.4911,  ...,  0.5268, -0.0134,  0.3010],\n",
      "         [-0.1856, -0.6939,  0.0868,  ...,  0.5741, -0.0706,  0.2637],\n",
      "         [-0.0827, -0.1011,  0.4543,  ...,  0.1231, -0.1420,  0.0325]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\">> input batch: \", batch)\n",
    "print(\">> output shape: \", out.shape)\n",
    "print(\">> out: \", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> total number of parameters: 163009536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\">> total number of parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 之前提到代码参数工1.24亿，但是为何这里输出为1.63亿呢？<br/>\n",
    "其原因是在原始的GPT-2体系结构中使用了一个称为**权重绑定**的概念，这意味着原始的GPT-2体系结构在其输出层中重用了来自标记嵌入层的权重。为了理解这意味着什么，来看看我们之前通过GPTModel在模型上初始化的令牌嵌入层和线性输出层的形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Token embedding layer shape: torch.Size([50257, 768])\n",
      ">> Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(f\">> Token embedding layer shape: {model.tok_emb.weight.shape}\")\n",
    "print(f\">> Output layer shape: {model.out_head.weight.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 由于字典表的大小为50257，这导致嵌入层非常大。且输出层重用了嵌入层的权重，因此应减去这一部分的参数。\n",
    "\n",
    "> 在一般情况下，不是用权重绑定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Number of trainable parameters considering weight tying: 124412160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\">> Number of trainable parameters considering weight tying: {total_params_gpt2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 生成文本\n",
    "\n",
    "![1718358855510](image/从零开始构建LLM/1718358855510.png)\n",
    "\n",
    "![1718358887750](image/从零开始构建LLM/1718358887750.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=-1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> encoded: [15496, 11, 314, 716]\n",
      ">> encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\">> encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\">> encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Output: tensor([[15496,    11,   314,   716, 17480, 23268,  2497, 19749,  1333, 15262]])\n",
      ">> Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor,\n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\">> Output:\", out)\n",
    "print(\">> Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Generated text:  Hello, I amINGTON vow saw bourgeois triBay\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(\">> Generated text: \", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 在未标记的数据上进行训练\n",
    "\n",
    "## 5.1 评估生成文本模型\n",
    "\n",
    "![1718851702204](image/从零开始构建LLM/1718851702204.png)\n",
    "\n",
    "5.1.1 使用GPT模型生成文本\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256, #A\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1, #B\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与之前的进行对比，context_length减少到256（之前为1024），这一改变减少了计算需求，使得能够在桌面版计算机上运行。\n",
    "在之后的训练中，将其更新回1024，以便于加载预训练模型。\n",
    "\n",
    "---\n",
    "\n",
    "三步生成文本的过程：\n",
    "1. tokenizer将输入文本转换为一系列token IDs\n",
    "2. 模型将token IDs转换为对应的logits，logits表示每个token在字典中可能的分布状况\n",
    "3. 将logits转换为token IDs，tokenizer再进行解码，生成文本\n",
    "\n",
    "![1718853446792](image/从零开始构建LLM/1718853446792.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> encoded: tensor([[6109, 3626, 6100,  345]])\n",
      ">> decoded_text: Every effort moves you Ya Primary Haleifacts rallying racing acronym employedliners quasi\n"
     ]
    }
   ],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    decoded = tokenizer.decode(token_ids.squeeze(0).tolist())\n",
    "    return decoded\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "encoded = text_to_token_ids(start_context, tokenizer)\n",
    "print(\">> encoded:\", encoded)\n",
    "\n",
    "token_ids = generate_text_simple(model=model, idx=encoded, max_new_tokens=10, context_size=GPT_CONFIG_124M['context_length'])\n",
    "\n",
    "decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "print(\">> decoded_text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 计算文本生成的损失\n",
    "\n",
    "![1718854323771](image/从零开始构建LLM/1718854323771.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> probas:  tensor([[[2.8377e-05, 7.2349e-06, 1.2548e-05,  ..., 5.9388e-05,\n",
      "          1.3404e-05, 1.2288e-05],\n",
      "         [1.3495e-05, 1.4862e-05, 2.8429e-05,  ..., 1.8806e-05,\n",
      "          1.5693e-05, 4.4732e-05],\n",
      "         [1.2664e-05, 1.3142e-05, 1.0387e-05,  ..., 4.5830e-05,\n",
      "          2.7469e-05, 6.0023e-06]],\n",
      "\n",
      "        [[1.3310e-05, 1.8276e-05, 2.6471e-05,  ..., 4.4993e-05,\n",
      "          1.4153e-05, 2.1337e-05],\n",
      "         [3.9846e-05, 1.4927e-05, 2.0788e-05,  ..., 1.3040e-05,\n",
      "          1.7489e-05, 4.1804e-05],\n",
      "         [1.8740e-05, 1.7283e-05, 1.5547e-05,  ..., 3.6920e-05,\n",
      "          2.2174e-05, 8.8161e-06]]])\n",
      ">> token_ids:  tensor([[[26729],\n",
      "         [ 6858],\n",
      "         [40186]],\n",
      "\n",
      "        [[11205],\n",
      "         [25483],\n",
      "         [38800]]])\n",
      ">> target batch:   effort moves you\n",
      ">> predicted batch:   Theme Andrew sluggish\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(\">> probas: \", probas)\n",
    "\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\">> token_ids: \", token_ids)\n",
    "\n",
    "print(\">> target batch: \", token_ids_to_text(targets[0], tokenizer))\n",
    "print(\">> predicted batch: \", token_ids_to_text(token_ids[0].flatten(), tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于还未被训练，因此产生的为随机文本。\n",
    "训练过程是不断减小目标与预测值之间的“距离”。\n",
    "\n",
    "![1718868480909](image/从零开始构建LLM/1718868480909.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Text 1: tensor([1.2227e-05, 1.6803e-05, 1.2385e-05])\n",
      ">> Text 2: tensor([1.2182e-05, 1.3089e-05, 4.1397e-06])\n",
      ">> log probas:  tensor([-11.3119, -10.9940, -11.2990, -11.3156, -11.2437, -12.3949])\n",
      ">> avg log probas:  tensor(-11.4265)\n",
      ">> neg avg log probas:  tensor(11.4265)\n"
     ]
    }
   ],
   "source": [
    "# 2-3\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\">> Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\">> Text 2:\", target_probas_2)\n",
    "\n",
    "# 4\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(\">> log probas: \", log_probas)\n",
    "\n",
    "# 5\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(\">> avg log probas: \", avg_log_probas)\n",
    "\n",
    "# 6\n",
    "neg_avg_log_probas = -avg_log_probas\n",
    "print(\">> neg avg log probas: \", neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交叉熵 Cross Entropy Loss， 是用来衡量两个概率分布之间的差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Logits shape: torch.Size([2, 3, 50257])\n",
      ">> Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\">> Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\">> Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在进行交叉熵之前，需要检查向量维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Flattened logits: torch.Size([6, 50257])\n",
      ">> Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\">> Flattened logits:\", logits_flat.shape)\n",
    "print(\">> Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loss:  tensor(11.4265)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(\">> Loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 困惑度</br>\n",
    "\n",
    "困惑度也是评价语言模型好坏的指标。它可以提供一种更可解释的方法来理解模型在预测序列中的下一个标记时的不确定性。</br>\n",
    "困惑度衡量了模型预测的概率分布与数据集中单词的实际分布的匹配程度。与损失相似，较低的困惑度表明模型的预测更接近实际分布。</br>\n",
    "困惑度的可解释性在于它表示模型在每一步中都不确定的有效词汇表大小。</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(91720.6797)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 计算训练和验证损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Characters: 20479\n",
      ">> Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "text_data = raw_text\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\">> Characters:\", total_characters)\n",
    "print(\">> Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1718868663879](image/从零开始构建LLM/1718868663879.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(len(text_data) * train_ratio)\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloader_v1(train_data, \n",
    "                                    batch_size=2, \n",
    "                                    max_length=GPT_CONFIG_124M['context_length'], \n",
    "                                    stride=GPT_CONFIG_124M['context_length'], \n",
    "                                    drop_last=True, \n",
    "                                    shuffle=True)\n",
    "val_loader = create_dataloader_v1(val_data, \n",
    "                                  batch_size=2, \n",
    "                                  max_length=GPT_CONFIG_124M['context_length'], \n",
    "                                  stride=GPT_CONFIG_124M['context_length'], \n",
    "                                  drop_last=False, \n",
    "                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(len(data_loader), num_batches)\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Train loss: 10.994715372721354\n",
      ">> Val loss: 11.020210266113281\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "train_loss = calc_loss_loader(train_loader, model, device)\n",
    "print(f\">> Train loss: {train_loss}\")\n",
    "\n",
    "val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(f\">> Val loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 训练一个LLM\n",
    "\n",
    "![1718875144870](image/从零开始构建LLM/1718875144870.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluete_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    excoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model, excoded, 50 , context_size)\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(f\">> {start_context} --> {decoded_text}\")\n",
    "    model.train()\n",
    "\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_token_seen = [], [], []\n",
    "    token_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            token_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluete_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_token_seen.append(token_seen)\n",
    "                print(f\">> Epoch {epoch + 1}, step {global_step: 06d}: train loss {train_loss:.4f}, val loss {val_loss:.4f}\")\n",
    "    \n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_token_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 1, step  00000: train loss 9.9413, val loss 10.0458\n",
      ">> Epoch 1, step  00005: train loss 8.1316, val loss 8.3626\n",
      ">> Every effort moves you --> Every effort moves you,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 1  # Change Here\n",
    "train_losses, val_losses, track_token_seen = train_model_simple(model, train_loader, val_loader, optimizer, device,\n",
    "                                                               num_epochs, 5, 5, \"Every effort moves you\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "# load model\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAHpCAYAAACful8UAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAACgIUlEQVR4nOzdeXhU5d3/8fdkDwlJCJA9EyBAIGxhywguiKCIgoioLKNFrfaxLq11aaXP41a31l2fWmt/7aOtJoBoFTdEQFlcGNaAbGHPZIUAIQvZM+f3x9GJqaIIDCfL53Vdc8l858zhO1zHJJ/c97lvm2EYBiIiIiIiIiJy2vlZ3YCIiIiIiIhIe6XQLSIiIiIiIuIjCt0iIiIiIiIiPqLQLSIiIiIiIuIjCt0iIiIiIiIiPqLQLSIiIiIiIuIjCt0iIiIiIiIiPqLQLSIiIiIiIuIjCt0iIiIiIiIiPqLQLSIi0o7s378fm81GTk6O1a2IiIgICt0iIiKtjs1m+8HHgw8+aHWLP0lpaSm//OUvsdvtBAcHExcXx4QJE/j888+tbk1ERMTnAqxuQERERFoqLi72/nn+/Pncf//95Obmemvh4eFWtHXSpk2bRn19Pf/85z/p1asXBw4cYNmyZRw+fNjq1kRERHxOI90iIiKtTFxcnPcRGRmJzWbzPo+JieGZZ54hKSmJ4OBgMjIy+Oijj457rqamJm644Qb69euH2+0GYOHChQwbNoyQkBB69erFQw89RGNjo/c9NpuNv//970ydOpVOnTrRp08f3n33Xe/rZWVlOJ1OunfvTmhoKH369OGVV1753r//6NGjrFq1ij/96U+MHTuWlJQUMjMzmTNnDpdddlmL42688Ua6d+9OREQEF1xwAZs2bWpxrlPtW0RExAoK3SIiIm3I888/z9NPP81TTz3F5s2bmTBhApdddhm7du36zrF1dXVcddVV5OTksGrVKux2O6tWreJnP/sZv/71r9m2bRsvv/wyr776Ko8++miL9z700ENcffXVbN68mUsuuQSn08mRI0cAuO+++9i2bRuLFi1i+/btvPTSS3Tr1u17+w0PDyc8PJx33nmHurq6436uq666ioMHD7Jo0SLWr1/PsGHDGDdunPfvPB19i4iIWMIQERGRVuuVV14xIiMjvc8TEhKMRx99tMUxI0eONG655RbDMAxj3759BmCsWrXKGDdunHHOOecYR48e9R47btw447HHHmvx/tdee82Ij4/3PgeM//mf//E+r6qqMgBj0aJFhmEYxuTJk43rr7/+hD/Dm2++aXTp0sUICQkxRo8ebcyZM8fYtGmT9/VVq1YZERERRm1tbYv3paamGi+//PJp61tERMQKGukWERFpIyoqKigqKuLss89uUT/77LPZvn17i9rMmTM5duwYH3/8MZGRkd76pk2b+MMf/uAdgQ4PD+emm26iuLiY6upq73GDBw/2/jksLIyIiAgOHjwIwC9/+UvmzZtHRkYGv/3tb/niiy9+sO9p06ZRVFTEu+++y8UXX8zy5csZNmwYr776qrenqqoqunbt2qKvffv2sWfPntPWt4iIiBW0kJqIiEg7dMkll/D666/z5ZdfcsEFF3jrVVVVPPTQQ1xxxRXfeU9ISIj3z4GBgS1es9lseDweACZOnEheXh4ffvghS5YsYdy4cdx666089dRTx+0nJCSECy+8kAsvvJD77ruPG2+8kQceeIDrrruOqqoq4uPjWb58+XfeFxUVddr6FhERsYJCt4iISBsRERFBQkICn3/+OWPGjPHWP//8czIzM1sc+8tf/pKBAwdy2WWX8cEHH3iPHzZsGLm5ufTu3fuUeunevTuzZ89m9uzZnHvuudxzzz0/GLr/U3p6Ou+88463p5KSEgICAujRo8f3Hn+6+hYRETnTFLpFRETakHvuuYcHHniA1NRUMjIyeOWVV8jJySErK+s7x95+++00NTUxadIkFi1axDnnnMP999/PpEmTsNvtXHnllfj5+bFp0ya2bNnCI488ckI93H///QwfPpwBAwZQV1fH+++/T//+/b/32MOHD3PVVVdxww03MHjwYDp37sy6det44oknmDJlCgDjx49n1KhRXH755TzxxBP07duXoqIiPvjgA6ZOncqIESNOS98iIiJWUOgWERFpQ371q19RXl7OXXfdxcGDB0lPT+fdd9+lT58+33v8HXfcgcfj4ZJLLuGjjz5iwoQJvP/++/zhD3/gT3/6E4GBgfTr148bb7zxhHsICgpizpw57N+/n9DQUM4991zmzZv3vceGh4fjcDh49tln2bNnDw0NDSQnJ3PTTTfx+9//HjCngH/44Yf893//N9dffz2lpaXExcVx3nnnERsbC3Ba+hYREbGCzTAMw+omRERERERERNojrV4uIiIiIiIi4iMK3SIiIiIiIiI+otAtIiIiIiIi4iMK3SIiIiIiIiI+otAtIiIiIiIi4iMK3SIiIiIiIiI+otDdyj344IPYbLYWj379+nlfr62t5dZbb6Vr166Eh4czbdo0Dhw40OIcbrebSy+9lE6dOhETE8M999xDY2Pjmf4o0gasXLmSyZMnk5CQgM1m45133mnxumEY3H///cTHxxMaGsr48ePZtWtXi2OOHDmC0+kkIiKCqKgofv7zn1NVVdXimM2bN3PuuecSEhJCcnIyTzzxhK8/mrQBP3b9XXfddd/5enjxxRe3OEbXn5yMxx9/nJEjR9K5c2diYmK4/PLLyc3NbXHM6fp+u3z5coYNG0ZwcDC9e/fm1Vdf9fXHk1buRK6/888//ztf/26++eYWx+j6k5P10ksvMXjwYCIiIoiIiGDUqFEsWrTI+7q+/p06he42YMCAARQXF3sfn332mfe13/zmN7z33nssWLCAFStWUFRUxBVXXOF9vampiUsvvZT6+nq++OIL/vnPf/Lqq69y//33W/FRpJU7duwYQ4YM4cUXX/ze15944gleeOEF/vrXv+JyuQgLC2PChAnU1tZ6j3E6nWzdupUlS5bw/vvvs3LlSn7xi194X6+oqOCiiy4iJSWF9evX8+STT/Lggw/yt7/9zeefT1q3H7v+AC6++OIWXw/nzp3b4nVdf3IyVqxYwa233srq1atZsmQJDQ0NXHTRRRw7dsx7zOn4frtv3z4uvfRSxo4dS05ODnfccQc33ngjixcvPqOfV1qXE7n+AG666aYWX/++/QtDXX9yKpKSkvjjH//I+vXrWbduHRdccAFTpkxh69atgL7+nRaGtGoPPPCAMWTIkO997ejRo0ZgYKCxYMECb2379u0GYHz55ZeGYRjGhx9+aPj5+RklJSXeY1566SUjIiLCqKur82nv0rYBxttvv+197vF4jLi4OOPJJ5/01o4ePWoEBwcbc+fONQzDMLZt22YAxtq1a73HLFq0yLDZbEZhYaFhGIbxl7/8xejSpUuL6+93v/udkZaW5uNPJG3Jf15/hmEYs2fPNqZMmXLc9+j6k9Pl4MGDBmCsWLHCMIzT9/32t7/9rTFgwIAWf9f06dONCRMm+PojSRvyn9efYRjGmDFjjF//+tfHfY+uPzndunTpYvz973/X17/TRCPdbcCuXbtISEigV69eOJ1O3G43AOvXr6ehoYHx48d7j+3Xrx92u50vv/wSgC+//JJBgwYRGxvrPWbChAlUVFR4f3slciL27dtHSUlJi+stMjISh8PR4nqLiopixIgR3mPGjx+Pn58fLpfLe8x5551HUFCQ95gJEyaQm5tLWVnZGfo00lYtX76cmJgY0tLS+OUvf8nhw4e9r+n6k9OlvLwcgOjoaOD0fb/98ssvW5zjm2O+OYcIfPf6+0ZWVhbdunVj4MCBzJkzh+rqau9ruv7kdGlqamLevHkcO3aMUaNG6evfaRJgdQPywxwOB6+++ippaWkUFxfz0EMPce6557JlyxZKSkoICgoiKiqqxXtiY2MpKSkBoKSkpMX/AN+8/s1rIifqm+vl+66nb19vMTExLV4PCAggOjq6xTE9e/b8zjm+ea1Lly4+6V/avosvvpgrrriCnj17smfPHn7/+98zceJEvvzyS/z9/XX9yWnh8Xi44447OPvssxk4cCDAaft+e7xjKioqqKmpITQ01BcfSdqQ77v+AGbNmkVKSgoJCQls3ryZ3/3ud+Tm5vLvf/8b0PUnp+6rr75i1KhR1NbWEh4ezttvv016ejo5OTn6+ncaKHS3chMnTvT+efDgwTgcDlJSUnjjjTfa/cUpIvJtM2bM8P550KBBDB48mNTUVJYvX864ceMs7Ezak1tvvZUtW7a0WD9F5Ew53vX37bUpBg0aRHx8POPGjWPPnj2kpqae6TalHUpLSyMnJ4fy8nLefPNNZs+ezYoVK6xuq93Q9PI2Jioqir59+7J7927i4uKor6/n6NGjLY45cOAAcXFxAMTFxX1ndcFvnn9zjMiJ+OZ6+b7r6dvX28GDB1u83tjYyJEjR3RNymnXq1cvunXrxu7duwFdf3LqbrvtNt5//30+/fRTkpKSvPXT9f32eMdEREToF+ly3Ovv+zgcDoAWX/90/cmpCAoKonfv3gwfPpzHH3+cIUOG8Pzzz+vr32mi0N3GVFVVsWfPHuLj4xk+fDiBgYEsW7bM+3pubi5ut5tRo0YBMGrUKL766qsWP4guWbKEiIgI0tPTz3j/0nb17NmTuLi4FtdbRUUFLperxfV29OhR1q9f7z3mk08+wePxeH9AGDVqFCtXrqShocF7zJIlS0hLS9PUXvlJCgoKOHz4MPHx8YCuPzl5hmFw22238fbbb/PJJ5985xaE0/X9dtSoUS3O8c0x35xDOqYfu/6+T05ODkCLr3+6/uR08ng81NXV6evf6WL1Sm7yw+666y5j+fLlxr59+4zPP//cGD9+vNGtWzfj4MGDhmEYxs0332zY7Xbjk08+MdatW2eMGjXKGDVqlPf9jY2NxsCBA42LLrrIyMnJMT766COje/fuxpw5c6z6SNKKVVZWGhs3bjQ2btxoAMYzzzxjbNy40cjLyzMMwzD++Mc/GlFRUcbChQuNzZs3G1OmTDF69uxp1NTUeM9x8cUXG0OHDjVcLpfx2WefGX369DFmzpzpff3o0aNGbGysce211xpbtmwx5s2bZ3Tq1Ml4+eWXz/jnldblh66/yspK4+677za+/PJLY9++fcbSpUuNYcOGGX369DFqa2u959D1Jyfjl7/8pREZGWksX77cKC4u9j6qq6u9x5yO77d79+41OnXqZNxzzz3G9u3bjRdffNHw9/c3PvroozP6eaV1+bHrb/fu3cYf/vAHY926dca+ffuMhQsXGr169TLOO+887zl0/cmpuPfee40VK1YY+/btMzZv3mzce++9hs1mMz7++GPDMPT173RQ6G7lpk+fbsTHxxtBQUFGYmKiMX36dGP37t3e12tqaoxbbrnF6NKli9GpUydj6tSpRnFxcYtz7N+/35g4caIRGhpqdOvWzbjrrruMhoaGM/1RpA349NNPDeA7j9mzZxuGYW4bdt999xmxsbFGcHCwMW7cOCM3N7fFOQ4fPmzMnDnTCA8PNyIiIozrr7/eqKysbHHMpk2bjHPOOccIDg42EhMTjT/+8Y9n6iNKK/ZD1191dbVx0UUXGd27dzcCAwONlJQU46abbmqxPYlh6PqTk/N91x1gvPLKK95jTtf3208//dTIyMgwgoKCjF69erX4O6Rj+rHrz+12G+edd54RHR1tBAcHG7179zbuueceo7y8vMV5dP3JybrhhhuMlJQUIygoyOjevbsxbtw4b+A2DH39Ox1shmEYZ25cXURERERERKTj0D3dIiIiIiIiIj6i0C0iIiIiIiLiIwrdIiIiIiIiIj6i0C0iIiIiIiLiIwrdIiIiIiIiIj6i0N2O1NXV8eCDD1JXV2d1K9IB6foTK+n6Eyvp+hMr6foTK+n6OzHaMqwdqaioIDIykvLyciIiIqxuRzoYXX9iJV1/YiVdf2IlXX9iJV1/J0Yj3SIiIiIiIiI+otAtIiIiIiIi4iMBVjfQVjU2NrJx40ZiY2Px82sdv7uorKwEoLCwkIqKCou7kY5G159YSdefWEnXn1hJ159YqaNffx6PhwMHDjB06FACAo4frXVP90lau3YtmZmZVrchIiIiIiIiFlqzZg0jR4487usa6T5JsbGxgPkPHB8fb3E3IiIiIiIiciYVFxeTmZnpzYbHo9B9kr6ZUh4fH09SUpLF3YiIiIiIiIgVfux249ZxM7KIiIiIiIhIO6TQLSIiIiIiIuIjCt0iIiIiIiIiPqJ7ukVERERERNopj8dDfX291W20SYGBgfj7+5/yeRS6RURERERE2qH6+nr27duHx+OxupU2Kyoqiri4OGw220mfQ6FbRERERESknTEMg+LiYvz9/UlOTv7RFbalJcMwqK6u5uDBgwCntE20QreIiIiIiEg709jYSHV1NQkJCXTq1Mnqdtqk0NBQAA4ePEhMTMxJTzXXrztERERERETamaamJgCCgoIs7qRt++YXFg0NDSd9DoVuERERERGRdupU7kWW0/Pvp9AtIiIiIiIi4iMK3SIiIiIiIiI+otAtIiIiIiIi7U6PHj147rnnrG5Dq5eLiIiIiIhI63D++eeTkZFxWsLy2rVrCQsLO/WmTpFCd3vXWAcBwVZ3ISIiIiIicsoMw6CpqYmAgB+Pst27dz8DHf04TS9vz47shSd7w8LbIO9LMAyrOxIREREREQsYhkF1faMlD+MEc8h1113HihUreP7557HZbNhsNl599VVsNhuLFi1i+PDhBAcH89lnn7Fnzx6mTJlCbGws4eHhjBw5kqVLl7Y4339OL7fZbPz9739n6tSpdOrUiT59+vDuu++ezn/m76WR7vZs+3tQVwEbXzMf0b0gYxYMmQmRSVZ3JyIiIiIiZ0hNQxPp9y+25O/e9ocJdAr68ej5/PPPs3PnTgYOHMgf/vAHALZu3QrAvffey1NPPUWvXr3o0qUL+fn5XHLJJTz66KMEBwfzr3/9i8mTJ5Obm4vdbj/u3/HQQw/xxBNP8OSTT/K///u/OJ1O8vLyiI6OPj0f9ntopLs9G/0ruO5DyLgGAsPMke9PHoFnB8JrU+GrN6GhxuouRUREREREiIyMJCgoiE6dOhEXF0dcXBz+/v4A/OEPf+DCCy8kNTWV6OhohgwZwn/9138xcOBA+vTpw8MPP0xqauqPjlxfd911zJw5k969e/PYY49RVVXFmjVrfPq5NNLdntls0ONs8zHxT7D9XdiYBXmfwZ5PzEdwJAy8AoZeA4nDzfeIiIiIiEi7Ehroz7Y/TLDs7z5VI0aMaPG8qqqKBx98kA8++IDi4mIaGxupqanB7Xb/4HkGDx7s/XNYWBgREREcPHjwlPv7IQrdHUVwuDm1PGOWOeK9aR7kzIVyN6x/xXx0S4MJj0Gf8VZ3KyIiIiIip5HNZjuhKd6t1X+uQn733XezZMkSnnrqKXr37k1oaChXXnkl9fX1P3iewMDAFs9tNhsej+e09/ttbfdfXU5edC8Y+3sYcy/sXwU5WbDtXTiUC0Hfupirj5jPtfq5iIiIiIicAUFBQTQ1Nf3ocZ9//jnXXXcdU6dOBcyR7/379/u4u5Nj6T3dK1euZPLkySQkJGCz2XjnnXdavG4YBvfffz/x8fGEhoYyfvx4du3a9aPnffHFF+nRowchISE4HI7vzNGvra3l1ltvpWvXroSHhzNt2jQOHDhwOj9a2+DnB73GwBV/g7t3wtS/gf2s5tc/fRSeTjNHxEVERERERHysR48euFwu9u/fz6FDh447Ct2nTx/+/e9/k5OTw6ZNm5g1a5bPR6xPlqWh+9ixYwwZMoQXX3zxe19/4okneOGFF/jrX/+Ky+UiLCyMCRMmUFtbe9xzzp8/nzvvvJMHHniADRs2MGTIECZMmNBinv5vfvMb3nvvPRYsWMCKFSsoKiriiiuuOO2fr00JiYAh05vv6TYMc5uxmjLoHNt8XNVB8yEiIiIiInKa3X333fj7+5Oenk737t2Pe4/2M888Q5cuXRg9ejSTJ09mwoQJDBs27Ax3e2JsxolumuZjNpuNt99+m8svvxwwR7kTEhK46667uPvuuwEoLy8nNjaWV199lRkzZnzveRwOByNHjuTPf/4zAB6Ph+TkZG6//XbuvfdeysvL6d69O9nZ2Vx55ZUA7Nixg/79+/Pll19y1llnfe956+rqqKur8z4vLCwkPT2d/Px8kpLa6fZbnibYtxJ6ngd+Xy9+sPi/wfVX6HMRZDjN/wYEWduniIiIiIi0UFtby759++jZsychISFWt9Nm/dC/Y0FBAcnJyT+aCVvtlmH79u2jpKSE8eObF/WKjIzE4XDw5Zdffu976uvrWb9+fYv3+Pn5MX78eO971q9fT0NDQ4tj+vXrh91uP+55AR5//HEiIyO9j/T09FP9iK2fnz+kjm0O3GAuwuZphNwPYb4TnukHH82Bkq+s61NERERERKSVarWhu6SkBIDY2NgW9djYWO9r/+nQoUM0NTX94HtKSkoICgoiKirqhM8LMGfOHMrLy72Pbdu2/dSP1D7MnAu3uODsX0N4LFQfhtV/gb+eYz5W/xWOHba6SxERERERkVah1Ybu1iY4OJiIiAjvo3Pnzla3ZJ2YfnDhH+A322DWAkifAv5B5mj3R78zF1+bfw3kLoKmRqu7FRERERERsUyrDd1xcXEA31lV/MCBA97X/lO3bt3w9/f/wffExcVRX1/P0aNHT/i8chz+AdD3Irj6X3BXLkx8EuIzwNMA29+DuTPgmf5QefwZBCIiIiIiIu1Zqw3dPXv2JC4ujmXLlnlrFRUVuFwuRo0a9b3vCQoKYvjw4S3e4/F4WLZsmfc9w4cPJzAwsMUxubm5uN3u455XTkCnaHD8Av5rBdz8OZx1K3TqBmHdzWno39i7wlwRXUREREREpAMIsPIvr6qqYvfu3d7n+/btIycnh+joaOx2O3fccQePPPIIffr0oWfPntx3330kJCR4VzgHGDduHFOnTuW2224D4M4772T27NmMGDGCzMxMnnvuOY4dO8b1118PmIux/fznP+fOO+8kOjqaiIgIbr/9dkaNGnXclcvlJ4obCBc/Bhc+BOUFzduQ1VXB3JnmQmy//By69bG2TxERERERER+zNHSvW7eOsWPHep/feeedAMyePZtXX32V3/72txw7doxf/OIXHD16lHPOOYePPvqoxVLte/bs4dChQ97n06dPp7S0lPvvv5+SkhIyMjL46KOPWiyu9uyzz+Ln58e0adOoq6tjwoQJ/OUvfzkDn7iD8Q+E6J7NzysKzecNNdC1d3N9xwfQra9CuIiIiIiItDutZp/utuZE92ST/2AYUH0Ewrqazxtq4em+UFsOSZkw1AkDpkJIpLV9ioiIiIi0Ydqn+/Ro1/t0SztlszUHbjC3HEs+C2x+ULAG3vs1PJUGb90Ee5eDx2NZqyIiIiIiIqdKobsdyy2ppNVPZIhMBOcbcOd2cxuybmnQWANfvQH/mgLPD4ZPHoUje63uVEREREREWrkePXrw3HPPWd1GCwrd7dT24gomPLeSSf/7GdkuN1V1rXy/7M5xcPav4VYX3PgJjLgBgiOhPB9WPgEvDIVXLoGNr5sLsomIiIiIiLQBCt3t1LaiCoIC/NhaVMHv3/4Kx6NL+e+3v2JbUYXVrf0wmw2ShsOkZ+HunTDtH5A6DrBB3uew8FbInm51lyIiIiIiIidEobudmjY8CdeccfzPpf3p1S2MY/VNZLncXPLCKqb+5XMWrMunpr7J6jZ/WGAIDLoSrv03/GYrjLsfolNh4BXNx9SUwfI/QVmedX2KiIiIiLQV9cd++qPpW7NmmxrNWkPNiZ33J/jb3/5GQkICnv9Y12nKlCnccMMN7NmzhylTphAbG0t4eDgjR45k6dKlJ/svccZYumWY+FaXsCBuPLcXPz+nJ1/uPUyWy83HW0vY6D7KRvdRHn5/G9OGJ+F02Okd09nqdn9YZCKcexeccyd4vvXLgi1vwfLHYMd7cPNn1vUnIiIiItIWPJbw099z1avmDkNg/ty94DpIOQeu/6D5mOcGmYsk/6cHy0/8r7nqKm6//XY+/fRTxo0bB8CRI0f46KOP+PDDD6mqquKSSy7h0UcfJTg4mH/9619MnjyZ3Nxc7Hb7T/9cZ4hCdwdgs9kYndqN0andKK2sY8H6fLJdbgrKanjl8/288vl+HD2jmeWwc/HAOIID/K1u+fhsNvD/1mXbpQf0HANplzTX6irh4/tgyAxIdpjvERERERGRVq1Lly5MnDiR7Oxsb+h+88036datG2PHjsXPz48hQ4Z4j3/44Yd5++23effdd7ntttusavtHKXR3MN07B3PL+b25+bxUVu4qJdvlZun2A7j2HcG17wjRYUFcNSKJWZl2UrqGWd3uj+s93nx8e5X2bQth/SvmIzoVMmaZATxS+6mLiIiISAf3+6Kf/h7/4OY/95tsnsP2H3cq3/HVqfX1NafTyU033cRf/vIXgoODycrKYsaMGfj5+VFVVcWDDz7IBx98QHFxMY2NjdTU1OB2u0/L3+0rCt0dlJ+fjfPTYjg/LYbi8hrmr81n3pp8SipqeXnFXl5esZdz+3TD6bAzrn8sgf6t/Pb/b49mxw2CDCdsfQeO7IFPHoZPHoHUsWa936UQGGpZqyIiIiIilgk6xYE1/4CWM09P13m/NnnyZAzD4IMPPmDkyJGsWrWKZ599FoC7776bJUuW8NRTT9G7d29CQ0O58sorqa+vPy1/t68odAvxkaHcMb4vt43tzSc7DpK9xs2KnaWs2nWIVbsOEdM5mBkjk5meaScxqg2E1fghcPlfYOIT5qh3TjbkfQZ7PjEfwZHmYmxDr4HE4Zp+LiIiIiLSSoSEhHDFFVeQlZXF7t27SUtLY9iwYQB8/vnnXHfddUydat5fXlVVxf79+y3s9sQodItXgL8fFw2I46IBceQfqWbuGjdvrMvnYGUdL3yymz9/upsL+sUwy2FnTN8Y/P1aeVgNDoehTvNxZC/kzIVNc829v7+Zft4t7evp5zOhc6zVHYuIiIiIdHhOp5NJkyaxdetWrrnmGm+9T58+/Pvf/2by5MnYbDbuu+++76x03hq18jnDYpXk6E789uJ+fHHvOP48ayijU7viMWDp9oPc8Oo6znviU/78yS4OVtRa3eqJie4FF/w3/Hoz/GwhDJ4OAaFwKBeWPgB7P7W6QxERERERAS644AKio6PJzc1l1qxZ3vozzzxDly5dGD16NJMnT2bChAneUfDWzGYY316BSk5UQUEBycnJ5Ofnk5TUMRbo2lNaxVyXmzc3FHC0ugGAAD8bF6bH4nSkMDq1K36tffT722rLzfu+t/4bZmQ334ey7hU4uA1G3AAx/S1tUURERETkZNTW1rJv3z569uxJSEiI1e20WT/073iimVDTy+WEpXYP538mpXP3hDQWbSkma7WbdXllLNpSwqItJfTo2olZDjtXDk8mOizI6nZ/XEgkDJ9tPr5hGLDmb2bojumv0C0iIiIiIqdEoVt+spBAf6YOTWLq0CR2lFSQ7XLz9oZC9h+u5rEPd/DU4p1MHBSH05HCyB5dsLW1hcouehg2zYMBVzTX1r0Cu5aY93/3nQD+gdb1JyIiIiIibYZCt5ySfnER/GHKQO6d2I/3NhWR5XKzuaCchTlFLMwpok9MOE6HnanDkogMbQNB1WZr3vv72zb8E4o2Qu4H0KkbDL7a3H4sbqA1fYqIiIiISJuge7pPUke8p/tEbS44SrbLzcKcImoamgAICfRj8uAEnGelMCQpsu2Nfh/cbm49tnk+VB1orscNNrceG3glhHW1rj8RERERkW/RPd2nx+m4p1uh+yQpdP+4itoGFm4sJMvlZkdJpbc+ICECpyOFyzISCA9uY5MtmhphzzLY+DrkLgKPuaAcfoGQNtEc/e49Hvzb2OcSERERkXblm7DYo0cPQkNDrW6nzaquriYvL0+h2woK3SfOMAw2uMvIcrl5f3Mx9Y3mXnphQf5cPjQRpyOF9IQIi7s8CdVH4KsFkJMFxZua62ExMGQ6nHs3hEZZ1p6IiIiIdFxNTU3s2rWLTp060b1797Y309RihmFQX19PaWkpTU1N9OnTBz+/ljtuK3T7mEL3ySk7Vs9bGwrIdrnZe+iYtz7UHsWsTDuTBicQGuRvYYcnqWRL8/Tz6kMQ2gXuyoWAYPN1TxP4tcHPJSIiIiJtVlVVFQUFBSjynbxOnToRHx9PUNB3d2dS6PYxhe5TYxgGq/ceIcuVx+KtJTQ0mZdhREgA04Yn4XTY6R3T2eIuT0JTA+z6GI4dat6KzOOBl0aZ249NeAwiEqztUUREREQ6jKamJhoaGqxuo03y9/cnICDguLMEtE+3tGo2m41RqV0ZldqV0so6FqzPJ9vlpqCshlc+388rn+/H0TOaWQ47Fw+MIzigjYwS+wdCv0tb1oo2QOkOKC+EKX9prtdVQXD4me1PRERERDoUf39//P3byM/S7ZRGuk+SRrpPP4/HYOWuUrJdbpZuP4Dn6yszOiyIq0YkMSvTTkrXMGubPBmGYd7zfXg3DLqyufaXURDcGYY6YcBUCIm0tk8RERERETlhml7uYwrdvlVcXsP8tfnMW5NPSUWtt35un244HXbG9Y8l0N/vB87Qyh3eA38eCYa5pRoBodB/shnAe5wHfm34s4mIiIiIdAAK3T6m0H1mNDZ5+GTHQbLXuFmxs5RvrtaYzsHMGJnM9Ew7iVFtdAuEyhJz4bWNWXAot7kemQxDZkLGTIjuZV1/IiIiIiJyXArdPqbQfeblH6lm7ho3b6zL51BVPQB+NrigXwyzHHbG9I3B368NboVgGFC4wdx6bMubUFve/FrK2ZAxC9Iv1/3fIiIiIiKtiEK3jyl0W6e+0cPH20rIdrn5Ys9hbz0xKpSZmclcPSKZmIiQHzhDK9ZQCzveN7cf2/MJ8PX/noFhMPLncNHDlrYnIiIiIiImrV4u7VZQgB+TBicwaXACe0qrmOty8+aGAgqP1vDUxzt5bukuLkyPxelIYXRqV/za0uh3YIi52NqgK83VzjfPM6efH9kD396qwNMEFYUQZbeuVxERERER+VEa6T5JGuluXWobmli0pZis1W7W5ZV56z26dmKWw86Vw5OJDvvuhvZtgmFA/hqIiG8O2buWQtY0c9Xzq161tD0RERERkY5II93SoYQE+jN1aBJThyaxo6SCbJebtzcUsv9wNY99uIOnFu9k4qA4nI4URvboctwN7lslmw3sjpa1og3mf8NimmseDxSuh6QRLUfFRURERETEMhrpPkka6W79qusbeW9TEVkuN5sLmhcn6xMTjtNhZ+qwJCJDAy3s8BQddYPNHyITzef7P4NXL4XoVHPxtSEzIFLXpoiIiIiIL2ghNR9T6G5bNhccJdvlZmFOETUN5t7YIYF+TB6cgPOsFIYkRbat0e/vs+FfsOheaDj2dcEGqWMhwwn9LoXANrq1moiIiIhIK6TQ7WMK3W1TRW0DCzcWkuVys6Ok0lsfkBCB05HCZRkJhAe34bsu6qpg20Jz9fO8z5rrwZEw8AoYeg0kDtf0cxERERGRU6TQ7WMK3W2bYRhscJeR5XLz/uZi6hs9AIQF+XP50EScjhTSEyIs7vIUHdkLm+aZAbw8v7neLa15+nnnOOv6ExERERFpwxS6fUyhu/0oO1bPWxsKyHa52XvomLc+1B7FrEw7kwYnEBrkb2GHp8jjgf2rICcLtr0LjTVm3eYHl/8Vhky3tj8RERERkTboRDOh3xns6aRUVlZyxx13kJKSQmhoKKNHj2bt2rXHPf66667DZrN95zFgwADvMQ8++OB3Xu/Xr9+Z+DjSCnUJC+LGc3ux7K4xzL3pLCYNjifQ38ZG91HueXMzjseW8tB7W9l9sPLHT9Ya+flBrzFwxd/g7lyY/AIkO8ytyL69KnrxJijaaNZFREREROS0aPU3r954441s2bKF1157jYSEBF5//XXGjx/Ptm3bSExM/M7xzz//PH/84x+9zxsbGxkyZAhXXXVVi+MGDBjA0qVLvc8DAlr9P4X4mM1mY1RqV0aldqW0so4F6/PJdrkpKKvhlc/388rn+3H0jGaWw87FA+MIDmiDo98hkTB8tvkoL2i5uvmnj8HOj+DCh+HsX1nXo4iIiIhIO9Kqk2ZNTQ1vvfUWCxcu5LzzzgPMUer33nuPl156iUceeeQ774mMjCQyMtL7/J133qGsrIzrr7++xXEBAQHExZ34/ax1dXXU1dV5n1dWttFRTzkh3TsHc8v5vbn5vFRW7T5E1uo8lm4/gGvfEVz7jhAdFsRVI5KYlWknpWuY1e2enG8Hbo/HDOT+wdD34uZ64QaoKIK+E8C/DW+vJiIiIiJikVYduhsbG2lqaiIkJKRFPTQ0lM8+++w472rpH//4B+PHjyclJaVFfdeuXSQkJBASEsKoUaN4/PHHsdvtxz3P448/zkMPPfTTP4S0aX5+Nsb07c6Yvt0pLq9h/tp85q3Jp6SilpdX7OXlFXs5t083nA474/rHEujf6u/Y+H5+fub080uegpBvLSD3+fOw7R3o1A0GX21uPxY30LI2RURERETamla/kNro0aMJCgoiOzub2NhY5s6dy+zZs+nduze5ubk/+N6ioiLsdjvZ2dlcffXV3vqiRYuoqqoiLS2N4uJiHnroIQoLC9myZQudO3f+3nP950h3YWEh6enpWkitA2ps8vDJjoNkr3GzYmep9xbomM7BzBiZzPRMO4lR7WRP7GUPm/t/HzvYXIsfYobvQVdBp2jrehMRERERsVC7Wb18z5493HDDDaxcuRJ/f3+GDRtG3759Wb9+Pdu3b//B9z7++OM8/fTTFBUVERQUdNzjjh49SkpKCs888ww///nPT6gvrV4uAPlHqpm7xs0b6/I5VFUPgJ8NLugXwyyHnTF9Y/D3a+N7Yjc1wu6l5urnuYvA02DW/QIhbaK593fqOPBv1RNnREREREROq3YTur9x7NgxKioqiI+PZ/r06VRVVfHBBx8c93jDMOjbty+TJk3i2Wef/dHzjxw5kvHjx/P444+fUD8K3fJt9Y0ePt5WQrbLzRd7DnvriVGhzMxM5uoRycREhPzAGdqIY4dhy5uw8XUo2dxcD4+FwdPNEfAY7QQgIiIiIu1fu9ky7BthYWHEx8dTVlbG4sWLmTJlyg8ev2LFCnbv3n1CI9dVVVXs2bOH+Pj409WudDBBAX5MGpxA9k1nseyuMdx4Tk+iOgVSeLSGpz7eyeg/fsIvX1/PZ7sO4fG0id9zfb+wruD4L7h5Fdz8GZx1C3TqClUH4IsX4KXRZjAXERERERGgDYx0L168GMMwSEtLY/fu3dxzzz2EhISwatUqAgMDmTNnDoWFhfzrX/9q8b5rr72WXbt2sXr16u+c8+6772by5MmkpKRQVFTEAw88QE5ODtu2baN79+4n1JdGuuXH1DY0sWhLMVmr3azLK/PWe3TtxCyHnSuHJxMddvzbHtqMxnrY9THkZIPNBjOyml9b8SQkDIXUseDXBrdYExERERE5jhPNhK3+Jszy8nLmzJlDQUEB0dHRTJs2jUcffZTAQHP7ouLiYtxu93fe89Zbb/H8889/7zkLCgqYOXMmhw8fpnv37pxzzjmsXr36hAO3yIkICfRn6tAkpg5NYkdJBdkuN29vKGT/4Woe+3AHTy3eycRBcTgdKYzs0QWbrY3e+x0QBP0nmQ+Pp7l+1A2fPgoY8OvN0CXluKcQEREREWmvWv1Id2ulkW45GdX1jby3qYgsl5vNBeXeep+YcJwOO1OHJREZ2k72wy4vgM9fMKeeX/3P5vrSB6FLDxhwRcvtyURERERE2pB2t5Baa6PQLadqc8FRsl1uFuYUUdPQBEBIoB+TByfgPCuFIUmRbXf0+3gqS+CZdDCaICAU+k+GoU7ocZ65V7iIiIiISBuh0O1jCt1yulTUNrBwYyFZLjc7Siq99QEJETgdKVyWkUB4cKu/E+TE1ByFDf+EjVlwKLe5HpkMQ2ZCxkyI7mVZeyIiIiIiJ0qh28cUuuV0MwyDDe4yslxu3t9cTH2jeX90WJA/lw9NxOlIIT2hnUzHNgwo3AA5r8NXb0Fd81R7Us6GjFmQfjkEh1vWooiIiIjID1Ho9jGFbvGlsmP1vLWhgGyXm72HjnnrQ+1RzMq0M2lwAqFB7WQ18IZa2PG+ufr5nk+Ar78kBYZB+hQYdi2kjLa0RRERERGR/6TQ7WMK3XImGIbB6r1HyHLlsXhrCQ1N5v+uESEBTBuehNNhp3dMZ4u7PI3KC2HzPHP6+ZE9Zi398pYLsYmIiIiItAIK3T6m0C1nWmllHQvW55PtclNQVuOtO3pGM8th5+KBcQQHtJPRb8OA/DWQkwUDppr7fAMc2gUf3AnDZsOgK63tUUREREQ6tHazT7eImLp3DuaW83tz83mprNp9iKzVeSzdfgDXviO49h0hOiyIq0YkMSvTTkrXMKvbPTU2G9gd5uPbcrJh30pz5fNvh27DMN8jIiIiItLKKHSLtDF+fjbG9O3OmL7dKS6vYf7afOatyaekopaXV+zl5RV7ObdPN5wOO+P6xxLo34624hpxPQSEQNKI5lpZHmRdCUNmwOAZEJloXX8iIiIiIv9B08tPkqaXS2vS2OTh09xSslx5rNhZyjf/V8d0DmbGyGSmZ9pJjAq1tklfWfEEfPqo+WebH/Qaa65+3m8SBIZY25uIiIiItFu6p9vHFLqltco/Us3cNW7eWJfPoap6APxsMDYtBudZdsb0jcHfrx1Nxa6rhG0LzanneZ8310MiYeA0yLgGEodp+rmIiIiInFYK3T6m0C2tXX2jh4+3lZDtcvPFnsPeemJUKDMzk7l6RDIxEe1sJPjIXsiZC5vmQnl+c717P3P0e/B06BxnXX8iIiIi0m4odPuYQre0JXtKq5jrcvPmhgKOVjcAEOBn48L0WJyOFEandsWvPY1+ezywf6U5+r3tXWj8erV3mz/0Hg9jfgdJw63tUURERETaNIVuH1PolraotqGJRVuKyVrtZl1embfeo2snZjnsXDk8meiwIAs79IHactj6jrn9WL7LrM1+H3qea/65sQ78gzT9XERERER+EoVuH1PolrZuR0kF2S43b28opLKuEYAgfz8mDorD6UhhZI8u2NpbED20G7a9A+fcCX5fr+q+6HewbxWMfxD6XmRldyIiIiLShih0+5hCt7QX1fWNvLepiCyXm80F5d56n5hwnA47U4clERkaaGGHPuTxwLMDoLIInG9Bn/FmvbbC3JosoJ2N+ouIiIjIaaPQ7WMK3dIebS44SrbLzcKcImoamgAICfRj8uAEnGelMCQpsv2NfteUmfd9D70G/PzN2pIHYOPrMPhqyHBC3EBrexQRERGRVkeh28cUuqU9q6htYOHGQrJcbnaUVHrrAxIicDpSuCwjgfDgAAs79LGXx0BxTvPz+CFm+B50FXSKtqwtEREREWk9FLp9TKFbOgLDMNjgLiPL5eb9zcXUN3oACAvy5/KhiTgdKaQnRFjcpQ80NcKeZeZod+4i8JgrvuMXCGkTzVHx1HHg345/8SAiIiIiP0ih28cUuqWjKTtWz1sbCsh2udl76Ji3PtQexaxMO5MGJxAa5G9hhz5SfQS+WmCufl68qbkeHmvu+53hhJh+1vUnIiIiIpZQ6PYxhW7pqAzDYPXeI2S58li8tYSGJvNLSERIANOGJ+F02Okd09niLn2kZIsZvjfPh+rDzfXE4eB8U1PPRURERDoQhW4fU+gWgdLKOhaszyfb5aagrMZbd/SMZpbDzsUD4wgOaIej3431sOtjyMmGXYshOhVudTXv9X1wB3Tr07wwm4iIiIi0OwrdPqbQLdLM4zFYtfsQWavzWLr9AJ6vv6pEhwVx1YgkZmXaSekaZm2TvlJVCuVuc7QboL4anuoLwZ3h54shym5tfyIiIiLiEyeaCbUKkIicMj8/G2P6dmdM3+4Ul9cwf20+89bkU1JRy8sr9vLyir2c26cbToedcf1jCfT3s7rl0ye8u/n4Rul2c4G1gCCI+NYX3/w10L0fhLTDhedERERE5Lg00n2SNNIt8sMamzx8mltKliuPFTtL+eYrTUznYGaMTGZ6pp3EqFBrm/SVxjoo2w/d05qfP50GDbXQfzIMdUKP88CvHf3yQURERKSD0fRyH1PoFjlx+UeqmbvGzRvr8jlUVQ+Anw3GpsXgPMvOmL4x+PvZLO7Shw7vgbkz4VBucy0yGYbMhIyZEN3Lut5ERERE5KQodPuYQrfIT1ff6GHJtgNkufL4Yk/z6t+JUaHMzEzm6hHJxESEWNihDxkGFG6AnNfhq7egrrz5tZSzIWMWpF8OweGWtSgiIiIiJ06h28cUukVOzZ7SKua63Ly5oYCj1Q0ABPjZuDA9FqcjhdGpXfFrr6PfDTWw4wNz+7E9nwJffxkODIMBl5sB3D5a089FREREWjGFbh9T6BY5PWobmli0pZis1W7W5ZV56z26dmKWw86Vw5OJDguysEMfKy+ETXPN7ceO7Gmu95sEM7Ks60tEREREfpBCt48pdIucfjtKKsh2uXl7QyGVdY0ABPn7MXFQHE5HCiN7dMFma6ej34YB+S5z9HvL2zD+Aci8yXytthxyPzIXYQvqZG2fIiIiIgIodPucQreI71TXN/LepiKyXG42FzTf+9wnJhynw87UYUlEhgZa2KGP1R8DbM0Be90r8P4dkDQSblxqZWciIiIi8rUTzYS6YVBEWp1OQQFMH2nn3dvO4d3bzmbGyGRCA/3ZdbCKB9/bhuOxpdyzYBM5+Udpl783DAprOaIdEAxRKdD/suZafTV89qw5PV1EREREWi2NdJ8kjXSLnFkVtQ0s3FhIlsvNjpJKb31AQgRORwqXZSQQHhxgYYc+5vGAp8EM4ACb5sHb/wU2P+g11tz7O+1SCGynq7+LiIiItDKaXu5jCt0i1jAMgw3uMrJcbt7fXEx9oweAsCB/Lh+aiNORQnpChMVdngG7l8LKp8H9RXMtJBIGXgkZTkgcBu31/ncRERGRVkCh28cUukWsV3asnrc2FJDtcrP30DFvfag9ilmZdiYNTiA0yN/CDs+Aw3u+Xv18LlQUNNe79zO3Hhs8AzrHWtefiIiISDul0O1jCt0irYdhGKzee4QsVx6Lt5bQ0GR+WYsICWDa8CScDju9Yzpb3KWPeTywb4W59dj2d6Gx1qzb/KH3eHP6ed+Lm6eni4iIiMgpaTcLqVVWVnLHHXeQkpJCaGgoo0ePZu3atcc9fvny5dhstu88SkpKWhz34osv0qNHD0JCQnA4HKxZs8bXH0VEfMRmszEqtSt/njWML+4dx28vTiOpSygVtY288vl+xj+zkukvf8nCnELqGpusbtc3/PwgdSxM+39w906Y/DwkZYLRBLsWwxs/g6/etLpLERERkQ6n1a86dOONN7JlyxZee+01EhISeP311xk/fjzbtm0jMTHxuO/Lzc0lIqL5vs6YmBjvn+fPn8+dd97JX//6VxwOB8899xwTJkwgNze3xXEi0vZ07xzMLef35ubzUlm1+xBZq/NYuv0Arn1HcO07QnRYEFeNSGJWpp2UrmFWt+sbIZEw/DrzcWiXuff39vcg/Vurn295CypLYNDVEN7dqk5FRERE2r1WPb28pqaGzp07s3DhQi699FJvffjw4UycOJFHHnnkO+9Zvnw5Y8eOpaysjKioqO89r8PhYOTIkfz5z38GwOPxkJyczO2338699977ve+pq6ujrq7O+7ywsJD09HRNLxdpA4rLa5i/Np95a/Ipqaj11s/t0w2nw864/rEE+rf6iT+nxjBaLqz20jlw4Cu45CnIvMm6vkRERETaqHYxvbyxsZGmpiZCQlpugRMaGspnn332g+/NyMggPj6eCy+8kM8//9xbr6+vZ/369YwfP95b8/PzY/z48Xz55ZfHPd/jjz9OZGSk95Genn6Sn0pEzrT4yFDuGN+Xz343lv/3sxGcn9Ydmw1W7TrEza9v4Ow/fsIzH+dSeLTG6lZ959uB2+OBEddB8lkwcFpzffMC+Oj3ULLljLcnIiIi0l616pFugNGjRxMUFER2djaxsbHMnTuX2bNn07t3b3Jzc79zfG5uLsuXL2fEiBHU1dXx97//nddeew2Xy8WwYcMoKioiMTGRL774glGjRnnf99vf/pYVK1bgcrm+tw+NdIu0L/lHqpm7xs0b6/I5VFUPgJ8NxqbF4DzLzpi+Mfj7dbAtt/4+Hgq+XjMjfoi59digq6BTtLV9iYiIiLRC7Wb18j179nDDDTewcuVK/P39GTZsGH379mX9+vVs3779hM4xZswY7HY7r7322kmH7v+k1ctF2of6Rg9Lth0gy5XHF3sOe+uJUaHMzEzm6hHJxESE/MAZ2gnDgF0fw8bXIXcReBrMul8gpE2EoddA6jjwb/VLgYiIiIicESeaCVv9T0+pqamsWLGCY8eOUVFRQXx8PNOnT6dXr14nfI7MzEzvdPRu3brh7+/PgQMHWhxz4MAB4uLiTmvvItL6BQX4cengeC4dHM+e0irmuty8uaGAwqM1PPXxTp5buosL02NxOlIYndoVv/Y6+m2zQd8J5uPYYdjyphnASzabW5BtfxfCY2HwdHMEPKaf1R2LiIiItAmt+p7ubwsLCyM+Pp6ysjIWL17MlClTTvi9OTk5xMfHAxAUFMTw4cNZtmyZ93WPx8OyZctajHyLSMeT2j2c/5mUzuo543h2+hBGpHSh0WOwaEsJ1/zDxQVPL+dvK/dw5Fi91a36VlhXcPwX3LwKbv4MzroFOnWFqgPwxQvwFwf8vwtg7d+hoR3fBy8iIiJyGrT66eWLFy/GMAzS0tLYvXs399xzDyEhIaxatYrAwEDmzJlDYWEh//rXvwB47rnn6NmzJwMGDKC2tpa///3v/O///i8ff/wx48aNA8wtw2bPns3LL79MZmYmzz33HG+88QY7duwgNjb2hPrS9HKRjmFHSQXZLjdvbyiksq4RgCB/PyYOisPpSGFkjy7YbO109PvbGuvN6ec52ea+355Gc2uyu3ZCYAeYfi8iIiLyH9rN9PLy8nLmzJlDQUEB0dHRTJs2jUcffZTAwEAAiouLcbvd3uPr6+u56667KCwspFOnTgwePJilS5cyduxY7zHTp0+ntLSU+++/n5KSEjIyMvjoo49OOHCLSMfRLy6CP0wZyL0T+/HepiKyXG42F5SzMKeIhTlF9IkJx+mwM3VYEpGhgVa36zsBQdB/kvmoKoWv3oCm+ubAbRjwz8mQNBJG367F10RERES+1upHulsrjXSLdFybC46S7XKzMKeImoYmAEIC/Zg8OAHnWSkMSYrsGKPf3+ZeDf83AQI7wd07IbizWf/P/cFFRERE2ol2s3p5a6XQLSIVtQ0s3FhIlsvNjpJKb31AQgRORwqXZSQQHtzqJxSdHo11kPshVBTDqFvMmmHAPy6C6J7m4ms9zgW/NrOUiIiIiMgPUuj2MYVuEfmGYRhscJeR5XLz/uZi6hs9AIQF+XP50EScjhTSEyIs7tICB7bCS6Obn0faIWMmDJlpBnERERGRNkyh28cUukXk+5Qdq+etDQVku9zsPXTMWx9qj2JWpp1JgxMIDfK3sMMzyDCgcD3kZMFXb0FdefNrKedAxixInwLB4db1KCIiInKSFLp9TKFbRH6IYRis3nuELFcei7eW0NBkfqmNCAlg2vAknA47vWM6W9zlGdRQAzs+MAP4nk+Br7/1BIbBgMvN6ecpo3X/t4iIiLQZCt0+ptAtIieqtLKOBevzyXa5KShr3tfa0TOaWQ47Fw+MIzigg4x+A5QXwqa55vZjR/Y017v0MPcEd/yXZa2JiIiInCiFbh9T6BaRn8rjMVi1+xBZq/NYuv0Anq+/+kaHBXHViCRmZdpJ6RpmbZNnkmFAvssc/d7yNtRXwqjbYMKj5useDzTWQlAna/sUERER+R4K3T6m0C0ip6K4vIb5a/OZtyafkopab/3cPt1wOuyM6x9LoH8HWum7/hhsfx8Sh0O33mZtzycw/2cw4jq46BFL2xMRERH5TyeaCTvIXjYiIq1LfGQod4zvy21je/NpbilZrjxW7Cxl1a5DrNp1iJjOwcwYmcz0TDuJUaFWt+t7QWEwZHrLWu5H5uh3Q/OUfAwDKksgIv7M9iciIiJykjTSfZI00i0ip1v+kWrmrnHzxrp8DlXVA+Bng7FpMTjPsjOmbwz+fh1ooTGPB9xfQHhc8+i3ezW8MhF6jTVXP+83CQJDrO1TREREOiRNL/cxhW4R8ZX6Rg9Lth0gy5XHF3sOe+uJUaHMzEzm6hHJxER00KD52bOw9MHm5yGRMHAaZFwDicO0+rmIiIicMQrdPqbQLSJnwp7SKua63Ly5oYCj1Q0ABPjZuDA9FqcjhdGpXfHrSKPfAEf2Qs5ccwX08vzmevd+5uj34BnQOda6/kRERKRDUOj2MYVuETmTahuaWLSlmKzVbtbllXnrPbp2YpbDzpXDk4kOC7KwQwt4PLB/JWzMgu3vmiudA9j8ofd4GOqEvhMhoIP9u4iIiMgZodDtYwrdImKVHSUVZLvcvL2hkMq6RgCC/P2YOCgOpyOFkT26YOto06xry2Hr22YAL1jTXA+Nhql/hb4TrOtNRERE2iWFbh9T6BYRq1XXN/LepiKyXG42F5R7631iwpnlsHPFsCQiQwMt7NAih3aZe39vmgeVxXD7Buiaar52ZC8ER0BYN2t7FBERkTZPodvHFLpFpDXZXHCUbJebhTlF1DQ0ARAS6MfkwQk4z0phSFJkxxv99jRBwTqwO5pr85yw8yOY/DwMvca63kRERKTN0z7dIiIdyOCkKAYnRfH7S/uzcGMhWS43O0oqWbC+gAXrCxiQEMEsh50pGYmEB3eQL/1+/i0Dt6cJjh0CTyMkDGuul+ZCUwPEDTzzPYqIiEi7p5Huk6SRbhFpzQzDYIO7jCyXm/c3F1Pf6AEgLMify4cm4nSkkJ4QYXGXFjm8p3m6OcCbP4ctb0L8EMhwwqCroFO0df2JiIhIm6Dp5T6m0C0ibUXZsXre2lBAtsvN3kPHvPWh9ihmZdqZNDiB0CB/Czu0kGHAv39hLsLmMbdkwy8Q0iaa089Tx4F/B5kZICIiIj+JQrePKXSLSFtjGAar9x4hy5XH4q0lNDSZX/4jQgKYNjwJp8NO75jOFndpkWOH4asF5gJsJZub6+GxMHi6GcC7p1nXn4iIiLQ6Ct0+ptAtIm1ZaWUdC9bnk+1yU1BW4607ekYzy2Hn4oFxBAd00NHvkq8gJxs2z4fqw831xOHm9POB0yA0yrL2REREpHVQ6PYxhW4RaQ88HoNVuw+RtTqPpdsP4Pn6O0J0WBBXjUhiVqadlK5h1jZplcZ62PWxOfq9czEY5qrwBHaCu3ZASKS1/YmIiIilFLp9TKFbRNqb4vIa5q/NZ96afEoqar31c/t0w+mwM65/LIH+fhZ2aKGqg7D5DTOAd46Ha//d/NqG18A+Crr1tq4/EREROeMUun1MoVtE2qvGJg+f5paS5cpjxc5SvvkuEdM5mBkjk5meaScxKtTaJq1iGFBfBcFf3/teXgjPDgAM+M02iEy0tD0RERE5c7RPt4iInJQAfz8uTI/lwvRY8o9UM3eNmzfW5XOwso4XPtnNnz/dzdi0GJxn2RnTNwZ/P5vVLZ85Nltz4AYzgPe5CBqqWwbu1S9BTDr0OBf8OujsABEREQE00n3SNNItIh1JfaOHJdsOkOXK44s9zYuLJUaFMjMzmatHJBMTEWJhhxZramzeWqyqFJ7pB55GiLRDxkwYMhOie1rbo4iIiJxWml7uYwrdItJR7SmtYq7LzZsbCjhabe5tHeBn48L0WJyOFEandsWvI41+/6eKIljxBGz5N9SVN9dTzoGhTuh/GQSHW9efiIiInBYK3T6m0C0iHV1tQxOLthSTtdrNurwyb71H107Mcti5cngy0WFBFnZosYYa2PEBbHwd9i4Hvv52GxgGA6ZCxixIGW1OWRcREZE2R6HbxxS6RUSa7SipINvl5u0NhVTWNQIQ5O/HxEFxOB0pjOzRBVtHDpflBbBprrn/95G9zfUuPcy9v4fMhKhky9oTERGRn06h28cUukVEvqu6vpH3NhWR5XKzuaB5anWfmHBmOexcMSyJyNBACzu0mGGAe7W59djWt82F2AD6TYIZWdb2JiIiIj+JQrePKXSLiPywrwrKyV6Txzsbi6hpaAIgJNCPyYMTcJ6VwpCkyI49+l1/DLa/Zwbws26BtIlm/che+OxZGHotJGda26OIiIgcl0K3jyl0i4icmIraBhZuLCTL5WZHSaW3PiAhglkOO1MyEgkP1g6WXp88AiufhN7j4Zq3rO5GREREjkOh28cUukVEfhrDMNjgLiPL5eb9zcXUN3oACAvy5/KhiTgdKaQnRFjcZSuQvxbW/R/0uwT6TzZr5QXw3q/NxdfSLoXADrw9m4iISCuh0O1jCt0iIiev7Fg9b20oINvlZu+hY956RnIUToedSYMTCA3yt7DDVmblU/DJw+afQyJh4JXmAmyJw7T6uYiIiEUUun1MoVtE5NQZhsHqvUfIcuWxeGsJDU3mt6SIkACmDU/C6bDTO6azxV22Akf2mfd+58yFioLmevd+5uj34BnQOda6/kRERDqgE82Efmewp5NSWVnJHXfcQUpKCqGhoYwePZq1a9ce9/h///vfXHjhhXTv3p2IiAhGjRrF4sWLWxzz4IMPYrPZWjz69evn648iIiL/wWazMSq1K3+eNYwv7h3Hby9OI6lLKBW1jbzy+X7GP7OS6S9/ycKcQuoam6xu1zrRPeGC/4E7voJr34FBV0NACJTugCX3wzP9Ietq2LYQGuus7lZERES+pdWvXHPjjTeyZcsWXnvtNRISEnj99dcZP34827ZtIzEx8TvHr1y5kgsvvJDHHnuMqKgoXnnlFSZPnozL5WLo0KHe4wYMGMDSpUu9zwMCWv0/hYhIu9a9czC3nN+bm89LZdXuQ2StzmPp9gO49h3Bte8I0WFBXDUiiVmZdlK6hlndrjX8/CB1rPmofcrcdmxjFhSsgV2LzUdoFzOUO/4LuqZa3bGIiEiH16qnl9fU1NC5c2cWLlzIpZde6q0PHz6ciRMn8sgjj5zQeQYMGMD06dO5//77AXOk+5133iEnJ+eke9P0chER3ysur2H+2nzmrcmnpKLWWz+3TzecDjvj+scS6N/qJ2353qFdkJMNm+ZBZZFZu/YdM5yDuT+47v0WERE5rU40E7bq4d3GxkaampoICWm5SmtoaCifffbZCZ3D4/FQWVlJdHR0i/quXbtISEggJCSEUaNG8fjjj2O32497nrq6OurqmqfsVVZWHvdYERE5PeIjQ7ljfF9uG9ubT3NLyXLlsWJnKat2HWLVrkPEdA5mxshkpmfaSYwKtbpd63TrA+MfMKeg7/0UdnwAPcc0v770ATi0G869E5JGWNeniIhIB9SqR7oBRo8eTVBQENnZ2cTGxjJ37lxmz55N7969yc3N/dH3P/HEE/zxj39kx44dxMTEALBo0SKqqqpIS0ujuLiYhx56iMLCQrZs2ULnzt+/YM+DDz7IQw899J26RrpFRM6s/CPVzF3j5o11+RyqqgfAzwZj02JwnmVnTN8Y/P00quvV1AhPp0H1IZg5D9ImNtf9W/Xv3kVERFq1drN6+Z49e7jhhhtYuXIl/v7+DBs2jL59+7J+/Xq2b9/+g+/Nzs7mpptuYuHChYwfP/64xx09epSUlBSeeeYZfv7zn3/vMf850l1YWEh6erpCt4iIReobPSzZdoAsVx5f7DnsrSdGhTIzM5mrRyQTE6H9rAE4uB2+ehPOvxf8A83asodh91Jz67FBV0Kn6B8+h4iIiLTQbkL3N44dO0ZFRQXx8fFMnz6dqqoqPvjgg+MeP2/ePG644QYWLFjQ4n7w4xk5ciTjx4/n8ccfP6F+dE+3iEjrsae0irkuN29uKOBodQMAAX42LkyPxelIYXRqV/w0+t3MMOCFoVC2z3zuH2SOgGdcA6kXaARcRETkBLSbLcO+ERYWRnx8PGVlZSxevJgpU6Yc99i5c+dy/fXXM3fu3BMK3FVVVezZs4f4+PjT2bKIiJwhqd3D+Z9J6ayeM45npw9hREoXGj0Gi7aUcM0/XFzw9HL+tnIPR47VW91q62CzwY3L4OI/QdxgaKo3txvLvgqeHWBuQ1b647dwiYiIyI9r9SPdixcvxjAM0tLS2L17N/fccw8hISGsWrWKwMBA5syZQ2FhIf/6178Ac0r57Nmzef7557niiiu85wkNDSUyMhKAu+++m8mTJ5OSkkJRUREPPPAAOTk5bNu2je7du59QXxrpFhFp3XaUVJDtcvP2hkIq6xoBCPL3Y+KgOJyOFEb26IJNK3qbSr4yVz/fPB+qm6fqkzjcnH4+cBqERlnWnoiISGvUbqaXv/HGG8yZM4eCggKio6OZNm0ajz76qDdAX3fddezfv5/ly5cDcP7557NixYrvnGf27Nm8+uqrAMyYMYOVK1dy+PBhunfvzjnnnMOjjz5KauqJ72eq0C0i0jZU1zfy3qYislxuNheUe+t9YsKZ5bBzxbAkIkMDLeywFWmsh10fQ04W7FwMRpNZ9w+G/pNg0nMQEmFpiyIiIq1FuwndrZVCt4hI2/NVQTnZa/J4Z2MRNQ1moAwJ9GPy4AScZ6UwJClSo9/fqDoIm98wA/jBbdC1N9y2rnm/7+ojWnxNREQ6NIVuH1PoFhFpuypqG1i4sZAsl5sdJZXe+oCECGY57EzJSCQ8WIuJAeaia8U5ZsjuPc6sNdSY25B17w9X/ws6x1raooiIiBUUun1MoVtEpO0zDIMN7jKyXG7e31xMfaMHgLAgfy4fmojTkUJ6gqZTf8e+VfCvyyAiEX69Gfy+Xpf1yF6I6tH8XEREpB1T6PYxhW4RkfblaHU9b64vINvlZu+hY956RnIUToedSYMTCA3yt7DDVqaiGMr2Q8oo83lTAzzdDwI7QcZMGDITonta2qKIiIgvKXT7mEK3iEj7ZBgGq/ceIcuVx+KtJTQ0md8mI0ICmDY8CafDTu+YzhZ32QqVbIFXLoG65sXqSDkHMmZB+hQIDreuNxERER9Q6PYxhW4RkfavtLKOBevzyXa5KSir8dYze0bjdNi5eGAcwQEa/fZqqIEdH5iLr+35FPj6R4zAMBgw1QzgKaObF2MTERFpwxS6fUyhW0Sk4/B4DFbtPkTW6jyWbj+A5+vvnNFhQVw1IolZmXZSuoZZ22RrU14Am+aa+38f2dtc79LD3Pt7yEyISrasPRERkVOl0O1jCt0iIh1TcXkN89fmM29NPiUVtd76uX264XTYGdc/lkB/LSTmZRjgXm2Ofm99G+qrvn7BBiNvhEufsrQ9ERGRk6XQ7WMK3SIiHVtjk4dPc0vJcuWxYmcp33w3jekczIyRyUzPtJMYFWptk61N/THY/h5sfB32r4IJj8OoW8zX6qrM/cCTRmr6uYiItAkK3T6m0C0iIt/IP1LN3DVu3liXz6GqegD8bDA2LQbnWXbG9I3B309BsoWy/RASBaFR5vMNr8G7t0Hfi2HWfAsbExEROTEnmgkDzmBPIiIi7VJydCd+e3E/7hjflyXbDpDlyuOLPYdZtuMgy3YcJDEqlJmZyVw9IpmYiBCr220duvRo+bz6kLndWLKjudZQA7kfQtqlEKh/NxERaZs00n2SNNItIiI/ZE9pFXNdbt7cUMDR6gYAAvxsXJgei9ORwujUrvhp9LulukrzHvCQCPP5V2/CWz+HkEgYeKW5AFviME0/FxGRVkHTy31MoVtERE5EbUMTi7YUk7Xazbq8Mm+9R9dOzHLYuXJ4MtFhQRZ22IptmgfLHoaKguZa937m1mODZ0DnWOt6ExGRDs+noTs/Px+bzeY98Zo1a8jOziY9PZ1f/OIXJ991G6LQLSIiP9WOkgqyXW7e3lBIZV0jAEH+fkwcFIfTkcLIHl2waRS3JY8H9q0wVz/f/h40fr1ivM0f+lxoBvC+EyFAv7gQEZEzy6eh+9xzz+UXv/gF1157LSUlJaSlpTFgwAB27drF7bffzv33339KzbcFCt0iInKyqusbeW9TEVkuN5sLyr31PjHhzHLYuWJYEpGhgRZ22ErVlsOWf5t7fxesaa6HRsOgq2CoE+IGa/q5iIicET4N3V26dGH16tWkpaXxwgsvMH/+fD7//HM+/vhjbr75Zvbu3XtKzbcFCt0iInI6fFVQTvaaPN7ZWERNQxMAIYF+TB6cgPOsFIYkRWr0+/uU7oRN2eYU9Mri5vq0f8CgK63rS0REOgyfrl7e0NBAcHAwAEuXLuWyyy4DoF+/fhQXF//QW0VERORbBiVF8njSYOZc0p+FGwvJcrnZUVLJgvUFLFhfwICECGY57EzJSCQ8WJuOeHXvC+MfhAvugz2fQs7rsOcTc8r5N3YtgaZ66HMR+GvmgIiIWOOkRrodDgdjx47l0ksv5aKLLmL16tUMGTKE1atXc+WVV1JQUPDjJ2njNNItIiK+YBgGG9xlZLncvL+5mPpGDwBhQf5cPjQRpyOF9IQIi7tspRpqW24t9vIYKM6BS56CzJssa0tERNonn450/+lPf2Lq1Kk8+eSTzJ49myFDhgDw7rvvkpmZeXIdi4iICDabjeEp0QxPieb+Sem8ub6AbJebvYeOkeVyk+Vyk5EchdNhZ9LgBEKD/K1uufX4duBuaoCe58KxQzDgiuZ67iI4mm9OQe8UfeZ7FBGRDuektwxramqioqKCLl26eGv79++nU6dOxMTEnLYGWyuNdIuIyJliGAar9x4hy5XH4q0lNDSZ37ojQgKYNjwJp8NO75jOFnfZShlGy4XV/u9icH8J/kGQNhEyroHUC8BfU/dFROSn8elCajU1NRiGQadOnQDIy8vj7bffpn///kyYMOHku25DFLpFRMQKpZV1LFifT7bLTUFZjbee2TMap8POxQPjCA7Q6Pf3MgxwvWze/13yVXM9PA6GTIcMJ3RPs64/ERFpU3waui+66CKuuOIKbr75Zo4ePUq/fv0IDAzk0KFDPPPMM/zyl788pebbAoVuERGxksdjsGr3IbJW57Fsx0GaPOa38+iwIK4akcSsTDspXcMs7rIVK95sbj321RtQfbi5njjC3Pt74DQIjbKsPRERaf18Grq7devGihUrGDBgAH//+9/53//9XzZu3Mhbb73F/fffz/bt20+p+bZAoVtERFqL4vIa5q/NZ96afEoqar31c/t0w+mwM65/LIH+fhZ22Io11sOuxbAxC3Z9DIa5bRv+wdB/kjn63et88NPsARERacmnobtTp07s2LEDu93O1VdfzYABA3jggQfIz88nLS2N6urqU2q+LVDoFhGR1qaxycOnuaVkufJYsbOUb77Dx3QOZsbIZKZn2kmMCrW2ydas6iBsnm8G8NKvBxCCOsPdOyGok7W9iYhIq+PT1ct79+7NO++8w9SpU1m8eDG/+c1vADh48CAREdrGRERExAoB/n5cmB7Lhemx5B+pZu4aN2+sy+dgZR0vfLKbP3+6m7FpMTjPsjOmbwz+frYfP2lHEh4Do2+HUbdB0UZz+nlgSHPgNgx4+2ZIGQ2DrlIQFxGRE3JSI91vvvkms2bNoqmpiQsuuIAlS5YA8Pjjj7Ny5UoWLVp02httbTTSLSIibUF9o4cl2w6Q5crjiz3N9y4nRoUyMzOZq0ckExMR8gNnEK+CdfD3cRAQao5+h2igQUSkI/Pp9HKAkpISiouLGTJkCH5+5n1ia9asISIign79+p1c122IQreIiLQ1e0qrmOty8+aGAo5WNwAQ4GfjwvRYnI4URqd2xU+j38dXVWqufF5XBePua67Pc0LsABgyE6J7WtefiIicUT4P3d/+i4AOFzwVukVEpK2qbWhi0ZZisla7WZdX5q336NqJWQ47Vw5PJjosyMIO25CSLfDXs5ufp5wDQ53Q/zIIDreuLxER8Tmfhm6Px8MjjzzC008/TVVVFQCdO3fmrrvu4r//+7+9I9/tmUK3iIi0BztKKsh2uXl7QyGVdY0ABPn7MXFQHE5HCiN7dMFm0+j3cTXUwI4PYOPrsHc58PWPVYFhMGCquf1YymjQv6GISLvj09A9Z84c/vGPf/DQQw9x9tnmb3c/++wzHnzwQW666SYeffTRk++8jVDoFhGR9qS6vpH3NhWR5XKzuaDcW+8TE84sh50rhiURGRpoYYdtQHkBbJprLsB2ZG9zvUsPc+uxITMhKtmy9kRE5PTyaehOSEjgr3/9K5dddlmL+sKFC7nlllsoLCz86R23MQrdIiLSXn1VUE72mjze2VhETYO5b3VIoB+TByfgPCuFIUmRGv3+IYYB7tWQkwVb34b6qq9fsEHP8yDzJug/2dIWRUTk1Pk0dIeEhLB582b69u3bop6bm0tGRgY1NTU/veM2RqFbRETau4raBhZuLCTL5WZHSaW3PiAhglkOO1MyEgkPPqndRzuO+mOw/T0zgO9badYcN8PEP5l//ubHMP0SQ0SkzfFp6HY4HDgcDl544YUW9dtvv501a9bgcrl+esdtjEK3iIh0FIZhsMFdRpbLzfubi6lv9AAQFuTP5UMTcTpSSE/Q9lk/qiwPNs0zR7lj083avpXw/p2Q+Qtw/MLa/kRE5Cc50Ux4Ur+efuKJJ7j00ktZunQpo0aNAuDLL78kPz+fDz/88OQ6FhERkVbJZrMxPCWa4SnR3D8pnTfXF5DtcrP30DGyXG6yXG4ykqNwOuxMGpxAaJC/1S23Tl1S4Pzftaxtng+Hd8HBrc01w4DGOgjU/ukiIu3BSW8ZVlRUxIsvvsiOHTsA6N+/P7/4xS945JFH+Nvf/nZam2yNNNItIiIdmWEYrN57hCxXHou3ltDQZP44ERESwLThSTgddnrHdLa4yzagrhK2vgMJQyFuoFkrWAevT4NBV5qrnycM0/RzEZFW6Izt0/1tmzZtYtiwYTQ1NZ2uU7ZaCt0iIiKm0so6FqzPJ9vlpqCseV2XzJ7ROB12Lh4YR3CARr9P2Mf3wRffuoWve38zfA+eDp1jretLRERaONFM2Oo31K6srOSOO+4gJSWF0NBQRo8ezdq1a3/wPcuXL2fYsGEEBwfTu3dvXn311e8c8+KLL9KjRw9CQkJwOBysWbPGR59ARESkfeveOZhbzu/NynvG8s8bMrkoPRZ/Pxtr9h3h1/NyGPX4Jzy+aDt5h49Z3WrbMP5BuPYdGHQVBIRA6XZYch880x+yp8O2hdBYb3WXIiJyglp96L7xxhtZsmQJr732Gl999RUXXXQR48ePP+62ZPv27ePSSy9l7Nix5OTkcMcdd3DjjTeyePFi7zHz58/nzjvv5IEHHmDDhg0MGTKECRMmcPDgwTP1sURERNodPz8bY/p2528/G8FnvxvLHeP7EBcRwpFj9by8Yi9jnlzOtf9w8dGWYhqaPFa323r5+UPqWJj2d7h7J0x6DpIywWiCnR/BGz+Dp9Pgw99C8SaruxURkR/RqqeX19TU0LlzZxYuXMill17qrQ8fPpyJEyfyyCOPfOc9v/vd7/jggw/YsmWLtzZjxgyOHj3KRx99BJirr48cOZI///nPAHg8HpKTk7n99tu59957T6g3TS8XERH5cY1NHj7NLSXLlceKnaXeHbJiOgczY2Qy0zPtJEaFWttkW1G6EzZlmyugVxY312MHwSVPQsoo63oTEemAfLJ6+RVXXPGDrx89evSnnO5HNTY20tTUREhIy9U7Q0ND+eyzz773PV9++SXjx49vUZswYQJ33HEHAPX19axfv545c+Z4X/fz82P8+PF8+eWXx+2lrq6Ouro67/PKysrjHisiIiKmAH8/LkyP5cL0WPKPVDNvrZv5a/M5WFnHC5/s5s+f7mZsWgzOs+yM6RuDv58WDDuu7n3Nqedj/wf2fmru/b3jAzjwFYR1az6uqhRCo8A/0KpORUTkW35S6I6MjPzR13/2s5+dUkPf1rlzZ0aNGsXDDz9M//79iY2NZe7cuXz55Zf07t37e99TUlJCbGzLRUZiY2OpqKigpqaGsrIympqavveYb1Zi/z6PP/44Dz300Kl/KBERkQ4qOboT90zox6/H9WXJtgNkufL4Ys9hlu04yLIdB0mMCmVmZjJXj0gmJkLbZR2XfwD0udB8VB+BvcuhW5/m1z+8C/K+gMnPQ79Lj3saERE5M35S6H7llVd81cdxvfbaa9xwww0kJibi7+/PsGHDmDlzJuvXrz+jfcyZM4c777zT+7ywsJD09PQz2oOIiEh7EBTgx6WD47l0cDx7SquY63Lz5oYCCo/W8NTHO3lu6S4uTI/F6UhhdGpX/DT6fXydomHgt2YiNjVA4QY4VgpR9uZ6eQEEdjKPFxGRM+onhW4rpKamsmLFCo4dO0ZFRQXx8fFMnz6dXr16fe/xcXFxHDhwoEXtwIEDREREEBoair+/P/7+/t97TFxc3HH7CA4OJjg42Pu8oqLiFD6ViIiIAKR2D+d/JqVz94Q0Fm0pJmu1m3V5ZSzaUsKiLSX06NqJWQ47Vw5PJjosyOp2Wz//QPjVRnOkO25Qc33Zw7D135A2ETKugdQLzBFzERHxuVa/evk3wsLCiI+Pp6ysjMWLFzNlypTvPW7UqFEsW7asRW3JkiWMGmUuLhIUFMTw4cNbHOPxeFi2bJn3GBERETmzQgL9mTo0iTd/OZqP7jiXn41KoXNwAPsPV/PYhzs467Fl/HreRtbsO8JpXAO2ffIPhF5jmp8bBpTth6Z6c7ux7Kvg2QGw5H4ozbWsTRGRjuK0rl7uC4sXL8YwDNLS0ti9ezf33HMPISEhrFq1isDAQObMmUNhYSH/+te/AHPLsIEDB3Lrrbdyww038Mknn/CrX/2KDz74gAkTJgDmlmGzZ8/m5ZdfJjMzk+eee4433niDHTt2fOde7+PR6uUiIiK+VV3fyHubishyudlcUO6t94kJZ5bDzhXDkogM1WJhJ6x4M+Rkw1dvQPXh5nriCBjqhAFXmAuwiYjICTnRTNjqQ/cbb7zBnDlzKCgoIDo6mmnTpvHoo496F3W77rrr2L9/P8uXL/e+Z/ny5fzmN79h27ZtJCUlcd9993Hddde1OO+f//xnnnzySUpKSsjIyOCFF17A4XCccF8K3SIiImfOVwXlZK/J452NRdQ0mFuThgT6MXlwAs6zUhiSFInNpnu/T0hjPexaDBuzYNfH5v7fAAEh0G+SGcB7jjH3CxcRkeNqN6G7tVLoFhEROfMqahtYuLGQLJebHSXN23cOSIhglsPOlIxEwoN1r/IJqzoIm+ebAbx0e3M90g63roagMOt6ExFp5RS6fUyhW0RExDqGYbDBXUaWy837m4upb/QAEBbkz+VDE3E6UkhPiLC4yzbEMKBoo7n391cLID4DZr/b/PrupZDsgODOlrUoItLaKHT7mEK3iIhI63C0up431xeQ7XKz99Axbz0jOQqnw86kwQmEBmmq9AlrqP16y7Fk83llCTzT35x+/uvNEN7d2v5ERFqJE82Emn8lIiIibVpUpyBuPLcXPz+nJ6v3HiHLlcfirSXk5B8lJ/8oD7+/jWnDk3A67PSO0UjtjwoMaQ7cYO7xHZ1q7vH97cC95S1IHA5depzxFkVE2hKNdJ8kjXSLiIi0XqWVdSxYn0+2y01BWY23ntkzGqfDzsUD4wgO0Oj3CTMMqCkzgzdA9RF4qi94GqDHuZAxC9Kn6B5wEelQNL3cxxS6RUREWj+Px2DV7kNkrc5j2Y6DNHnMH3uiw4K4akQSszLtpHRVUPzJDu2CD++BvcuBr3+UDAqH9MvN1c/to0CryYtIO6fQ7WMK3SIiIm1LcXkN89fmM29NPiUVtd76uX264XTYGdc/lkB/Pws7bIOO5sPmeeb+30f2Nte79IQMJwyZ0XKquohIO6LQ7WMK3SIiIm1TY5OHT3NLyXLlsWJnKd/8JBTTOZgZI5OZnmknMSrU2ibbGsMA92rIeR22vgP1VV+/YINeY8wA3m8SBHWysksRkdNKodvHFLpFRETavvwj1cxb62b+2nwOVdUD4GeDsWkxOM+yM6ZvDP5+mib9k9Qfg23vmtuP7V/VXE+/HK7+p2VtiYicbgrdPqbQLSIi0n7UN3pYsu0AWa48vthz2FtPjAplZmYyV49IJiYixMIO26iy/bBpnhnAJzwG/Seb9aNucz/wITMhIsHSFkVETpZCt48pdIuIiLRPe0urmLvGzYL1BRytbgAgwM/GhemxOB0pjE7tip9Gv38ajwcwwO/rFeOX/xGWPw69xsLP3rGyMxGRk3aimVCrhYiIiIh8S6/u4fz3pemsnjOOZ6cPYURKFxo9Bou2lHDNP1xc8PRyXl6xh8NVdVa32nb4+TUHboDYAWAfbd7r/Y2KYnj/TihcDxoTEpF2RCPdJ0kj3SIiIh3HjpIKsl1u3t5QSGVdIwBB/n5MHBSH05HCyB5dsGmLrJ/OMJq3FvvsWVj6oPnn7v3Nvb8HT4fOsZa1JyLyQzS93McUukVERDqe6vpG3ttURJbLzeaCcm+9T0w4sxx2rhiWRGRooIUdtmFuF6z9f7D9PWj8eks3mz/0udAcEe97MQQEWdujiMi3KHT7mEK3iIhIx/ZVQTnZa/J4Z2MRNQ1NAIQE+jF5cALOs1IYkhSp0e+TUVsOW/5t7v1dsKa5HhoNg682R8Djh1jXn4jI1xS6fUyhW0RERAAqahtYuLGQLJebHSWV3vqAhAhmOexMyUgkPDjAwg7bsNKdsCnbXAG9sri5Hjuoefp5WFfr+hORDk2h28cUukVEROTbDMNgg7uMLJeb9zcXU9/oASAsyJ/LhybidKSQnhBhcZdtVFMj7P3U3HpsxwfQZO6pjvMt6DPe2t5EpMNS6PYxhW4RERE5nqPV9by5voBsl5u9h4556xnJUTgddiYNTiA0yP8HziDHVX0EtrwFu5bAzLnNq6KvegaqD8OIG6BrqrU9ikiHoNDtYwrdIiIi8mMMw2D13iNkufJYvLWEhibzx66IkACmDU/C6bDTO6azxV22A02N8Gw6VB2A6a9D/8lWdyQiHcCJZkLdYCQiIiLiIzabjVGpXRmV2pXSyjoWrM8n2+WmoKyGVz7fzyuf7yezZzROh52LB8YRHKDR75Nis8Hk52HrO9BnQnN91dNQvAkyroHUC8BfP/qKyJmnke6TpJFuERERORkej8Gq3YfIWp3Hsh0HafKYP4pFhwVx1YgkZmXaSekaZnGX7YDHAy8MgaNu83l4HAyZbm4/1j3N2t5EpF3Q9HIfU+gWERGRU1VcXsP8tfnMW5NPSUWtt35un244HXbG9Y8l0N/Pwg7buOLN5tZjX71h3u/9jcQRMNQJA66A0CjL2hORtk2h28cUukVEROR0aWzy8GluKVmuPFbsLOWbn85iOgczY2Qy0zPtJEaFWttkW9ZYD7sWmwF852IwzH3VCQiBfpPM7cd6nd+8KJuIyAlQ6PYxhW4RERHxhfwj1cxb62b+2nwOVZlbY/nZYGxaDM6z7IzpG4O/n83iLtuwqoOw+Q1z+7GD25rrEYkwZAacdw8E6hccIvLjFLp9TKFbREREfKm+0cOSbQfIcuXxxZ7mqdGJUaHMzEzm6hHJxESEWNhhG2cYUJwDG7PgqwVQexS69IBf5ZgLs4G5KroWXxOR41Do9jGFbhERETlT9pZWMXeNmwXrCzha3QBAgJ+NC9NjcTpSGJ3aFT+Nfp+8xjrI/RAMDwyc1lx7YSj0OBcm/hFCu1jbo4i0OgrdPqbQLSIiImdabUMTi7YUk7Xazbq8Mm+9R9dOzMy0c+XwJLqGB1vYYTuS+xHMnQ6dE+A3W5rv966rhGDtrS4iCt0+p9AtIiIiVsotqSTblce/NxRSWdcIQJC/HxMHxeF0pDCyRxdsNo1+nzTDgIJ1UHUA+k8ya02N8OwA6NbHXHwtfQoEaXs3kY5KodvHFLpFRESkNaiub+S9TUVkudxsLij31nvHhON02LliWBKRoYEWdtiO5K+Ff1wIfP3jc1A4pF9ubj9mH9V8L7iIdAgK3T6m0C0iIiKtzVcF5WSvyeOdjUXUNJjbYoUE+jF5cALOs1IYkhSp0e9TdTQfNs8ztx87sre53qUnZDjNFdCjkq3rT0TOGIVuH1PoFhERkdaqoraBhRsLyXK52VFS6a0PSIhglsPOlIxEwoO1KvcpMQxwr4ac12HrO1Bf9fULNug1BjKugX6XQlAnK7sUER9S6PYxhW4RERFp7QzDYIO7jCyXm/c3F1Pf6AEgLMify4cm4nSkkJ4QYXGX7UD9Mdj2rrn39/5VzfXgCDj713De3db1JiI+o9DtYwrdIiIi0pYcra7nzfUFZLvc7D10zFvPSI7C6bAzaXACoUH+FnbYTpTth5y5sCkbjrrhokdg9O3ma/XV5n7gEQlWdigip4lCt48pdIuIiEhbZBgGq/ceIcuVx+KtJTQ0mT8KRoQEMG14Ek6Hnd4x2hLrlHk8kPcZxKRDWDezljMXFt4Cw2bD5OcsbU9ETt2JZkLdzCMiIiLSgdhsNkaldmVUaldKK+tYsD6fbJebgrIaXvl8P698vp/MntE4HXYuHhhHcIBGv0+Knx/0PK9lrWQzGB6ISGyuNdbBgS2QMEyrn4u0UxrpPkka6RYREZH2wuMxWLX7EFmr81i24yBNHvPHw+iwIK4akcSsTDspXbUf9WlxeA+ERDaPfm99GxZcB937m3t/D54OnWMtbVFETsyJZkK/M9jTT9bU1MR9991Hz549CQ0NJTU1lYcffpgf+j3Bddddh81m+85jwIAB3mMefPDB77zer1+/M/GRRERERFodPz8bY/p2528/G8FnvxvLHeP7EBcRwpFj9by8Yi9jnlzOtf9w8dGWYhqaPFa327Z1TW0O3ADlBRAQAqXbYcl98Ex/yJ5uLszWWG9dnyJy2rTq6eV/+tOfeOmll/jnP//JgAEDWLduHddffz2RkZH86le/+t73PP/88/zxj3/0Pm9sbGTIkCFcddVVLY4bMGAAS5cu9T4PCGjV/xQiIiIiZ0R8ZCh3jO/LbWN782luKVmuPFbsLGXVrkOs2nWImM7BzBiZzPRMO4lRoVa32/aNvh2GXmuOeOdkQcFa2PmR+QiNhsFXm/t/xw+2ulMROUmtOml+8cUXTJkyhUsvvRSAHj16MHfuXNasWXPc90RGRhIZGel9/s4771BWVsb111/f4riAgADi4uJ807iIiIhIGxfg78eF6bFcmB5L/pFq5q11M39tPgcr63jhk938+dPdjE2LwXmWnTF9Y/D30/3IJy00CkZcbz5Kd5rhe9M8qCoB11/NR+wgGOqEQVdDWFerOxaRn6BVTy8fPXo0y5YtY+fOnQBs2rSJzz77jIkTJ57wOf7xj38wfvx4UlJSWtR37dpFQkICvXr1wul04na7f/A8dXV1VFRUeB+VlZU//QOJiIiItEHJ0Z24Z0I/vrh3HC/OGsbo1K54DFi24yA3vLqO8574lD9/souDFbVWt9r2de8LFz4Ev9kKzjch/XLwD4IDX8FH98LTabBridVdishP0KoXUvN4PPz+97/niSeewN/fn6amJh599FHmzJlzQu8vKirCbreTnZ3N1Vdf7a0vWrSIqqoq0tLSKC4u5qGHHqKwsJAtW7bQufP3b5Hx4IMP8tBDD32nroXUREREpCPaW1rF3DVuFqwv4Gh1AwABfjYuTI/F6UhhdGpX/DT6fXpUH4Etb8HG1+Hgdrg7F0K7mK/lr4GgcIhNt7ZHkQ6oXezTPW/ePO655x6efPJJBgwYQE5ODnfccQfPPPMMs2fP/tH3P/744zz99NMUFRURFBR03OOOHj1KSkoKzzzzDD//+c+/95i6ujrq6uq8zwsLC0lPT1foFhERkQ6ttqGJRVuKyVrtZl1embfeo2snZmbauXJ4El3Dgy3ssJ0pL4TIb2059v/GQeE6uPwlc/VzETlj2sU+3ffccw/33nsvM2bMAGDQoEHk5eXx+OOP/2joNgyD//u//+Paa6/9wcANEBUVRd++fdm9e/dxjwkODiY4uPkbRkVFxU/4JCIiIiLtU0igP1OHJjF1aBK5JZVku/L494ZC9h+u5vFFO3j6451MHBSH05HCyB5dsGkv6lMT+R97fHeOg4BQ6D2+ub7/M2iogV5jwb9V/7gv0iG06v8Lq6ur8fNredu5v78/Hs+Pb1WxYsUKdu/efdyR62+rqqpiz549XHvttSfdq4iIiEhHlxbXmYemDOR3E/vx3qYislxuNheUszCniIU5RfSOCcfpsHPFsCQiQwOtbrftCwiGGVlQVwXB4c31Tx+HvM+gc7y573eG07xXXEQs0aoXUps8eTKPPvooH3zwAfv37+ftt9/mmWeeYerUqd5j5syZw89+9rPvvPcf//gHDoeDgQMHfue1u+++mxUrVrB//36++OILpk6dir+/PzNnzvTp5xERERHpCDoFBTB9pJ13bzuH9247h5mZyYQG+rP7YBUPvbcNx2NLuWfBJja6y2jFdzq2Hd8O3B6Pub1YaDRUFsPnz8GLI+Hv42Hd/0HNUau6FOmwWvU93ZWVldx33328/fbbHDx4kISEBGbOnMn999/vnTJ+3XXXsX//fpYvX+59X3l5OfHx8Tz//PPcdNNN3znvjBkzWLlyJYcPH6Z79+6cc845PProo6Smpp5wbyc6f19EREREoKK2gYUbC8lyudlR0rwLTHp8BM6z7EzJSCQ8uFVPwmxbGuvNvb5zsmHXx2A0mfWAEOg3ydx+rOcY8PO3tk+RNqxdLKTWmil0i4iIiPx0hmGwwV1GlsvN+5uLqW80bxsMC/Ln8qGJzHLYGZAQaXGX7UzlAfjqDdiYBaXbm+sRiTBkprkAW9cTH3wSEZNCt48pdIuIiIicmqPV9by5voBsl5u9h4556xnJUTgddiYNTiA0SCOxp41hQNFGyMmCrxZAbblZDwqHe3ZDYKi1/Ym0MQrdPqbQLSIiInJ6GIbB6r1HyHLlsXhrCQ1N5o+nESEBTBuehNNhp3dMZ4u7bGcaaiH3Q3P6eUQ8XPa/Zt0wYNlD5srnPc4Fv1a9BJSIpRS6fUyhW0REROT0K62sY8H6fLJdbgrKarz1zJ7ROB12Lh4YR3CARr9PK4+nOVwXbYS/nQ/+wXB3LoR2sbQ1kdasXezTLSIiIiIdS/fOwdxyfm9uPi+VVbsPkbU6j2U7DrJm3xHW7DtCdFgQV41IYlamnZSuYVa32z58ezQ7OAKGXwfYWgbuD+6CxOGQPgWC9O8u8lNopPskaaRbRERE5MwoLq9h/tp85q3Jp6Si1ls/t083nA474/rHEuivadA+c3AH/MVh/jkoHNIvN1c/t48Cm83S1kSspOnlPqbQLSIiInJmNTZ5+DS3lCxXHit2lvLNT7ExnYOZMTKZ6Zl2EqO0GNhpV1UKG1417/8+sre53qUnZDhhyAyISrasPRGrKHT7mEK3iIiIiHXyj1Qzb62b+WvzOVRVD4CfDcamxeA8y86YvjH4+2kU9rQyDHCvhpzXYes7UF/19Qs26DUGMq6B/pO0Crp0GArdPqbQLSIiImK9+kYPS7YdIMuVxxd7DnvriVGhzMxM5uoRycREhFjYYTtVfwy2vWtuP7Z/VXM9OAIGXgHDfmbeAy7Sjil0+5hCt4iIiEjrsre0irlr3CxYX8DR6gYAAvxsXJgei9ORwujUrvhp9Pv0K9sPOXPN6eflbrM28ka49GlL2xLxNYVuH1PoFhEREWmdahuaWLSlmKzVbtbllXnrPbp2YmamnSuHJ9E1PNjCDtspjwfyPjPDt+O/IGGoWXevhpVPwYjrod+l1vYochopdPuYQreIiIhI65dbUkm2K49/byiksq4RgCB/PyYOisPpSGFkjy7YtAK3by28FTa+DkOvgSkvmrVvIoj+7aUNU+j2MYVuERERkbajur6R9zYVkeVys7mg3FvvHROO02HnimFJRIYGWthhO3Z4jzn6nXYJJH19n3fRRnj7l+bWY4Ouhs6x1vYochIUun1MoVtERESkbfqqoJzsNXm8s7GImoYmAEIC/Zg8OIFZDjsZyVEa/fa1D38La142/2zzhz4XQcYs6HsxBARZ25vICVLo9jGFbhEREZG2raK2gYUbC8lyudlRUumtp8dH4DzLzpSMRMKDAyzssB2rOQpb3zZXPy9Y21wPjYbBV5v7f8cPtqw9kROh0O1jCt0iIiIi7YNhGGxwHyXLlcf7m4upb/QAEBbkz+VDE5nlsDMgIdLiLtux0p1m+N40D6pKmuuxg76efn4VhHWzrj+R41Do9jGFbhEREZH252h1PW+uLyDb5WbvoWPeekZyFE6HnUmDEwgN8reww3asqRH2fmoG8B0fQFO9WfcLMKedj/1viE23tkeRb1Ho9jGFbhEREZH2yzAMVu89QpYrj8VbS2hoMn9kjggJYNrwJJwOO71jOlvcZTtWfQS2vGUG8KKNZu2W1RDT3/xzQy0EhljXnwgK3T6n0C0iIiLSMZRW1rFgfT7ZLjcFZTXeembPaJwOOxcPjCM4QKPfPnNgG+z5BEbf1lx78wZzVfQJj0GPs63rTTq0E82EWhlCREREROQHdO8czC3n9+bm81JZtfsQWavzWLbjIGv2HWHNviNEhwVx1YgkZmXaSekaZnW77U9sestp5Q01sPNjqK+EoE7N9ZoyCOoM/oo40rpopPskaaRbREREpOMqLq9h/tp85q3Jp6Si1ls/t083nA474/rHEujvZ2GH7dyxQ7DzI3OV82+2d3vnVtizDAZPN+vd+1rbo7R7ml7uYwrdIiIiItLY5OHT3FKyXHms2FnKNz9Zx3QOZsbIZKZn2kmMCrW2yY7A0wQvZMBRd3MtaaQZvgdeASFafV5OP4VuH1PoFhEREZFvyz9Szby1buavzedQlbnytp8NxqbF4DzLzpi+Mfj72Szush1rrIOdi83F13YtAaPJrAeEQP/JkDELeo4BP91/L6eHQrePKXSLiIiIyPepb/SwZNsBslx5fLHnsLeeGBXKzMxkrh6RTEyEVt72qcoDsHm+GcBLdzTXI5JgyAwzgHdNta4/aRcUun1MoVtEREREfsze0irmrnGzYH0BR6sbAAjws3FheixORwqjU7vip9Fv3zEMKNoAOdnw1QKoLW9+zT4afvYOBARb1p60bQrdPqbQLSIiIiInqrahiUVbisla7WZdXpm33qNrJ2Zm2rlyeBJdwxX+fKqhFnI/NEe/93wCKWfDde83v35gK3TvD35aAE9OjEK3jyl0i4iIiMjJyC2pJNuVx783FFJZ1whAkL8fEwfF4XSkMLJHF2w2jX77VEWRucVY7ADzedVBeLofRCbCf62C0ChL25O2Qft0i4iIiIi0QmlxnXloykB+N7Ef720qIsvlZnNBOQtziliYU0TvmHCcDjtXDEsiMjTQ6nbbp4gE8/GNA1shKAzCurcM3Ps/g4Sh5msiJ0kj3SdJI90iIiIicrp8VVBO9po83tlYRE2Duep2SKAfkwcnMMthJyM5SqPfvtZQY46Af7PAWk0ZPJUG/oEw4HJz+zH7qOZ9waXD0/RyH1PoFhEREZHTraK2gYUbC8lyudlRUumtp8dH4DzLzpSMRMKDNVn1jCjaCAuuh7J9zbUuPc3wPWQGRCVb15u0CgrdPqbQLSIiIiK+YhgGG9xHyXLl8f7mYuobPQCEBflz+dBEZjnsDEiItLjLDsAwwP2lufja1negvurrF2zQawxkXAP9J0FgqJVdikUUun1MoVtEREREzoSj1fW8ub6A7DVu9pYe89YzkqNwOuxMGpxAaJC/hR12EHVVsP1dc/ux/aua68ERMPAKcwQ8aaSmn3cgCt0+ptAtIiIiImeSYRis3nuELFcei7eW0NBk/hgfERLAtOFJOB12esd0trjLDuLIPtg0zwzg5e7m+rDZcNkL1vUlZ5RCt48pdIuIiIiIVUor61iwPp+5a9zkH6nx1jN7RuN02Ll4YBzBARr99jmPxxz1zsmGbQth6kswYKr5WkURuFdD2iUQGGJtn+ITCt0+ptAtIiIiIlbzeAxW7T5E1uo8lu04SJPH/NE+OiyIq4YnMTPTTo9u2u7qjKitgIAQCAgyn698Ej55BPpeDLPmW9ub+IT26RYRERERaef8/GyM6dudMX27U1xew/y1+cxbk09JRS0vr9zLyyv3cm6fbjgddsb1jyXQ38/qltuvkIiWz4MjISIR0qc016oOwub5MHg6hMec2f7EMq36/7qmpibuu+8+evbsSWhoKKmpqTz88MP80OD88uXLsdls33mUlJS0OO7FF1+kR48ehISE4HA4WLNmja8/joiIiIiIz8RHhnLH+L589rux/L+fjeD8tO7YbLBq1yFufn0DZ//xE575OJfCozU/fjI5dY5fwB1fwaCrmmub58PH/wNP94PsGbD9PWist65HOSNa9Uj3n/70J1566SX++c9/MmDAANatW8f1119PZGQkv/rVr37wvbm5uURENP+2KSam+TdJ8+fP58477+Svf/0rDoeD5557jgkTJpCb+//bu/PwKMtD/eP3ZJJMEkgIJGQlAxJkSQTZkiEoB6kgIFKpWLYpv7jVWtDWWmlBi9EqYK2H0mOVtmqxHgKh4SeuLGoQKVuCkLAIgUIkgZCEIFsgZJ33/JEyNgqYRCYzSb6f65rrYp553+Ge+Bi953mXA/W2AwAAAFoab7OXRsWFa1RcuI6eKlfa9gKt2H5UJ8oq9T/rD+lPnxzSiF5hsg+xanjPMJm9uNq2y3iZJf3HufXBXaXowVLhZ9LBNXWPgBCp7ySp/zQpsp/bosJ1PPqc7jvuuEPh4eF6/fXXnWMTJ06Uv7+/li5detl9NmzYoBEjRuj06dMKDg6+7DY2m00JCQn605/+JElyOByKiYnRI488otmzZzcoG+d0AwAAoKWoqnHoo30lSs3M15bDXzrHo4P9NTUxRpMGxygsiIt9NZvSA3X3/t61Qjr/H0fkRvStu/VY30lSuxD35UODNLQTevTh5UOHDlVGRoYOHjwoSdq1a5c2bdqksWPHfuu+/fv3V2RkpEaNGqXNmzc7x6uqqrRjxw6NHDnSOebl5aWRI0dq69atV3y/yspKnTt3zvkoKyv7Dp8MAAAAaD6+3l4a1y9Sy348ROt/OVw/HnadggN8VHjmol788KCGPr9eP126Q5v+dVIOh8euybUenXtJo34r/eJzaVq6FDdBMvtKxXuktbOl/+4lpdmlA2uk2mp3p8V35NGHl8+ePVvnzp1T7969ZTabVVtbq3nz5slut19xn8jISP35z3/W4MGDVVlZqddee0233HKLMjMzNXDgQJ08eVK1tbUKDw+vt194eLhyc3Ov+L4LFizQM888c80+GwAAAOAO3Tu315Pj4vTL23ppzd4ipW4r0Gf5p7Vmb7HW7C1Wt5AATU206u5BXRTS3uLuuK2b2VvqeVvdo/yUtPf/S9lLpaIcKff9use09LrX0WJ59OHlaWlpmjVrln7/+98rPj5eOTk5evTRR7Vw4UIlJyc3+H2GDx8uq9Wq//3f/9Xx48cVHR2tLVu2KCkpybnNr371K3366afKzMy87HtUVlaqsrLS+bywsFBxcXEcXg4AAIAW70BxmZZl5uutnYUqq6yRJPmavTS2b4Tstq5K6NZRJhPnfjebks/r7v2d96n04Ia6ci5Jny2RHDXSDROlgE5ujYhWcsuwWbNmafbs2ZoyZYokqW/fvsrPz9eCBQsaVboTExO1adMmSVJoaKjMZrNKSkrqbVNSUqKIiIgrvofFYpHF8tU3fefOnWvMRwEAAAA8Vq+IQD1z5w369djeem/XcaVmFmj3sbN6J+e43sk5rh5h7WW3WXXXwC7q4O/j7ritX3i8NHqeZBjSpS87HLXSpy9IZceldqFS/A/cmxEN5tHndJeXl8vLq35Es9ksh8PRqPfJyclRZGSkJMnX11eDBg1SRkaG83WHw6GMjIx6K98AAABAWxPg663JCVa9+/DNeu/hmzU1MUb+PmYdOnFez7y3T7b5H2tW+i5lF5y+6m18cY3859EFjhrppp9J3YZJvW7/ajzrVemjFKn0YPPnQ4N49Er3+PHjNW/ePFmtVsXHxys7O1sLFy7Ufffd59xmzpw5Kiws1JtvvilJWrRoka677jrFx8eroqJCr732mtavX68PP/zQuc9jjz2m5ORkDR48WImJiVq0aJEuXLige++9t9k/IwAAAOCJ+nbpoAVd+mnO7X30TnahUjMLlFtcpvQdx5S+45jiIoNkH2LVnf2j1d7i0bWidfC2SEN+Wve4xDCkrX+STh+RNi+SuiTU3XrshomSXwd3JcXXePS/HS+99JLmzp2rGTNm6MSJE4qKitJPfvITPfXUU85tioqKVFBQ4HxeVVWlX/7ylyosLFRAQID69eunjz/+WCNGjHBuM3nyZJWWluqpp55ScXGx+vfvr7Vr137j4moAAABAWxfk56PpSd30oyFdtbPgjFIz8/X+7iLtKzqnJ1ft1fwP9mvCgGhNs1kVH0XRa1aGQ7rtOSk7VfrXh9Kx7XWPtXOkPuPrCvh1w/99v3C4i0dfSM2TcZ9uAAAAtFVnyqu0cscxLcsqUF7pBed4/5hg2W1W3dEvSv6+FL1mVVYi7flHXQEv3f/VeFAX6cYpdQU8JNZ9+VqhhnZCSncTUboBAADQ1hmGoW15p5Sama91nxerurauWgT5eWvioC6y26zqERbo5pRtjGFIx3fWXf18T7pUcfar16xJUn97XQk3c0G874rS7WKUbgAAAOArpWWVSt9xVMuzCnT01EXneOJ1nWS3WTXmhghZvFn9blbVFdKB1VJOqnR4fd3h6B2s0s93SV4efU3tFoHS7WKUbgAAAOCbHA5D/zx0Uqnb8pWRe0K1jrq60amdr344qIumJlrVLbSdm1O2QeeOS7vSJL8gKeGBurGaKmnJGOn626Shj0i+/HNpDEq3i1G6AQAAgKsrPluhFduPKm17gYrOVjjHh10fKrvNqlv7hMvHzIqr2+x/X1phl9pHSL/4XDL/+zrbDgcr4Q1A6XYxSjcAAADQMDW1Dn1yoFSpmfn69GCpLjWQsECLJifEaEqiVdHB/u4N2RZVlUu5H0g1FdLA6XVjjlrplSFSTKLU/0eSdUj9+4XDidLtYpRuAAAAoPGOnipX2vYCrdh+VCfPV0mSvEzSiF5hsg+xanjPMJm9KHluk7dBevPOr5536l535fN+U6TgGLfF8kSUbhejdAMAAABNV1Xj0Ef7SpSama8th790jkcH+2tqYowmDY5RWJCfGxO2UYYhFWytu/ja529LVef//YJJ6j68bvW7zx2SD0cmULpdjNINAAAAXBt5pee1PKtA6TuO6Ux5tSTJ28ukUXHhstu6amhsiLxY/W5+leel/e/VFfAj//xq3BIk3XBX3e3HuiS02cPPKd0uRukGAAAArq2K6lqt2Vuk1G0F+iz/tHO8W0iApiZadfegLgppb3Fjwjbs1Bd1Vz/PWSadLfhqPOR66eZfSAPs7svmJpRuF6N0AwAAAK5zoLhMyzLz9dbOQpVV1kiSfM1eGts3QnZbVyV06yhTG11hdSuHQ8rfJGWnSvvekWouSiOfriveUt1tyAyH5NP6Tw2gdLsYpRsAAABwvfKqGr2367hSMwu0+9hZ53iPsPay26y6a2AXdfD3cWPCNqzinLTv7br7fAdG1I3tTpdWPy4NfVj6r1lujedqDe2E3s2YCQAAAAAaJcDXW5MTrJqcYNWeY2e1LCtfb2cf16ET5/XMe/v0u7W5Gt8vStNsVvWPCWb1uzn5BUkD/1/9sYNrpYozUm3NV2M1VXVj7cOaM53HYKW7iVjpBgAAANzjXEW13skuVGpmgXKLy5zjcZFBsg+x6s7+0WpvYX3RLRy1dbcd69xb6hBdN7b/PekfyXUr4gPs0vWjJW9ft8a8Fji83MUo3QAAAIB7GYahnQVnlJqZr/d3F6mqxiFJaudr1oQB0Zpmsyo+qoObU0If/kba8tJXzwNCpL6T6u7/HdnPfbm+I0q3i1G6AQAAAM9xprxKK3cc07KsAuWVXnCO948Jlt1m1R39ouTva3ZjwjbuRK60a1ndFdDPl3w1HtG37t7ffX8otQtxX74moHS7GKUbAAAA8DyGYWhb3imlZuZr3efFqq6tqztBft6aOKiL7DareoQFujllG1ZbIx1eL+UslQ6skWqr6sa9fKReY+ru/d1jlGT2/NMDKN0uRukGAAAAPFtpWaXSdxzV8qwCHT110TmeeF0n2W1WjbkhQhZvVr/dpvyUtGellJMqFeV8Nd4uTJr0ptQ1yW3RGoLS7WKUbgAAAKBlcDgM/fPQSaVuy1dG7gnVOuoqUKd2vvrhoC6ammhVt9B2bk7ZxpV8LuUsk3avkC6ekR4/KAV0cneqq6J0uxilGwAAAGh5is9WaMX2o0rbXqCisxXO8WHXh8pus+rWPuHyMXu5MWEbV1stFe2Wugxyd5JvRel2MUo3AAAA0HLV1Dr0yYFSpWbm69ODpbrUisICLZqcEKMpiVZFB/u7NyQ8GqXbxSjdAAAAQOtw9FS50rYXaMX2Yzp5vlKS5GWSRvQKk32IVcN7hsnsZXJzSngaSreLUboBAACA1qWqxqGP9pUoNTNfWw5/6RyPDvbXlIQYTU6IUViQnxsTwpNQul2M0g0AAAC0Xnml57U8q0DpO47pTHm1JMnby6RRceGy27pqaGyIvFj9btMo3S5G6QYAAABav4rqWq3ZW6TUbQX6LP+0c7xbSICmJlp196AuCmlvcWNCuAul28Uo3QAAAEDbcqC4TMsy8/XWzkKVVdZIknzNXhrbN0J2W1cldOsok4nV77aC0u1ilG4AAACgbSqvqtF7u44rNbNAu4+ddY73CGsvu82quwZ2UQd/HzcmRHOgdLsYpRsAAADAnmNntSwrX29nH9fF6lpJkp+Pl8b3i9I0m1X9Y4JZ/W6lKN0uRukGAAAAcMm5imq9k12o1MwC5RaXOcfjIoNkH2LVnf2j1d7i7caEuNYo3S5G6QYAAADwdYZhaGfBGaVm5uv93UWqqnFIktr5mjVhQLSm2ayKj+rg5pS4FijdLkbpBgAAAHA1Z8qrtHLHMS3LKlBe6QXneP+YYNltVt3RL0r+vmY3JsR3Qel2MUo3AAAAgIYwDEPb8k4pNTNf6z4vVnVtXQUL8vPWxEFdZLdZ1SMs0M0p0VgN7YScVAAAAAAALmQymZQUG6Kk2BCVllUqfcdRLc8q0NFTF7Vk8xEt2XxEidd1kt1m1ZgbImTxZvW7NaF0AwAAAEAz6Rxo0Yxbeuih/4rVPw+dVOq2fGXknlDWF6eU9cUpdWrnqx8O6qKpiVZ1C23n7ri4BijdAAAAANDMvLxMGt6zs4b37KzisxVasf2o0rYXqOhshf6yMU9/2ZinYdeHym6z6tY+4fIxe7k7MpqIc7qbiHO6AQAAAFxLNbUOfXKgVKmZ+fr0YKkuNbWwQIsmJ8RoSqJV0cH+7g0Jp4Z2Qo/+uqS2tlZz587VddddJ39/f8XGxurZZ5/V1b4neOuttzRq1Ch17txZQUFBSkpK0rp16+pt8/TTT8tkMtV79O7d29UfBwAAAACuyNvspVFx4Xrj3kRtnDVCM0fEKrS9RSfKKvXS+kMa9rv1uv+N7VqfW6JaB2unLYVHH17+u9/9TosXL9bf//53xcfH67PPPtO9996rDh066Gc/+9ll99m4caNGjRql+fPnKzg4WEuWLNH48eOVmZmpAQMGOLeLj4/Xxx9/7Hzu7e3RPwoAAAAAbUhMpwDNGt1bP7+1pz7aV6LUzHxtOfylMnJPKCP3hKKD/TUlIUaTE2IUFuTn7ri4Co9umlu2bNGdd96pcePGSZK6deum5cuXKysr64r7LFq0qN7z+fPn65133tF7771Xr3R7e3srIiKiwVkqKytVWVnpfF5WVtbgfQEAAACgKXy9vTSuX6TG9YtUXul5Lc8qUPqOYyo8c1H//dFB/THjXxoVFy67rauGxobIy8vk7sj4Go8+vHzo0KHKyMjQwYMHJUm7du3Spk2bNHbs2Aa/h8PhUFlZmTp16lRv/F//+peioqLUvXt32e12FRQUXPV9FixYoA4dOjgfcXFxjf9AAAAAANBE3Tu315Pj4rRtzq36w+QbNbhrR9U4DK3ZW6wfvZ6pEf+9QX/59LC+PF/57W+GZuPRF1JzOBx64okn9MILL8hsNqu2tlbz5s3TnDlzGvweL7zwgp5//nnl5uYqLCxMkrRmzRqdP39evXr1UlFRkZ555hkVFhZq7969Cgy8/E3pv77SXVhYqLi4OC6kBgAAAMBtDhSXaVlmvt7aWaiyyhpJkq/ZS2P7Rshu66qEbh1lMrH67QoNvZCaR5futLQ0zZo1S7///e8VHx+vnJwcPfroo1q4cKGSk5O/df9ly5bpxz/+sd555x2NHDnyitudOXNGXbt21cKFC3X//fc3KBtXLwcAAADgKcqravTeruNKzSzQ7mNnneM9wtrLbrPqroFd1MHfx40JW59WUbpjYmI0e/ZszZw50zn23HPPaenSpcrNzb3qvmlpabrvvvuUnp7uPCf8ahISEjRy5EgtWLCgQdko3QAAAAA80Z5jZ7UsK19vZx/XxepaSZKfj5fG94vSNJtV/WOCWf2+BlrFLcPKy8vl5VU/otlslsPhuOp+y5cv17333qvly5c3qHCfP39ehw8fVmRk5HfKCwAAAADu1rdLBy24q58yn7xVz94Zr94Rgaqodih9xzH94JUtGvc/m5Sama/z/z4cHa7l0VcvHz9+vObNmyer1ar4+HhlZ2dr4cKFuu+++5zbzJkzR4WFhXrzzTcl1R1SnpycrD/+8Y+y2WwqLi6WJPn7+6tDhw6SpMcff1zjx49X165ddfz4caWkpMhsNmvq1KnN/yEBAAAAwAWC/Hw0PambfjSkq3YWnFFqZr7e312kfUXn9OSqvZr/wX5NGBCtaTar4qM6uDtuq+XRh5eXlZVp7ty5WrVqlU6cOKGoqChNnTpVTz31lHx9fSVJ99xzj44cOaINGzZIkm655RZ9+umn33iv5ORkvfHGG5KkKVOmaOPGjfryyy/VuXNn3XzzzZo3b55iY2MbnI3DywEAAAC0NGfKq7RyxzEtyypQXukF53j/mGDZbVbd0S9K/r5mNyZsOVrFOd2ejNINAAAAoKUyDEPb8k4pNTNf6z4vVnVtXS0M8vPWxEFdZLdZ1SPs8nd2Qp2GdkKPPrwcAAAAAHDtmUwmJcWGKCk2RKVllUrfcVTLswp09NRFLdl8REs2H1HidZ1kt1k15oYIWbxZ/W4qSjcAAAAAtGGdAy2acUsPPfRfsfrnoZNK3ZavjNwTyvrilLK+OKVO7Xz1w0FdNDXRqm6h7dwdt8WhdAMAAAAA5OVl0vCenTW8Z2cVn63Qiu1Hlba9QEVnK/SXjXn6y8Y8Dbs+VHabVbf2CZeP2aNvhuUxOKe7iTinGwAAAEBrV1Pr0CcHSpWama9PD5bqUnsMC7RockKMpiRaFR3s796QbsKF1FyM0g0AAACgLTl6qlxp2wu0YvsxnTxfKUnyMkkjeoXJPsSq4T3DZPYyuTll86F0uxilGwAAAEBbVFXj0Ef7SpSama8th790jkcH+2tKQowmJ8QoLMjPjQmbB6XbxSjdAAAAANq6vNLzWp5VoPQdx3SmvFqS5O1l0qi4cNltXTU0NkRerXT1m9LtYpRuAAAAAKhTUV2rNXuLlLqtQJ/ln3aOdw0J0LREq+4e1EUh7S1uTHjtUbpdjNINAAAAAN90oLhMyzLz9dbOQpVV1kiSfM1eGts3QnZbVyV06yiTqeWvflO6XYzSDQAAAABXVl5Vo/d2HdeyzALtOnbWOd4jrL3sNqvuGtBFHQJ83Jjwu6F0uxilGwAAAAAaZs+xs1qWla+3s4/rYnWtJMnPx0vj+0Vpms2q/jHBLW71m9LtYpRuAAAAAGiccxXVeie7UKmZBcotLnOOx0UGyT7Eqjv7R6u9xduNCRuO0u1ilG4AAAAAaBrDMLSz4IxSM/P1/u4iVdU4JEntfM2aMCBa02xWxUd1cHPKq6N0uxilGwAAAAC+uzPlVVq545iWZRUor/SCc7x/TLBe/GE/9QgLdGO6K2toJ2wZ6/YAAAAAgFYpOMBXDwzrrvtvvk7b8k4pNTNf6z4vVm7xOXUO9HN3vO+M0g0AAAAAcDuTyaSk2BAlxYbo5PlK7Tl2Vh38W+7VzS/xcncAAAAAAAD+U2h7i0b0DnN3jGuC0g0AAAAAgItQugEAAAAAcBFKNwAAAAAALkLpBgAAAADARSjdAAAAAAC4CKUbAAAAAAAXoXQDAAAAAOAilG4AAAAAAFyE0g0AAAAAgItQugEAAAAAcBFKNwAAAAAALkLpBgAAAADARSjdAAAAAAC4CKUbAAAAAAAX8XZ3gJbK4XBIkoqKitycBAAAAADQ3C51wUvd8Eoo3U1UUlIiSUpMTHRzEgAAAACAu5SUlMhqtV7xdZNhGEYz5mk1ampqlJ2drfDwcHl5eeZR+mVlZYqLi9O+ffsUGBjo7jho45iP8BTMRXgS5iM8CfMRnqQlzEeHw6GSkhINGDBA3t5XXs+mdLdi586dU4cOHXT27FkFBQW5Ow7aOOYjPAVzEZ6E+QhPwnyEJ2lN89Ezl2gBAAAAAGgFKN0AAAAAALgIpbsVs1gsSklJkcVicXcUgPkIj8FchCdhPsKTMB/hSVrTfOScbgAAAAAAXISVbgAAAAAAXITSDQAAAACAi1C6AQAAAABwEUo3AAAAAAAuQulu4V5++WV169ZNfn5+stlsysrKuur26enp6t27t/z8/NS3b1+tXr26mZKiLWjMfHz11Vc1bNgwdezYUR07dtTIkSO/df4CDdXY342XpKWlyWQyacKECa4NiDalsfPxzJkzmjlzpiIjI2WxWNSzZ0/+e41rprHzcdGiRerVq5f8/f0VExOjX/ziF6qoqGimtGjNNm7cqPHjxysqKkomk0lvv/32t+6zYcMGDRw4UBaLRT169NAbb7zh8pzXAqW7BVuxYoUee+wxpaSkaOfOnbrxxhs1evRonThx4rLbb9myRVOnTtX999+v7OxsTZgwQRMmTNDevXubOTlao8bOxw0bNmjq1Kn65JNPtHXrVsXExOi2225TYWFhMydHa9PYuXjJkSNH9Pjjj2vYsGHNlBRtQWPnY1VVlUaNGqUjR45o5cqVOnDggF599VVFR0c3c3K0Ro2dj8uWLdPs2bOVkpKi/fv36/XXX9eKFSv0xBNPNHNytEYXLlzQjTfeqJdffrlB23/xxRcaN26cRowYoZycHD366KN64IEHtG7dOhcnvQYMtFiJiYnGzJkznc9ra2uNqKgoY8GCBZfdftKkSca4cePqjdlsNuMnP/mJS3OibWjsfPy6mpoaIzAw0Pj73//uqohoI5oyF2tqaoyhQ4car732mpGcnGzceeedzZAUbUFj5+PixYuN7t27G1VVVc0VEW1IY+fjzJkzje9973v1xh577DHjpptucmlOtD2SjFWrVl11m1/96ldGfHx8vbHJkycbo0ePdmGya4OV7haqqqpKO3bs0MiRI51jXl5eGjlypLZu3XrZfbZu3Vpve0kaPXr0FbcHGqop8/HrysvLVV1drU6dOrkqJtqAps7F3/72twoLC9P999/fHDHRRjRlPr777rtKSkrSzJkzFR4erhtuuEHz589XbW1tc8VGK9WU+Th06FDt2LHDeQh6Xl6eVq9erdtvv71ZMgP/qSV3GW93B0DTnDx5UrW1tQoPD683Hh4ertzc3MvuU1xcfNnti4uLXZYTbUNT5uPX/frXv1ZUVNQ3fpkCjdGUubhp0ya9/vrrysnJaYaEaEuaMh/z8vK0fv162e12rV69WocOHdKMGTNUXV2tlJSU5oiNVqop83HatGk6efKkbr75ZhmGoZqaGj300EMcXg63uFKXOXfunC5evCh/f383Jft2rHQDcLvnn39eaWlpWrVqlfz8/NwdB21IWVmZpk+frldffVWhoaHujgPI4XAoLCxMf/3rXzVo0CBNnjxZTz75pP785z+7OxraoA0bNmj+/Pl65ZVXtHPnTr311lv64IMP9Oyzz7o7GtCisNLdQoWGhspsNqukpKTeeElJiSIiIi67T0RERKO2BxqqKfPxkhdffFHPP/+8Pv74Y/Xr18+VMdEGNHYuHj58WEeOHNH48eOdYw6HQ5Lk7e2tAwcOKDY21rWh0Wo15XdjZGSkfHx8ZDabnWN9+vRRcXGxqqqq5Ovr69LMaL2aMh/nzp2r6dOn64EHHpAk9e3bVxcuXNCDDz6oJ598Ul5erN+h+VypywQFBXn0KrfESneL5evrq0GDBikjI8M55nA4lJGRoaSkpMvuk5SUVG97Sfroo4+uuD3QUE2Zj5L0wgsv6Nlnn9XatWs1ePDg5oiKVq6xc7F3797as2ePcnJynI/vf//7ziujxsTENGd8tDJN+d1400036dChQ84vfyTp4MGDioyMpHDjO2nKfCwvL/9Gsb70hZBhGK4LC1xGi+4y7r6SG5ouLS3NsFgsxhtvvGHs27fPePDBB43g4GCjuLjYMAzDmD59ujF79mzn9ps3bza8vb2NF1980di/f7+RkpJi+Pj4GHv27HHXR0Ar0tj5+Pzzzxu+vr7GypUrjaKiIuejrKzMXR8BrURj5+LXcfVyXEuNnY8FBQVGYGCg8fDDDxsHDhww3n//fSMsLMx47rnn3PUR0Io0dj6mpKQYgYGBxvLly428vDzjww8/NGJjY41Jkya56yOgFSkrKzOys7ON7OxsQ5KxcOFCIzs728jPzzcMwzBmz55tTJ8+3bl9Xl6eERAQYMyaNcvYv3+/8fLLLxtms9lYu3atuz5Cg1G6W7iXXnrJsFqthq+vr5GYmGhs27bN+drw4cON5OTketv/4x//MHr27Gn4+voa8fHxxgcffNDMidGaNWY+du3a1ZD0jUdKSkrzB0er09jfjf+J0o1rrbHzccuWLYbNZjMsFovRvXt3Y968eUZNTU0zp0Zr1Zj5WF1dbTz99NNGbGys4efnZ8TExBgzZswwTp8+3fzB0ep88sknl/1/wUtzMDk52Rg+fPg39unfv7/h6+trdO/e3ViyZEmz524Kk2FwbAgAAAAAAK7AOd0AAAAAALgIpRsAAAAAABehdAMAAAAA4CKUbgAAAAAAXITSDQAAAACAi1C6AQAAAABwEUo3AAAAAAAuQukGAAAAAMBFKN0AAMClTCaT3n77bXfHAADALSjdAAC0Yvfcc49MJtM3HmPGjHF3NAAA2gRvdwcAAACuNWbMGC1ZsqTemMVicVMaAADaFla6AQBo5SwWiyIiIuo9OnbsKKnu0O/Fixdr7Nix8vf3V/fu3bVy5cp6++/Zs0ff+9735O/vr5CQED344IM6f/58vW3+9re/KT4+XhaLRZGRkXr44YfrvX7y5En94Ac/UEBAgK6//nq9++67ztdOnz4tu92uzp07y9/fX9dff/03viQAAKClonQDANDGzZ07VxMnTtSuXbtkt9s1ZcoU7d+/X5J04cIFjR49Wh07dtT27duVnp6ujz/+uF6pXrx4sWbOnKkHH3xQe/bs0bvvvqsePXrU+zueeeYZTZo0Sbt379btt98uu92uU6dOOf/+ffv2ac2aNdq/f78WL16s0NDQ5vsBAADgQibDMAx3hwAAAK5xzz33aOnSpfLz86s3/sQTT+iJJ56QyWTSQw89pMWLFztfGzJkiAYOHKhXXnlFr776qn7961/r6NGjateunSRp9erVGj9+vI4fP67w8HBFR0fr3nvv1XPPPXfZDCaTSb/5zW/07LPPSqor8u3bt9eaNWs0ZswYff/731doaKj+9re/ueinAACA+3BONwAArdyIESPqlWpJ6tSpk/PPSUlJ9V5LSkpSTk6OJGn//v268cYbnYVbkm666SY5HA4dOHBAJpNJx48f16233nrVDP369XP+uV27dgoKCtKJEyckST/96U81ceJE7dy5U7fddpsmTJigoUOHNumzAgDgaSjdAAC0cu3atfvG4d7Xir+/f4O28/HxqffcZDLJ4XBIksaOHav8/HytXr1aH330kW699VbNnDlTL7744jXPCwBAc+OcbgAA2rht27Z943mfPn0kSX369NGuXbt04cIF5+ubN2+Wl5eXevXqpcDAQHXr1k0ZGRnfKUPnzp2VnJyspUuXatGiRfrrX//6nd4PAABPwUo3AACtXGVlpYqLi+uNeXt7Oy9Wlp6ersGDB+vmm29WamqqsrKy9Prrr0uS7Ha7UlJSlJycrKefflqlpaV65JFHNH36dIWHh0uSnn76aT300EMKCwvT2LFjVVZWps2bN+uRRx5pUL6nnnpKgwYNUnx8vCorK/X+++87Sz8AAC0dpRsAgFZu7dq1ioyMrDfWq1cv5ebmSqq7snhaWppmzJihyMhILV++XHFxcZKkgIAArVu3Tj//+c+VkJCggIAATZw4UQsXLnS+V3JysioqKvSHP/xBjz/+uEJDQ3X33Xc3OJ+vr6/mzJmjI0eOyN/fX8OGDVNaWto1+OQAALgfVy8HAKANM5lMWrVqlSZMmODuKAAAtEqc0w0AAAAAgItQugEAAAAAcBHO6QYAoA3jLDMAAFyLlW4AAAAAAFyE0g0AAAAAgItQugEAAAAAcBFKNwAAAAAALkLpBgAAAADARSjdAAAAAAC4CKUbAAAAAAAXoXQDAAAAAOAi/wewgq8Eo2U+MgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    ax.plot(epochs_seen, train_losses, label=\"train\")\n",
    "    ax.plot(epochs_seen, val_losses, linestyle='-.', label=\"val\")\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend()\n",
    "\n",
    "    ax1 = ax.twiny()\n",
    "    ax1.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax1.set_xlabel(\"Tokens Seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epoch_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epoch_tensor, track_token_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 控制随机性的解码策略\n",
    "\n",
    "主要介绍两个函数：`temperature scaling` 和 `top-k sampling`\n",
    "\n",
    "首先需要将模型转到cpu上，因为较小的模型在推理时不需要gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> generated text:  Every effort moves you,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(model=model,\n",
    "                                 idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "                                 max_new_tokens=25,\n",
    "                                 context_size=GPT_CONFIG_124M[\"context_length\"])\n",
    "print(\">> generated text: \", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Temperature scaling\n",
    "\n",
    "一种添加概率选择过程到向下一代标记生成任务的技术。</br>\n",
    "在前面的章节中，`generate_text_simple` 函数使用 `torch.argmax` 取最大概率，这一行为被称为贪婪解码 greedy decode。</br>\n",
    "为了使输出更加多样化，我们使用 **`从概率分布进行采样`** 来替换掉`argmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> inverse vocab (argmax):  forward\n",
      ">> inverse vocab (probability distribution):  toward\n"
     ]
    }
   ],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "print(\">> inverse vocab (argmax): \", inverse_vocab[next_token_id])\n",
    "\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(\">> inverse vocab (probability distribution): \", inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印出来的结果都是forward。`multinomial`是根据概率分数的比例来对下一个标记进行采样。因此在这里，forward仍然是最大的概率分数。在执行多次后我们统计一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> sampled 46 times: closer\n",
      ">> sampled 0 times: every\n",
      ">> sampled 0 times: effort\n",
      ">> sampled 578 times: forward\n",
      ">> sampled 4 times: inches\n",
      ">> sampled 0 times: moves\n",
      ">> sampled 0 times: pizza\n",
      ">> sampled 368 times: toward\n",
      ">> sampled 4 times: you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for _ in range(1000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))  \n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\">> sampled {freq} times: {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，与argmax不同，大部分情况下，会选择`forward`但是也有其他的可能。</br>\n",
    "我们可以通过一个叫做`temperature scaling`的概念来控制分布和选择过程。`temperature scaling`只是一个大于0的树。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temperature大于1会得到更加均匀的分布，小于1则会得到更尖锐的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, t) for t in temperatures]\n",
    "\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, T in enumerate(temperatures):\n",
    "    ax.bar(x + i * bar_width, scaled_probas[i], width=bar_width, label=f\"T={T}\")\n",
    "\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(list(vocab.keys()), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Top-k sampling\n",
    "\n",
    "上一节的温度采样和温度尺度可能会生成错误的结果，为了使结果更加准确，我们采用Tok-k采样。当结合概率采样和温度尺度时，可以提高文本生成结果。\n",
    "\n",
    "在top-k抽样中，我们可以将采样的标记限制在最可能的top-k标记中，并通过屏蔽其概率分数，从选择过程中排除所有其他标记，如下图所示。\n",
    "\n",
    "![1718954311719](image/从零开始构建LLM/1718954311719.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> top logits:  tensor([6.7500, 6.2800, 4.5100])\n",
      ">> top positions:  tensor([3, 7, 0])\n",
      ">> new logits:  tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n",
      ">> topk probas:  tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "# >> top k and position\n",
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\">> top logits: \", top_logits)\n",
    "print(\">> top positions: \", top_pos)\n",
    "\n",
    "# >> mask logits\n",
    "new_logits = torch.where(condition=next_token_logits < top_logits[-1],\n",
    "                         input=torch.tensor(float('-inf')),\n",
    "                         other=next_token_logits)\n",
    "print(\">> new logits: \", new_logits)\n",
    "\n",
    "# >> topk probas\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(\">> topk probas: \", topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此引入温度尺度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 修改文本生成函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        # >> context\n",
    "        idx_cond = idx if idx.size(0) <= context_size else idx[-context_size:]\n",
    "\n",
    "        # >> logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]  # last\n",
    "\n",
    "        # >> topk\n",
    "        if top_k is not None:\n",
    "            top_logits, top_pos = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]  # min value\n",
    "            # mask logits\n",
    "            logits = torch.where(condition=logits < min_val, input=torch.tensor(float('-inf')), other=logits)\n",
    "        \n",
    "        # >> temperature\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> generated text:  Every effort moves you.,\n",
      "\n",
      "\n",
      " the to.\"\n",
      " in it,. to,\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(model=model, idx=text_to_token_ids(\"Every effort moves you\", tokenizer), \n",
    "                     max_new_tokens=15, \n",
    "                     context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "                     top_k=25,\n",
    "                     temperature=1.4)\n",
    "print(\">> generated text: \", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 在PyTorch中加载和保存模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "model_path = os.path.join(\"save_model\", \"model.pth\")\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> model.eval()作用：**禁用dropout**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdamW使用历史数据来动态调整每个模型参数的学习速率。如果没有它，优化器就会重置，模型可能会学习次优，甚至不能正确收敛，这意味着它将失去生成连贯文本的能力。使用torch.save，我们可以保存模型和优化器的state_dict的内容如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = os.path.join(\"save_model\", \"model_and_optimizer.pth\")\n",
    "\n",
    "# save model and optimizer\n",
    "torch.save({\n",
    "    \"model_states_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "}, model_path)\n",
    "\n",
    "# load model and optimizer\n",
    "checkpoint = torch.load(model_path)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_states_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 从OpenAI中加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt_download.py\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def download_and_load_gpt2(model_size, models_dir):\n",
    "    # Validate model size\n",
    "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
    "    if model_size not in allowed_sizes:\n",
    "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
    "\n",
    "    # Define paths\n",
    "    model_dir = os.path.join(models_dir, model_size)\n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "    filenames = [\n",
    "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
    "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
    "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
    "    ]\n",
    "\n",
    "    # Download files\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    for filename in filenames:\n",
    "        file_url = os.path.join(base_url, model_size, filename)\n",
    "        file_path = os.path.join(model_dir, filename)\n",
    "        download_file(file_url, file_path)\n",
    "\n",
    "    # Load settings and params\n",
    "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
    "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "\n",
    "    return settings, params\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def download_file(url, destination):\n",
    "    # Send a GET request to download the file in streaming mode\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Get the total file size from headers, defaulting to 0 if not present\n",
    "    file_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "    # Check if file exists and has the same size\n",
    "    if os.path.exists(destination):\n",
    "        file_size_local = os.path.getsize(destination)\n",
    "        if file_size == file_size_local:\n",
    "            print(f\"File already exists and is up-to-date: {destination}\")\n",
    "            return\n",
    "\n",
    "    # Define the block size for reading the file\n",
    "    block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "    # Initialize the progress bar with total file size\n",
    "    progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
    "    with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "        # Open the destination file in binary write mode\n",
    "        with open(destination, \"wb\") as file:\n",
    "            # Iterate over the file data in chunks\n",
    "            for chunk in response.iter_content(block_size):\n",
    "                progress_bar.update(len(chunk))  # Update progress bar\n",
    "                file.write(chunk)  # Write the chunk to the file\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def download_file(url, destination):\n",
    "    # Send a GET request to download the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        # Get the total file size from headers, defaulting to 0 if not present\n",
    "        file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "\n",
    "        # Check if file exists and has the same size\n",
    "        if os.path.exists(destination):\n",
    "            file_size_local = os.path.getsize(destination)\n",
    "            if file_size == file_size_local:\n",
    "                print(f\"File already exists and is up-to-date: {destination}\")\n",
    "                return\n",
    "\n",
    "        # Define the block size for reading the file\n",
    "        block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "        # Initialize the progress bar with total file size\n",
    "        progress_bar_description = os.path.basename(url)  # Extract filename from URL\n",
    "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "            # Open the destination file in binary write mode\n",
    "            with open(destination, \"wb\") as file:\n",
    "                # Read the file in chunks and write to destination\n",
    "                while True:\n",
    "                    chunk = response.read(block_size)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    file.write(chunk)\n",
    "                    progress_bar.update(len(chunk))  # Update progress bar\n",
    "\n",
    "\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: models\\124M\\checkpoint\n",
      "File already exists and is up-to-date: models\\124M\\encoder.json\n",
      "File already exists and is up-to-date: models\\124M\\hparams.json\n",
      "File already exists and is up-to-date: models\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: models\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: models\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: models\\124M\\vocab.bpe\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb0 in position 16: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m settings, params \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_and_load_gpt2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m124M\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msettings: \u001b[39m\u001b[38;5;124m\"\u001b[39m, settings)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams: \u001b[39m\u001b[38;5;124m\"\u001b[39m, params)\n",
      "Cell \u001b[1;32mIn[107], line 38\u001b[0m, in \u001b[0;36mdownload_and_load_gpt2\u001b[1;34m(model_size, models_dir)\u001b[0m\n\u001b[0;32m     36\u001b[0m tf_ckpt_path \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mlatest_checkpoint(model_dir)\n\u001b[0;32m     37\u001b[0m settings \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhparams.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m---> 38\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mload_gpt2_params_from_tf_ckpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_ckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m settings, params\n",
      "Cell \u001b[1;32mIn[107], line 108\u001b[0m, in \u001b[0;36mload_gpt2_params_from_tf_ckpt\u001b[1;34m(ckpt_path, settings)\u001b[0m\n\u001b[0;32m    105\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblocks\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{} \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layer\u001b[39m\u001b[38;5;124m\"\u001b[39m])]}\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Iterate over each variable in the checkpoint\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# Load the variable and remove singleton dimensions\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     variable_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mload_variable(ckpt_path, name))\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# Process the variable name to extract relevant parts\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\training\\checkpoint_utils.py:141\u001b[0m, in \u001b[0;36mlist_variables\u001b[1;34m(ckpt_dir_or_file)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.list_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlist_variables\u001b[39m(ckpt_dir_or_file):\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Lists the checkpoint keys and shapes of variables in a checkpoint.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m  Checkpoint keys are paths in a checkpoint graph.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m    List of tuples `(key, shape)`.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m   reader \u001b[38;5;241m=\u001b[39m \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_dir_or_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m   variable_map \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mget_variable_to_shape_map()\n\u001b[0;32m    143\u001b[0m   names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(variable_map\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\training\\checkpoint_utils.py:76\u001b[0m, in \u001b[0;36mload_checkpoint\u001b[1;34m(ckpt_dir_or_file)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.load_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_checkpoint\u001b[39m(ckpt_dir_or_file):\n\u001b[0;32m     48\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns `CheckpointReader` for checkpoint found in `ckpt_dir_or_file`.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m  If `ckpt_dir_or_file` resolves to a directory with multiple checkpoints,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m      checkpoints.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m   filename \u001b[38;5;241m=\u001b[39m \u001b[43m_get_checkpoint_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_dir_or_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m file or checkpoints in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgiven directory \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m ckpt_dir_or_file)\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\training\\checkpoint_utils.py:479\u001b[0m, in \u001b[0;36m_get_checkpoint_filename\u001b[1;34m(ckpt_dir_or_file)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ckpt_dir_or_file, os\u001b[38;5;241m.\u001b[39mPathLike):\n\u001b[0;32m    478\u001b[0m   ckpt_dir_or_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(ckpt_dir_or_file)\n\u001b[1;32m--> 479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIsDirectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_dir_or_file\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    480\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m checkpoint_management\u001b[38;5;241m.\u001b[39mlatest_checkpoint(ckpt_dir_or_file)\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ckpt_dir_or_file\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:689\u001b[0m, in \u001b[0;36mis_directory\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgfile.IsDirectory\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_directory\u001b[39m(dirname):\n\u001b[0;32m    681\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns whether the path is a directory or not.\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \n\u001b[0;32m    683\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;124;03m    True, if the path is a directory; False otherwise\u001b[39;00m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 689\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mis_directory_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:703\u001b[0m, in \u001b[0;36mis_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns whether the path is a directory or not.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \n\u001b[0;32m    696\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;124;03m  True, if the path is a directory; False otherwise\u001b[39;00m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 703\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pywrap_file_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIsDirectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError:\n\u001b[0;32m    705\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb0 in position 16: invalid start byte"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(\"124M\", \"models\")\n",
    "print(\"settings: \", settings)\n",
    "print(\"params: \", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 上述代码出错，没有找到好的解决方案，因此使用其他方法来解决<br/>\n",
    "`pip install transformers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like gpt2 is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py:491\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    490\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[1;32m--> 491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py:1092\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1092\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connection.py:642\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    634\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    635\u001b[0m         (\n\u001b[0;32m    636\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSystem time is way off (before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRECENT_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). This will probably \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    639\u001b[0m         SystemTimeWarning,\n\u001b[0;32m    640\u001b[0m     )\n\u001b[1;32m--> 642\u001b[0m sock_and_verified \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39msocket\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connection.py:783\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[1;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[0;32m    781\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m normalized\n\u001b[1;32m--> 783\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\util\\ssl_.py:469\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 469\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\util\\ssl_.py:513\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m--> 513\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\ssl.py:501\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    496\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    498\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\ssl.py:1041\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1041\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\ssl.py:1310\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1309\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1310\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] 远程主机强迫关闭了一个现有的连接。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    842\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 844\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    847\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\util\\retry.py:470\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\util\\util.py:38\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py:491\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    490\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[1;32m--> 491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py:1092\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1092\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connection.py:642\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    634\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    635\u001b[0m         (\n\u001b[0;32m    636\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSystem time is way off (before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRECENT_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). This will probably \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    639\u001b[0m         SystemTimeWarning,\n\u001b[0;32m    640\u001b[0m     )\n\u001b[1;32m--> 642\u001b[0m sock_and_verified \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39msocket\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connection.py:783\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[1;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[0;32m    781\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m normalized\n\u001b[1;32m--> 783\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\util\\ssl_.py:469\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 469\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\util\\ssl_.py:513\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m--> 513\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\ssl.py:501\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    496\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    498\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\ssl.py:1041\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1041\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\ssl.py:1310\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1309\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1310\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:1238\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1238\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:1631\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent)\u001b[0m\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1631\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1639\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1640\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:385\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 385\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m    386\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    387\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    388\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    390\u001b[0m     )\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:408\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[1;32m--> 408\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    409\u001b[0m hf_raise_for_status(response)\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:67\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[1;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\requests\\adapters.py:501\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mConnectionError\u001b[0m: (ProtocolError('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None)), '(Request ID: d8006615-0d23-4919-a39e-a95a4d3fe7f7)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mLocalEntryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\transformers\\utils\\hub.py:389\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 389\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:1371\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[0;32m   1369\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1370\u001b[0m         \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n\u001b[1;32m-> 1371\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[0;32m   1372\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error happened while trying to locate the file on the Hub and we cannot find the requested files\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1373\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the local cache. Please check your connection and try again or make sure your Internet connection\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1374\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is on.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1375\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhead_call_error\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;66;03m# From now on, etag and commit_hash are not None.\u001b[39;00m\n",
      "\u001b[1;31mLocalEntryNotFoundError\u001b[0m: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline, set_seed\n\u001b[1;32m----> 2\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m set_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      4\u001b[0m generator(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, I\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm a language model,\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, num_return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\transformers\\pipelines\\__init__.py:782\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    779\u001b[0m                 adapter_config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m    780\u001b[0m                 model \u001b[38;5;241m=\u001b[39m adapter_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_model_name_or_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 782\u001b[0m     config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    783\u001b[0m         model, _from_pipeline\u001b[38;5;241m=\u001b[39mtask, code_revision\u001b[38;5;241m=\u001b[39mcode_revision, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs\n\u001b[0;32m    784\u001b[0m     )\n\u001b[0;32m    785\u001b[0m     hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39m_commit_hash\n\u001b[0;32m    787\u001b[0m custom_tasks \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1082\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1080\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1082\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m PretrainedConfig\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1084\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\transformers\\configuration_utils.py:644\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    642\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    643\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 644\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[0;32m    646\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\transformers\\configuration_utils.py:699\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    695\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME)\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[1;32m--> 699\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\transformers\\utils\\hub.py:429\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_missing_entries \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_connection_errors:\n\u001b[0;32m    428\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    430\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt connect to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to load this file, couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find it in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    431\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m cached files and it looks like \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not the path to a directory containing a file named\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    432\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCheckout your internet connection or see how to run the library in offline mode at\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    433\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    434\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_missing_entries:\n",
      "\u001b[1;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like gpt2 is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 由于网络限制，也报错了\n",
    "\n",
    "移步[./download_huggingface_model.ipynb](./download_huggingface_model.ipynb)下载模型，这个下载方式有很多，可以通过git/网站直接下载都可以，本人通过阅读(官方连接)[https://huggingface.co/docs/transformers/installation#offline-mode]之后进行下载的。<br/>\n",
    "这一部分就不用跟着书看了，只能自己摸索，大致流程也是跟着书一起的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> config: GPT2Config {\n",
      "  \"_name_or_path\": \"./gpt2/config.json\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.36.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Model, GPT2Tokenizer, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"./gpt2/config.json\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"./gpt2/\")\n",
    "model = GPT2Model.from_pretrained(\"./gpt2/\")\n",
    "\n",
    "print(\">> config:\", config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> tokenizer: GPT2Tokenizer(name_or_path='./gpt2/', vocab_size=50257, model_max_length=1024, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\">> tokenizer:\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> model: GPT2Model(\n",
      "  (wte): Embedding(50257, 768)\n",
      "  (wpe): Embedding(1024, 768)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (h): ModuleList(\n",
      "    (0-11): 12 x GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (act): NewGELUActivation()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\">> model:\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1719213912457](image/从零开始构建LLM/1719213912457.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453],\n",
       "        [ 0.0403, -0.0486,  0.0462,  ...,  0.0861,  0.0025,  0.0432],\n",
       "        [-0.1275,  0.0479,  0.1841,  ...,  0.0899, -0.1297, -0.0879],\n",
       "        ...,\n",
       "        [-0.0445, -0.0548,  0.0123,  ...,  0.1044,  0.0978, -0.0695],\n",
       "        [ 0.1860,  0.0167,  0.0461,  ..., -0.0963,  0.0785, -0.0225],\n",
       "        [ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model's block weight\n",
    "model.wte.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来将模型参数加载至我们的GPTModel中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()\n",
    "gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the OpenAI weights to the corresponding weight tensors in our GPTModel instance\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights_into_gpt(gpt, model):\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, model.wte.weight)\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, model.wpe.weight)\n",
    "\n",
    "    for b in range(len(model.h)):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            model.h[b].attn.c_attn.weight, 3, axis=-1\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].att.W_query.weight =  assign(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight =  assign(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            model.h[b].attn.c_attn.bias, 3, axis=-1\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(gpt.trf_blocks[b].att.W_query.bias, q_b.T)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(gpt.trf_blocks[b].att.W_key.bias, k_b.T)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(gpt.trf_blocks[b].att.W_value.bias, v_b.T)\n",
    "\n",
    "        \n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(gpt.trf_blocks[b].att.out_proj.weight, model.h[b].attn.c_proj.weight)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(gpt.trf_blocks[b].att.out_proj.bias, model.h[b].attn.c_proj.bias)\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layer[0].weight = assign(gpt.trf_blocks[b].ff.layer[0].weight, model.h[b].mlp.c_fc.weight.T)\n",
    "        gpt.trf_blocks[b].ff.layer[0].bias = assign(gpt.trf_blocks[b].ff.layer[0].bias, model.h[b].mlp.c_fc.bias)\n",
    "        gpt.trf_blocks[b].ff.layer[2].weight = assign(gpt.trf_blocks[b].ff.layer[2].weight, model.h[b].mlp.c_proj.weight.T)\n",
    "        gpt.trf_blocks[b].ff.layer[2].bias = assign(gpt.trf_blocks[b].ff.layer[2].bias, model.h[b].mlp.c_proj.bias)\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(gpt.trf_blocks[b].norm1.scale, model.h[b].ln_1.weight)\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(gpt.trf_blocks[b].norm1.shift, model.h[b].ln_1.bias)\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(gpt.trf_blocks[b].norm2.scale, model.h[b].ln_2.weight)\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(gpt.trf_blocks[b].norm2.shift, model.h[b].ln_2.bias)\n",
    "    \n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, model.ln_f.weight)\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, model.ln_f.bias)\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, model.wte.weight)\n",
    "    return gpt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuexiaolei\\AppData\\Local\\Temp\\ipykernel_22208\\1292868022.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.nn.Parameter(torch.tensor(right))\n"
     ]
    }
   ],
   "source": [
    "gpt = load_weights_into_gpt(gpt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'allowed_special': {'<|endoftext|>'}} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> generated text By MyGPT: \n",
      " hello, my name is_- that to is the. to and is not ( was can in a a \" is can\n",
      "., the,\n"
     ]
    }
   ],
   "source": [
    "tokenids = generate(gpt, idx=text_to_token_ids(\"hello, my name is\", tokenizer).to(device),\n",
    "         max_new_tokens=25, context_size=NEW_CONFIG['context_length'],\n",
    "         top_k=50, temperature=1.5)\n",
    "print(\">> generated text By MyGPT: \\n\", token_ids_to_text(tokenids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a timeageageageageageageageageageageageageageageageageageageageageageageageageage\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"./gpt2/\")\n",
    "model = GPT2Model.from_pretrained(\"./gpt2/\")\n",
    "\n",
    "input_text = \"Once upon a time\"\n",
    "\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "def generate_by_gpt2(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        # >> context\n",
    "        idx_cond = idx if idx.size(0) <= context_size else idx[-context_size:]\n",
    "\n",
    "        # >> logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits.last_hidden_state[:, -1, :]  # last\n",
    "\n",
    "        # >> topk\n",
    "        if top_k is not None:\n",
    "            top_logits, top_pos = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]  # min value\n",
    "            # mask logits\n",
    "            logits = torch.where(condition=logits < min_val, input=torch.tensor(float('-inf')), other=logits)\n",
    "        \n",
    "        # >> temperature\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n",
    "\n",
    "model.eval()\n",
    "\n",
    "generated_ids = generate_by_gpt2(model, idx=input_ids,\n",
    "         max_new_tokens=25, context_size=NEW_CONFIG['context_length'],\n",
    "         top_k=50, temperature=1.5)\n",
    "# 解码生成的文本\n",
    "generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> GPT2Model 与 GPTLMHeadModel不一样， GPT2Model主要用于获取模型的隐藏状态，而GPTLMHeadModel集成了GPT2Model并添加了语言建模的头部，使其能够进行文本生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> generated text: \n",
      " Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('./gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('./gpt2')\n",
    "\n",
    "text = \"Once upon a time\"\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "\n",
    "output = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\">> generated text: \\n\", generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 分类任务的微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.6.3\n",
      "numpy version: 1.23.5\n",
      "tiktoken version: 0.7.0\n",
      "torch version: 2.1.2\n",
      "tensorflow version: 2.16.1\n",
      "pandas version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\", # For OpenAI's pretrained weights\n",
    "        \"pandas\"      # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 不同类别的微调\n",
    "\n",
    "微调语言模型最常见的方法是**指令微调**和**分类微调**。<br/>\n",
    "\n",
    "* 分类微调与训练一个CNN相似，用于特定任务，属于监督学习范畴。但是使用LLM构建比生成式模型更加容易一些。\n",
    "* 指令微调能够做的事情能够多一些。\n",
    "\n",
    "微调流程如下：\n",
    "\n",
    "![1719279066942](image/从零开始构建LLM/1719279066942.png)\n",
    "\n",
    "## 6.2 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as sms_spam_collection\\SMSSpamCollection.tsv\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_file_path = os.path.join('data', 'SMSSpamCollection.tsv')\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# >> check label: not balanced\n",
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上述结果看，类别并不是平衡的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n",
    "\n",
    "train_df.to_csv(\"./data/train.csv\", index=None)\n",
    "validation_df.to_csv(\"./data/validation.csv\", index=None)\n",
    "test_df.to_csv(\"./data/test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 dataloader\n",
    "\n",
    "* 注意：文本长度不同，需要以下处理：\n",
    "    1. 将所有本文截断为数据集或批次中最短消息的长度\n",
    "    2. 将所有消息填充到数据集或批次中最长消息的长度\n",
    "* 本文采用第二种方式\n",
    "* 使用第二章的 `<|endoftext|>`进行处理\n",
    "\n",
    "![1719282711195](image/从零开始构建LLM/1719282711195.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> <|endoftext|>'s token ID is: [50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(\">> <|endoftext|>'s token ID is:\", tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 创建dataset与dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"./data/train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)\n",
    "\n",
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"./data/validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"./data/test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Input shape: torch.Size([8, 120])\n",
      ">> Target shape: torch.Size([8])\n",
      "\n",
      ">> Train: 130 training batches\n",
      ">> Validation: 19 validation batches\n",
      ">> Test: 38 test batches\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_loader)\n",
    "\n",
    "input_batch, target_batch = next(train_iter)\n",
    "print(\">> Input shape:\", input_batch.shape)\n",
    "print(\">> Target shape:\", target_batch.shape)\n",
    "print()\n",
    "print(f\">> Train: {len(train_loader)} training batches\")\n",
    "print(f\">> Validation: {len(val_loader)} validation batches\")\n",
    "print(f\">> Test: {len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 使用预训练权重初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuexiaolei\\AppData\\Local\\Temp\\ipykernel_22208\\1292868022.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.nn.Parameter(torch.tensor(right))\n"
     ]
    }
   ],
   "source": [
    "model = GPTModel(BASE_CONFIG)\n",
    "\n",
    "gpt_model = GPT2Model.from_pretrained(\"./gpt2\")\n",
    "\n",
    "model = load_weights_into_gpt(model, gpt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> generated text:  every effort moves you. the the the the the the the the the the the the the the\n"
     ]
    }
   ],
   "source": [
    "text = \"every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(model, text_to_token_ids(text, tokenizer), 15, BASE_CONFIG[\"context_length\"])\n",
    "\n",
    "print(\">> generated text: \", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 增加一个用于分类的头\n",
    "\n",
    "![1719284410394](image/从零开始构建LLM/1719284410394.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 从技术上来说，仅需要训练最后一层分类层即可<br/>\n",
    "然而，实验表明微调附加层可以显着提高性能<br/>\n",
    "因此，我们还使最后一个Trf块和将最后一个Trf块连接到输出层的LayerNorm块可训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Inputs: tensor([[5211,  345,  423,  640]])\n",
      ">> Inputs dimensions: torch.Size([1, 4])\n",
      ">> Outputs:\n",
      " tensor([[[-0.6233,  0.3664],\n",
      "         [-0.5076,  0.4399],\n",
      "         [-0.6472,  0.5222],\n",
      "         [-0.5264,  0.4531]]])\n",
      ">> Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\">> Inputs:\", inputs)\n",
    "print(\">> Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\">> Outputs:\\n\", outputs)\n",
    "print(\">> Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 计算分类损失和准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Last output token: tensor([[-0.5264,  0.4531]])\n",
      ">> Class label: 1\n"
     ]
    }
   ],
   "source": [
    "print(\">> Last output token:\", outputs[:, -1, :])\n",
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\">> Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token·\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Training accuracy: 48.75%\n",
      ">> Validation accuracy: 45.00%\n",
      ">> Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\">> Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\">> Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\">> Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.879\n",
      "Validation loss: 0.821\n",
      "Test loss: 0.774\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 使用标记数据进行微调\n",
    "\n",
    "![1719286267048](image/从零开始构建LLM/1719286267048.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.765, Val loss 0.806\n",
      "Ep 1 (Step 000050): Train loss 0.684, Val loss 0.684\n",
      "Ep 1 (Step 000100): Train loss 0.632, Val loss 0.659\n",
      "Training accuracy: 60.00% | Validation accuracy: 62.50%\n",
      "Ep 2 (Step 000150): Train loss 0.656, Val loss 0.644\n",
      "Ep 2 (Step 000200): Train loss 0.585, Val loss 0.581\n",
      "Ep 2 (Step 000250): Train loss 0.537, Val loss 0.526\n",
      "Training accuracy: 82.50% | Validation accuracy: 82.50%\n",
      "Ep 3 (Step 000300): Train loss 0.451, Val loss 0.448\n",
      "Ep 3 (Step 000350): Train loss 0.387, Val loss 0.379\n",
      "Training accuracy: 90.00% | Validation accuracy: 87.50%\n",
      "Ep 4 (Step 000400): Train loss 0.227, Val loss 0.337\n",
      "Ep 4 (Step 000450): Train loss 0.362, Val loss 0.280\n",
      "Ep 4 (Step 000500): Train loss 0.291, Val loss 0.272\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 5 (Step 000550): Train loss 0.326, Val loss 0.262\n",
      "Ep 5 (Step 000600): Train loss 0.422, Val loss 0.224\n",
      "Training accuracy: 87.50% | Validation accuracy: 92.50%\n",
      "Training completed in 13.16 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 88.94%\n",
      "Validation accuracy: 91.28%\n",
      "Test accuracy: 89.33%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[1]\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = os.path.join(\"save_model\", \"review_classifier.pth\")\n",
    "\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "model_state_dict = torch.load(model_path)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 指令微调\n",
    "\n",
    "![1719309589135](image/从零开始构建LLM/1719309589135.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 7.1 指令微调介绍\n",
    "\n",
    "功能概览\n",
    "\n",
    "![1719309666974](image/从零开始构建LLM/1719309666974.png)\n",
    "\n",
    "流程\n",
    "\n",
    "![1719309789448](image/从零开始构建LLM/1719309789448.png)\n",
    "\n",
    "## 7.2 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"./data/instruction-data.json\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': \"What is an antonym of 'complicated'?\",\n",
       " 'input': '',\n",
       " 'output': \"An antonym of 'complicated' is 'simple'.\"}"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM的输入由多种形式，下图展示了两种形式：Alpaca和Phi-3，本文使用Alpaca形式进行训练\n",
    "\n",
    "![1719373091773](image/从零开始构建LLM/1719373091773.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Training set length: 935\n",
      ">> Validation set length: 55\n",
      ">> Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\">> Training set length:\", len(train_data))\n",
    "print(\">> Validation set length:\", len(val_data))\n",
    "print(\">> Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 数据封装\n",
    "\n",
    "![1719380932620](image/从零开始构建LLM/1719380932620.png)\n",
    "\n",
    "![1719381496083](image/从零开始构建LLM/1719381496083.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        for entry in data:\n",
    "            instruction_plus_input = self.format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
    "    \n",
    "    def format_input(self, entry):\n",
    "        instruction_text = (\n",
    "            f\"Below is an instruction that describes a task. \"\n",
    "            f\"Write a response that appropriately completes the request.\"\n",
    "            f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "        )\n",
    "\n",
    "        input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "        return instruction_text + input_text\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encoded_texts[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100, allowed_max_length=None, device=\"cpu\"):\n",
    "    batch_max_length = max(len(entry)+1 for entry in batch)\n",
    "\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for entry in batch:\n",
    "        new_entry = entry.copy()\n",
    "        new_entry += [pad_token_id]\n",
    "\n",
    "        padded = new_entry + [pad_token_id] * (batch_max_length - len(new_entry))\n",
    "\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        \n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "        \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 创建dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 1024)\n",
       "  (wpe): Embedding(1024, 1024)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-23): 24 x GPT2Block(\n",
       "      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_model = GPT2Model.from_pretrained(\"./gpt2-medium\")\n",
    "gpt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuexiaolei\\AppData\\Local\\Temp\\ipykernel_22208\\1292868022.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.nn.Parameter(torch.tensor(right))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = load_weights_into_gpt(model, gpt_model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
