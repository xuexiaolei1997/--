{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 理解大语言模型 - Large Language Model (LLM)\n",
    "\n",
    "> 主要结构如下：\n",
    "从raw data中进行预训练，得出基础模型（这一部分可以了解一下元学习的概念），这个基础模型所拥有的基础能力为文本补全、短时任务的推理能力。</br>\n",
    "> 在基础模型之上，可以导入自己标记的数据进行训练，这一部分可以成为微调（finetune），得到自己的LLM，可以用于分类，总结，翻译，个人助理等任务。\n",
    "\n",
    "![1716275709784](image/从零开始构建LLM/1716275709784.png)\n",
    "\n",
    "> **Transformer** 结构概览</br>\n",
    "1、输入需要被翻译的文本</br>\n",
    "2、预处理文本</br>\n",
    "3、编码器将输入文本进行编码</br>\n",
    "4、将编码部分送入解码器</br>\n",
    "5、模型每次只完成一个单词的翻译</br>\n",
    "6、预处理文本</br>\n",
    "7、解码器生成一个单词</br>\n",
    "8、完成翻译</br>\n",
    "\n",
    "![1716275687724](image/从零开始构建LLM/1716275687724.png)\n",
    "\n",
    "> BERT与GPT区别：BERT更多的使用于文本填空，GPT则是预测下一个单词。\n",
    "\n",
    "![1716275758151](image/从零开始构建LLM/1716275758151.png)\n",
    "\n",
    "> **构建大模型步骤**</br>\n",
    "\n",
    "|阶段|子项|\n",
    "|---|---|\n",
    "|一|准备数据和样本|\n",
    "||实现注意力机制|\n",
    "||实现LLM结构|\n",
    "|二|训练|\n",
    "||模型评估|\n",
    "||加载预训练模型权重|\n",
    "|三|微调自己的模型|\n",
    "\n",
    "![1716275818354](image/从零开始构建LLM/1716275818354.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 文本数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 词嵌入\n",
    "词嵌入的根本目的是为了**将非数值数据转换为向量**，这样才能放入计算机进行运算。常见词嵌入的有**Word2Vec**。在GPT架构中，没有使用这一技术，GPT3的嵌入大小达到了12288维。其中，GPT将词嵌入作为训练模型，不断调整。也就是说，**GPT将词嵌入这一部分也进行训练**。\n",
    "\n",
    "![1716433691383](image/从零开始构建LLM/1716433691383.png)\n",
    "\n",
    "## 2.2 标记文本\n",
    "标记文本就是将文本进行拆分，拆分为单个单词后，对每个单词进行唯一映射。可以使用字典进行标记，将每个单词映射为token id，再使用token id进行词嵌入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Total number of character: 20479\n",
      ">> raw text: I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n",
      "\n",
      ">> preprocessed: ['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n",
      ">> length: 4690\n",
      "\n",
      ">> size of vocab after removed duplicate words: 1130\n",
      ">> vocab: front 20 items\n",
      "! 0\n",
      "\" 1\n",
      "' 2\n",
      "( 3\n",
      ") 4\n",
      ", 5\n",
      "-- 6\n",
      ". 7\n",
      ": 8\n",
      "; 9\n",
      "? 10\n",
      "A 11\n",
      "Ah 12\n",
      "Among 13\n",
      "And 14\n",
      "Are 15\n",
      "Arrt 16\n",
      "As 17\n",
      "At 18\n",
      "Be 19\n",
      "Begin 20\n"
     ]
    }
   ],
   "source": [
    "filepath = os.path.join('data', 'the-verdict.txt')\n",
    "assert os.path.exists(filepath), f\"{filepath} is not exists.\"\n",
    "with open(filepath) as f:\n",
    "    raw_text = f.read()\n",
    "print(\">> Total number of character:\", len(raw_text))\n",
    "print(\">> raw text:\", raw_text[:100])\n",
    "print()\n",
    "\n",
    "# split raw text\n",
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]  # remove empty string\n",
    "print(\">> preprocessed:\", preprocessed[:30])\n",
    "print(\">> length:\", len(preprocessed))\n",
    "print()\n",
    "\n",
    "# remove duplicate words\n",
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "print(\">> size of vocab after removed duplicate words:\", vocab_size)\n",
    "\n",
    "# create vocab\n",
    "vocab = {token:integer for integer,token in enumerate(all_words)}\n",
    "print(\">> vocab: front 20 items\")\n",
    "for tok, i in vocab.items():\n",
    "    if i > 20:\n",
    "        break\n",
    "    print(tok, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1716433945337](image/从零开始构建LLM/1716433945337.png)\n",
    "\n",
    "字典表的创建方式可以通过自己创建，通过创建后的字典表，可以实现文本与token id之间的互相转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> original text:  \"It's the last he painted, you know,\" \n",
      "           Mrs. Gisburn said with pardonable pride.\n",
      ">> encoded data: [1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n",
      ">> decoded data: \" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):  # our vocab\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}  # reverse k, v\n",
    "    \n",
    "    def encode(self, text):  # our text\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()  # remove empty string\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text\n",
    "\n",
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "print(\">> original text: \", text)\n",
    "\n",
    "ids = tokenizer.encode(text)\n",
    "print(\">> encoded data:\", ids)\n",
    "\n",
    "decoded_text = tokenizer.decode(ids)\n",
    "print(\">> decoded data:\", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1716434053588](image/从零开始构建LLM/1716434053588.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 特殊处理\n",
    "正如一般的数据预处理流程，文本中的异常数据也应当注意。当上述字典表覆盖不全面时，针对不在字典表中的字符就需要特殊处理，并且不同句子之间，也需要分割符。</br>\n",
    "\n",
    "**为未知单词加入一些特殊标记**是非常有用的。作用如下：\n",
    "\n",
    "* 使用特殊标记来帮助 LLM 提供额外的上下文\n",
    "* 注：一些特殊标记如下<br/>\n",
    "    1. [BOS] Beginning of sequence. 文本开始<br/>\n",
    "    2. [EOS] end of sequence. 文本结束<br/>\n",
    "    3. [PAD] padding. 使训练文本长度统一<br/>\n",
    "    [UNK] 未知字符，不在字典表中<br/>\n",
    "* GPT-2中仅使用`<|endoftext|>`减少复杂性，`<|endoftext|>`与`[EOS]`用法类似。GPT-2同时使用`<|endoftext|>`来进行PAD操作。\n",
    "* 对于未知单词，GPT-2未使用[UNK]进行替代，而是使用字节对编码-(byte-pair encoding, BPE)将单词进行分解。\n",
    "\n",
    "因此在上述V1版本上，我们需要进行改进，将未知字符与分割符加入字典表中：\n",
    "\n",
    "`all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])`\n",
    "\n",
    "![1716455910828](image/从零开始构建LLM/1716455910828.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> size of vocab after removed duplicate words: 1161\n",
      ">> vocab: last 5 items\n",
      "('younger', 1156)\n",
      "('your', 1157)\n",
      "('yourself', 1158)\n",
      "('<|endoftext|>', 1159)\n",
      "('<|unk|>', 1160)\n"
     ]
    }
   ],
   "source": [
    "# preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)  # pre version\n",
    "preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "\n",
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(\">> size of vocab after removed duplicate words:\", vocab_size)\n",
    "\n",
    "print(\">> vocab: last 5 items\")\n",
    "for i, tok in enumerate(list(vocab.items())[-5:]):\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> input text: Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n",
      ">> encoded data: [1160, 5, 362, 1155, 642, 1000, 10, 1159, 57, 1013, 981, 1009, 738, 1013, 1160, 7]\n",
      ">> decoded data: <|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int \n",
    "            else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text\n",
    "\n",
    "\n",
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "\n",
    "print(\">> input text:\", text)\n",
    "\n",
    "ids = tokenizer.encode(text)\n",
    "print(\">> encoded data:\", ids)\n",
    "\n",
    "decoded_text = tokenizer.decode(ids)\n",
    "print(\">> decoded data:\", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 字节对编码\n",
    "\n",
    "`pip install tiktoken`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simpleNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tiktoken in d:\\python\\python39\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\python\\python39\\lib\\site-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\python\\python39\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\python\\python39\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python\\python39\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\python\\python39\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\python39\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> encoded data: [15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 617, 34680, 27271, 13]\n",
      ">> decoded data: Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\"\n",
    "\n",
    "ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(\">> encoded data:\", ids)\n",
    "\n",
    "decoded_text = tokenizer.decode(ids)\n",
    "print(\">> decoded data:\", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BPE会将未知单词拆分成独立个体的单词\n",
    "\n",
    "![1716778401378](image/从零开始构建LLM/1716778401378.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 使用滑窗进行数据采样\n",
    "\n",
    "![1716778580547](image/从零开始构建LLM/1716778580547.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> x: [290, 4920, 2241, 287]\n",
      ">> y: [4920, 2241, 287, 257]\n",
      "\n",
      ">> tokenizer encode in one context:\n",
      ">> [290] --> 4920\n",
      ">> [290, 4920] --> 2241\n",
      ">> [290, 4920, 2241] --> 287\n",
      ">> [290, 4920, 2241, 287] --> 257\n",
      "\n",
      ">> tokenizer decode in one context:\n",
      ">>  and -->  established\n",
      ">>  and established -->  himself\n",
      ">>  and established himself -->  in\n",
      ">>  and established himself in -->  a\n"
     ]
    }
   ],
   "source": [
    "enc_text = tokenizer.encode(raw_text)\n",
    "enc_sample = enc_text[50:]\n",
    "\n",
    "context_size = 4\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size + 1]\n",
    "print(f\">> x: {x}\")\n",
    "print(f\">> y: {y}\")\n",
    "print()\n",
    "\n",
    "print(\">> tokenizer encode in one context:\")\n",
    "for i in range(1, context_size + 1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(f\">> {context} --> {desired}\")\n",
    "print()\n",
    "\n",
    "print(\">> tokenizer decode in one context:\")\n",
    "for i in range(1, context_size + 1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(f\">> {tokenizer.decode(context)} --> {tokenizer.decode([desired])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，我们主要关心的只有两个向量，输入和输出\n",
    "\n",
    "![1716778596288](image/从零开始构建LLM/1716778596288.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: torch in d:\\python\\python39\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: filelock in d:\\python\\python39\\lib\\site-packages (from torch) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions in d:\\python\\python39\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in d:\\python\\python39\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\python\\python39\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\python\\python39\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in d:\\python\\python39\\lib\\site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\python\\python39\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\python\\python39\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> [tensor([[  40,  367, 2885, 1464],\n",
      "        [2885, 1464, 1807, 3619]]), tensor([[ 367, 2885, 1464, 1807],\n",
      "        [1464, 1807, 3619,  402]])]\n"
     ]
    }
   ],
   "source": [
    "# modify: batch_size, max_length, stride\n",
    "# will get different data\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=2, max_length=4, stride=2, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "data = next(data_iter)\n",
    "print(f\">> {data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 创建token嵌入\n",
    "\n",
    "这一部分将token id转换为嵌入向量\n",
    "\n",
    "![1716778710812](image/从零开始构建LLM/1716778710812.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n",
      ">> tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Simple Example\n",
    "input_ids = torch.tensor([2, 3, 5, 1])\n",
    "\n",
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "print(f\">> {embedding_layer.weight}\")\n",
    "\n",
    "print(f\">> {embedding_layer(input_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 编码位置向量\n",
    "当token id一致时，使用同一个词嵌入会得到相同输出，如下图所示：\n",
    "\n",
    "![1716778847577](image/从零开始构建LLM/1716778847577.png)\n",
    "\n",
    "为了解决这一问题，引入了位置编码，这样可以保证每一个编码是独一无二的\n",
    "\n",
    "![1716778935403](image/从零开始构建LLM/1716778935403.png)\n",
    "\n",
    "最后，所有的数据处理流程如下：\n",
    "\n",
    "![1716778990725](image/从零开始构建LLM/1716778990725.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      ">> Inputs shape: torch.Size([8, 4])\n",
      ">> torch.Size([8, 4, 256])\n",
      ">> pos embeddings's shape: torch.Size([4, 256])\n",
      ">> input embeddings's shape: torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "\n",
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=max_length, stride=max_length, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "\n",
    "inputs, targets = next(data_iter)\n",
    "print(f\">> Token IDs:\\n {inputs}\")\n",
    "print(f\">> Inputs shape: {inputs.shape}\")\n",
    "\n",
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(f\">> {token_embeddings.shape}\")\n",
    "# >> (8, 4, 256) -> 8: batch_size, 4: max_length, 256: output_dim\n",
    "\n",
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(f\">> pos embeddings's shape: {pos_embeddings.shape}\")\n",
    "\n",
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(f\">> input embeddings's shape: {input_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 编码注意力机制\n",
    "\n",
    "主要流程如下：\n",
    "1. 一个简单的自注意力\n",
    "2. LLM中使用的注意力机制\n",
    "3. 因果关系的注意力机制\n",
    "4. 多头注意力机制\n",
    "\n",
    "![1716780422961](image/从零开始构建LLM/1716780422961.png)\n",
    "\n",
    "## 3.1 长时序建模的问题\n",
    "\n",
    "主要问题是上下文丢失。如RNN不能在解码阶段直接从编码器中访问早期的隐藏状态。因此，它只依赖于当前的隐藏状态，它封装了所有相关的信息。这可能会导致上下文的丢失，特别是在依赖关系可能跨越较长距离的复杂句子中。\n",
    "\n",
    "## 3.2 使用注意机制捕获数据依赖关系\n",
    "\n",
    "早期为了解决RNN对于长时序问题，研究者提出以下结构，被成为*Bahdanau attention*，这一机制使得解码阶段能够访问编码早期状态。\n",
    "\n",
    "![1718697183686](image/从零开始构建LLM/1718697183686.png)\n",
    "\n",
    "之后根据*Bahdanau attention*得到启发，提出了早期的*Transformer*结构。\n",
    "\n",
    "![1716877433399](image/从零开始构建LLM/1716877433399.png)\n",
    "\n",
    "## 3.3 自注意输入的不同部分\n",
    "\n",
    "自注意力是LLM中Transformer的基石。\n",
    "在自注意力中，“自我”是指该机制通过关联单个输入序列中的不同位置来计算注意权重的能力。它关注的是本身不同部分的关系和依赖。而传统的注意力机制则是关注两个序列之间的关系\n",
    "\n",
    "### 3.3.1 一个简单的自我注意机制，没有训练权重\n",
    "\n",
    "自注意的目标是为每个输入元素计算一个上下文向量，它结合了来自所有其他输入元素的信息。在自注意力中，我们的目标是为每一个输入元素${x^{(i)}}$计算上下文向量${z^{(i)}}$。一个上下文向量可以被解释为一个丰富的嵌入向量。</br>\n",
    "如下图所示，*Your journey starts with one step*为输入句子，现在关注${x^{(2)}}$与${z^{(2)}}$，${z^{(2)}}$包含了从${x^{(1)}}$到${x^{(T)}}$之间的所有信息。\n",
    "在自注意过程中，上下文向量起着至关重要的作用。它们的目的是通过在序列中合并来自所有其他元素的信息，在输入序列中（如句子）中创建每个元素的丰富表示，如下图所示。\n",
    "\n",
    "![1716879045635](image/从零开始构建LLM/1716879045635.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1716881565809](image/从零开始构建LLM/1716881565809.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "\n",
    "query = inputs[1]  # 2nd input token is the query\n",
    "\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query) # dot product (transpose not necessary here since they are 1-dim vectors)\n",
    "\n",
    "print(f\">> {attn_scores_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 上述操作可以理解为矩阵的乘法 dot product，其中值越大，表示相关性越高\n",
    "\n",
    "紧接着需要对其进行归一化操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> attn_scores for x^2: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      ">> attn_scores's sum for x^2: 1.0000001192092896\n"
     ]
    }
   ],
   "source": [
    "attn_scores_2 = attn_scores_2 / attn_scores_2.sum()\n",
    "print(f\">> attn_scores for x^2: {attn_scores_2}\")\n",
    "print(f\">> attn_scores's sum for x^2: {attn_scores_2.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 在实际中，更多的是使用softmax操作，这一操作在处理极值和梯度时有更好的表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> attn_weights_naive for x^2: tensor([0.1630, 0.1770, 0.1765, 0.1603, 0.1570, 0.1663])\n",
      ">> attn_weights_naive's sum for x^2: 1.0\n",
      "\n",
      ">> attn_weights for x^2: tensor([0.1630, 0.1770, 0.1765, 0.1603, 0.1570, 0.1663])\n",
      ">> attn_weights's sum for x^2: 1.0\n"
     ]
    }
   ],
   "source": [
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "\n",
    "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
    "print(f\">> attn_weights_naive for x^2: {attn_weights_2_naive}\")\n",
    "print(f\">> attn_weights_naive's sum for x^2: {attn_weights_2_naive.sum()}\")\n",
    "print()\n",
    "\n",
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "print(f\">> attn_weights for x^2: {attn_weights_2}\")\n",
    "print(f\">> attn_weights's sum for x^2: {attn_weights_2.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> context_vec: tensor([0.4325, 0.5937, 0.5349])\n"
     ]
    }
   ],
   "source": [
    "# Above All\n",
    "query = inputs[1]\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i] * x_i\n",
    "print(f\">> context_vec: {context_vec_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 为所有输入计算权重\n",
    "\n",
    "![1716945187106](image/从零开始构建LLM/1716945187106.png)\n",
    "\n",
    "计算流程与之前一致\n",
    "\n",
    "![1716945198064](image/从零开始构建LLM/1716945198064.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> attn scores: tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n",
      ">> attn scores: tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n",
      ">> attn weights (softmax): tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "# >> attention scores\n",
    "# method 1\n",
    "attn_scores = torch.empty(6, 6)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    for j, x_j in enumerate(inputs):\n",
    "        attn_scores[i, j] = torch.dot(x_i, x_j)\n",
    "print(f\">> attn scores: {attn_scores}\")\n",
    "\n",
    "# method 2\n",
    "attn_scores = torch.matmul(inputs, inputs.T)\n",
    "print(f\">> attn scores: {attn_scores}\")\n",
    "\n",
    "# >> attention weights (softmax)\n",
    "attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "print(f\">> attn weights (softmax): {attn_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 使用训练权重实现自注意力\n",
    "\n",
    "### 3.4.1 一步一步计算注意力权重\n",
    "\n",
    "这里引入了三个权重${W_q}$, ${W_k}$, ${W_v}$，这三个权重矩阵用于将输入token ${x^i}$ 映射为查询，键， 值向量。\n",
    "\n",
    "![1716947702233](image/从零开始构建LLM/1716947702233.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4676)\n"
     ]
    }
   ],
   "source": [
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2\n",
    "\n",
    "# requires_grad=False to reduce clutter in the outputs for illustration purposes\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "\n",
    "query_2 = torch.matmul(x_2, W_query)\n",
    "key_2 = torch.matmul(x_2, W_key)\n",
    "value_2 = torch.matmul(x_2, W_value)\n",
    "\n",
    "attn_scores_22 = torch.dot(query_2, key_2)\n",
    "print(attn_scores_22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 权重与注意力权重的区别：</br>\n",
    "权重 ${W}$ 是指神经网络中的权重，在训练过程中被优化的部分。<br/>\n",
    "注意权重决定了上下文向量依赖于输入的不同部分的程度。<br/>\n",
    "<br/>\n",
    "总的来说，权重参数是定义神经网络的基础的、可学习的参数，而注意里权重是上下文特定的、动态的值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> keys shape: torch.Size([6, 2])\n",
      ">> values shape: torch.Size([6, 2])\n",
      ">> attn weights for x_2: tensor([0.1545, 0.2136, 0.2123, 0.1320, 0.1419, 0.1457])\n",
      ">> context vector for x_2: tensor([0.3341, 1.0655])\n"
     ]
    }
   ],
   "source": [
    "keys = torch.matmul(inputs, W_key)\n",
    "values = torch.matmul(inputs, W_value)\n",
    "\n",
    "print(f\">> keys shape: {keys.shape}\")\n",
    "print(f\">> values shape: {values.shape}\")\n",
    "\n",
    "attn_scores_2 = torch.matmul(query_2, keys.T)\n",
    "\n",
    "d_k = keys.shape[-1]\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k ** 0.5, dim=-1)\n",
    "print(f\">> attn weights for x_2: {attn_weights_2}\")\n",
    "\n",
    "context_vec_2 = torch.matmul(attn_weights_2, values)\n",
    "print(f\">> context vector for x_2: {context_vec_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 实现一个紧凑的自注意类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "  \n",
    "    def forward(self, x):\n",
    "        keys = torch.matmul(x, self.W_key)\n",
    "        values = torch.matmul(x, self.W_value)\n",
    "        queries = torch.matmul(x, self.W_query)\n",
    "\n",
    "        attn_scores = torch.matmul(queries, keys.T)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        context_vec = torch.matmul(attn_weights, values)\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1717397936262](image/从零开始构建LLM/1717397936262.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> context: tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "print(f\">> context: {sa_v1(inputs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 `nn.Linear` ，除了可以有效计算矩阵外，它还优化了权值初始化方案，有助于模型训练更加稳定和有效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = torch.matmul(queries, keys.T)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        context_vec = torch.matmul(attn_weights, values)\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> context: tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(f\">> context: {sa_v2(inputs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 用因果关系的注意力来隐藏未来的词语\n",
    "\n",
    "![1717401849186](image/从零开始构建LLM/1717401849186.png)\n",
    "\n",
    "### 3.5.1 应用因果注意力掩码\n",
    "\n",
    "![1717401901352](image/从零开始构建LLM/1717401901352.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> attn weights: tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
      "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
      "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      ">> mask:  tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n",
      ">> masked:  tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<MulBackward0>)\n",
      ">> masked norm:  tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa_v2.W_query(inputs)\n",
    "keys = sa_v2.W_key(inputs)\n",
    "\n",
    "attn_scores = torch.matmul(queries, keys.T)\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "print(\">> attn weights:\", attn_weights)\n",
    "\n",
    "context_length = attn_scores.shape[0]\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "print(\">> mask: \", mask_simple)\n",
    "\n",
    "masked_simple = attn_weights * mask_simple\n",
    "print(\">> masked: \", masked_simple)\n",
    "\n",
    "row_sums = torch.sum(masked_simple, dim=-1, keepdim=True)\n",
    "masked_simple_norm = masked_simple / row_sums\n",
    "print(\">> masked norm: \", masked_simple_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **信息泄露**</br>\n",
    "当应用掩码时，由于计算的权重已经进行了softmax，因此会有影响。然而，当我们在mask之后重新调整注意力权重时，本质是在一个更小的子集上重新计算softmax，因此mask位置对于softmax没有贡献。</br>\n",
    "\n",
    "因此可以将流程简化为：\n",
    "\n",
    "![1717402483387](image/从零开始构建LLM/1717402483387.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> mask:  tensor([[0., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      ">> masked:  tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      ">> attn weights:  tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "print(\">> mask: \", mask)\n",
    "\n",
    "masked = torch.masked_fill(attn_scores, mask.bool(), -torch.inf)\n",
    "print(\">> masked: \", masked)\n",
    "\n",
    "attn_weights = torch.softmax(masked / keys.shape[-1] ** 0.5, dim=1)\n",
    "print(\">> attn weights: \", attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 用dropout来掩盖额外的注意权重\n",
    "\n",
    "在transformer架构中，dropout通常用在两个地方：计算注意力分数之后或者应用注意力权重之前\n",
    "\n",
    "![1717558177482](image/从零开始构建LLM/1717558177482.png)\n",
    "\n",
    "需要注意的是，dropout时，会将原数值进行放大，这样能够保证注意力权重的平衡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> dropout rate (0.5):  tensor([[2., 2., 2., 2., 2., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 2., 0.],\n",
      "        [2., 2., 0., 0., 0., 2.],\n",
      "        [2., 0., 0., 0., 0., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.]])\n",
      ">> dropout attn weights:  tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6206, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4921, 0.0000, 0.4638, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3966, 0.3968, 0.3775, 0.3941, 0.0000],\n",
      "        [0.3869, 0.3327, 0.0000, 0.0000, 0.3331, 0.3058]],\n",
      "       grad_fn=<MulBackward0>)\n",
      ">> dropout rate (0.1):  tensor([[1.1111, 1.1111, 1.1111, 1.1111, 1.1111, 1.1111],\n",
      "        [1.1111, 1.1111, 1.1111, 1.1111, 1.1111, 0.0000],\n",
      "        [0.0000, 1.1111, 1.1111, 1.1111, 1.1111, 1.1111],\n",
      "        [1.1111, 1.1111, 1.1111, 0.0000, 1.1111, 1.1111],\n",
      "        [1.1111, 1.1111, 0.0000, 1.1111, 1.1111, 1.1111],\n",
      "        [1.1111, 1.1111, 1.1111, 1.1111, 1.1111, 1.1111]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5)\n",
    "example = torch.ones(6, 6)\n",
    "print(\">> dropout rate (0.5): \", dropout(example))\n",
    "\n",
    "print(\">> dropout attn weights: \", dropout(attn_weights))\n",
    "\n",
    "dropout = torch.nn.Dropout(0.1)\n",
    "example = torch.ones(6, 6)\n",
    "print(\">> dropout rate (0.1): \", dropout(example))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 实现一个紧凑的因果注意力类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = torch.matmul(queries, keys.transpose(1, 2))\n",
    "        attn_scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_vec = torch.matmul(attn_weights, values)\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> batch shape:  torch.Size([2, 6, 3])\n",
      ">> context_vecs:  tensor([[[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]],\n",
      "\n",
      "        [[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>)\n",
      ">> context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(\">> batch shape: \", batch.shape) # 2 inputs with 6 tokens each, and each token has embedding dimension 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "context_length = batch.shape[1]\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "\n",
    "context_vecs = ca(batch)\n",
    "\n",
    "print(\">> context_vecs: \", context_vecs)\n",
    "print(\">> context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 将单个注意力扩展到多头注意力\n",
    "\n",
    "### 3.6.1 将多头注意力扩展到多头注意力\n",
    "\n",
    "![1717567513041](image/从零开始构建LLM/1717567513041.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias) \n",
    "             for _ in range(num_heads)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> context_vecs: tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
      ">> context_vecs.shape: torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "context_length = batch.shape[1] # This is the number of tokens\n",
    "d_in, d_out = 3, 2\n",
    "mha = MultiHeadAttentionWrapper(\n",
    "    d_in, d_out, context_length, 0.0, num_heads=2\n",
    ")\n",
    "\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(\">> context_vecs:\", context_vecs)\n",
    "print(\">> context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2 通过权重分割实现多头注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False) -> None:\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = torch.matmul(queries, keys.transpose(2, 3))\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        context_vec = torch.matmul(attn_weights, values).transpose(1, 2)\n",
    "\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1718186662363](image/从零开始构建LLM/1718186662363.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> context_vecs: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]],\n",
      "\n",
      "        [[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n",
      ">> context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(\">> context_vecs:\", context_vecs)\n",
    "print(\">> context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 实现GPT并生成文本\n",
    "\n",
    "## 4.1 实现一个LLM结构\n",
    "\n",
    "LLM总体框架图如下：\n",
    "1. 词嵌入\n",
    "2. 多头注意力\n",
    "3. 输出层\n",
    "\n",
    "![1718247386638](image/从零开始构建LLM/1718247386638.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 parameter\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 根据下图，一步一步编写GPT模型\n",
    "\n",
    "![1718258629553](image/从零开始构建LLM/1718258629553.png)\n",
    "\n",
    "编写代码如下所示，但是并没有编写归一化与具体的Transformer块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(*[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "  \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "  \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5) -> None:\n",
    "        super().__init__()\n",
    "  \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> GPT数据流\n",
    "\n",
    "![1718262314570](image/从零开始构建LLM/1718262314570.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> batch:  tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      ">> out shape:  torch.Size([2, 4, 50257])\n",
      ">> out:  tensor([[[-1.1947,  0.1392, -0.8616,  ..., -1.4987, -0.0314, -0.4490],\n",
      "         [ 0.0497,  0.3861, -0.3281,  ..., -0.1826,  1.3084,  0.9867],\n",
      "         [ 0.7005,  1.4747, -0.4149,  ...,  1.7756, -0.2280,  0.5384],\n",
      "         [ 0.4885,  1.7545, -0.6707,  ...,  1.1501, -0.1143, -0.9368]],\n",
      "\n",
      "        [[-1.1947,  0.1392, -0.8616,  ..., -1.4987, -0.0314, -0.4490],\n",
      "         [-0.5591,  0.5797, -0.1296,  ...,  0.2691,  0.3151,  1.4046],\n",
      "         [ 0.8524,  1.2833, -0.1786,  ..., -0.1982,  0.1097,  0.2812],\n",
      "         [-0.0190, -0.8277,  0.2299,  ...,  1.7974, -0.1646, -0.1049]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(\">> batch: \", batch)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\">> out shape: \", logits.shape)\n",
    "print(\">> out: \", logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 使用layer normalization进行归一化激活\n",
    "\n",
    "> 由于梯度消失或爆炸等问题，训练多层深度神经网络有时会具有挑战性。这些问题导致了不稳定的训练动态，使网络难以有效地调整其权值，这意味着学习过程很难为神经网络找到一组参数（权值），以最小化损失函数。换句话说，该网络很难学习数据中的潜在模式，其程度将使其能够做出准确的预测或决策。</br>\n",
    "\n",
    "> 层归一化背后的主要思想是调整神经网络层的激活（输出），使其均值为0，方差为1，也称为单位方差。这种调整加速了收敛到有效的权重，并确保了一致、可靠的训练。</br>\n",
    "\n",
    "> **层归一化通常在多头注意模块前后和最终输出层之前应用。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_printoptions(sci_mode=True)  # set float number\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "  \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 使用层归一化实现前向神经网络\n",
    "\n",
    "**GeLU**激活函数\n",
    "\n",
    "在神经网络中，使用最广泛的是ReLU函数，但是在LLM，除了ReLU外，还有两种显著的激活函数：GELU (Gaussian Error Linear Unit) 和 SwiGLU (Sigmoid-Weighted Linear Unit)。GELU和SwiGLU分别是更复杂和光滑的包含高斯单元和s型门控线性单位的激活函数。他们可以表现的更好。\n",
    "\n",
    "$$\n",
    "\\text{GELU}(x) \\approx 0.5 \\cdot x \\cdot \\left(1 + \\tanh\\left[\\sqrt{\\frac{2}{\\pi}} \\cdot \\left(x + 0.044715 \\cdot x^3\\right)\\right]\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * ( 1 + torch.tanh(torch.sqrt(torch.tensor(2 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GELU Test\n",
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], ['GELU', \"ReLU\"])):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 在此基础上实现一个前馈网络，这个前馈网络至关重要，主要解决非线性问题，并且可以探索更丰富的空间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> ffn out size:  torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = ffn(x)\n",
    "print(\">> ffn out size: \", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 增加短连接\n",
    "\n",
    "short connection通过跳过一个或多个层来创建一个梯度通过网络的更短路径，这是通过将一个层的输出添加到后面一个层的输出来实现的。这就是为什么这些连接也被称为跳过连接。在训练过程中，它们在保持梯度的流动方面起着至关重要的作用。\n",
    "\n",
    "![1718273582034](image/从零开始构建LLM/1718273582034.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut) -> None:\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU()),\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(x)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "model_without_shorcut = ExampleDeepNeuralNetwork(layer_sizes, False)\n",
    "\n",
    "def print_gradients(model, x):\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\">> {name} has gradient mean of {param.grad.abs()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> layers.0.0.weight has gradient mean of tensor([[0.0018, 0.0000, 0.0018],\n",
      "        [0.0010, 0.0000, 0.0010],\n",
      "        [0.0065, 0.0000, 0.0065]])\n",
      ">> layers.1.0.weight has gradient mean of tensor([[6.3482e-07, 3.8762e-07, 7.6243e-06],\n",
      "        [1.5987e-04, 9.7618e-05, 1.9201e-03],\n",
      "        [8.4790e-05, 5.1773e-05, 1.0183e-03]])\n",
      ">> layers.2.0.weight has gradient mean of tensor([[0.0039, 0.0031, 0.0015],\n",
      "        [0.0041, 0.0033, 0.0015],\n",
      "        [0.0050, 0.0040, 0.0019]])\n",
      ">> layers.3.0.weight has gradient mean of tensor([[0.0491, 0.0031, 0.0283],\n",
      "        [0.0257, 0.0016, 0.0148],\n",
      "        [0.0465, 0.0029, 0.0268]])\n",
      ">> layers.4.0.weight has gradient mean of tensor([[0.0417, 0.0856, 0.0110]])\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shorcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> layers.0.0.weight has gradient mean of tensor([[3.2044e-06, 0.0000e+00, 3.2044e-06],\n",
      "        [1.8830e-03, 0.0000e+00, 1.8830e-03],\n",
      "        [3.0898e-03, 0.0000e+00, 3.0898e-03]])\n",
      ">> layers.1.0.weight has gradient mean of tensor([[1.5119e-04, 1.8919e-05, 1.4878e-04],\n",
      "        [8.6263e-04, 1.0795e-04, 8.4891e-04],\n",
      "        [2.0144e-04, 2.5207e-05, 1.9824e-04]])\n",
      ">> layers.2.0.weight has gradient mean of tensor([[2.1789e-04, 6.5373e-06, 2.5559e-04],\n",
      "        [1.2170e-03, 3.6514e-05, 1.4276e-03],\n",
      "        [4.6673e-05, 1.4003e-06, 5.4749e-05]])\n",
      ">> layers.3.0.weight has gradient mean of tensor([[1.8056e-04, 2.5326e-05, 2.2459e-04],\n",
      "        [3.3904e-03, 4.7555e-04, 4.2170e-03],\n",
      "        [1.9221e-03, 2.6960e-04, 2.3907e-03]])\n",
      ">> layers.4.0.weight has gradient mean of tensor([[0.0184, 0.0108, 0.0193]])\n"
     ]
    }
   ],
   "source": [
    "model_without_shorcut = ExampleDeepNeuralNetwork(layer_sizes, True)\n",
    "print_gradients(model_without_shorcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 连接注意力层和线性层\n",
    "\n",
    "**transformer block的说明**\n",
    "\n",
    "![1718347509428](image/从零开始构建LLM/1718347509428.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg) -> None:\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(d_in=cfg[\"emb_dim\"], \n",
    "                                      d_out=cfg[\"emb_dim\"],\n",
    "                                      context_length=cfg[\"context_length\"], \n",
    "                                      num_heads=cfg[\"n_heads\"],\n",
    "                                      dropout=cfg[\"drop_rate\"],\n",
    "                                      qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_resid = nn.Dropout(cfg[\"drop_rate\"])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_resid(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_resid(x)\n",
    "        x = x + shortcut\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 编码GPT模型\n",
    "\n",
    "![1718352064601](image/从零开始构建LLM/1718352064601.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> input batch:  tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      ">> output shape:  torch.Size([2, 4, 50257])\n",
      ">> out:  tensor([[[ 0.2159,  1.7803, -1.3144,  ...,  0.1518,  0.3433, -0.2426],\n",
      "         [-0.4640,  0.0124, -0.0818,  ...,  0.1752,  0.8148,  0.2054],\n",
      "         [-0.3823,  0.1988,  0.2054,  ...,  0.0659, -0.1415,  0.1057],\n",
      "         [-0.1542,  0.7591, -0.2797,  ..., -0.2908,  0.6896, -0.1746]],\n",
      "\n",
      "        [[-0.2024,  1.6316, -0.9047,  ...,  0.1310,  0.5152, -0.3395],\n",
      "         [-0.0648,  0.8608, -0.4911,  ...,  0.5268, -0.0134,  0.3010],\n",
      "         [-0.1856, -0.6939,  0.0868,  ...,  0.5741, -0.0706,  0.2637],\n",
      "         [-0.0827, -0.1011,  0.4543,  ...,  0.1231, -0.1420,  0.0325]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\">> input batch: \", batch)\n",
    "print(\">> output shape: \", out.shape)\n",
    "print(\">> out: \", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> total number of parameters: 163009536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\">> total number of parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 之前提到代码参数工1.24亿，但是为何这里输出为1.63亿呢？<br/>\n",
    "其原因是在原始的GPT-2体系结构中使用了一个称为**权重绑定**的概念，这意味着原始的GPT-2体系结构在其输出层中重用了来自标记嵌入层的权重。为了理解这意味着什么，来看看我们之前通过GPTModel在模型上初始化的令牌嵌入层和线性输出层的形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Token embedding layer shape: torch.Size([50257, 768])\n",
      ">> Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(f\">> Token embedding layer shape: {model.tok_emb.weight.shape}\")\n",
    "print(f\">> Output layer shape: {model.out_head.weight.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 由于字典表的大小为50257，这导致嵌入层非常大。且输出层重用了嵌入层的权重，因此应减去这一部分的参数。\n",
    "\n",
    "> 在一般情况下，不是用权重绑定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Number of trainable parameters considering weight tying: 124412160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\">> Number of trainable parameters considering weight tying: {total_params_gpt2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 生成文本\n",
    "\n",
    "![1718358855510](image/从零开始构建LLM/1718358855510.png)\n",
    "\n",
    "![1718358887750](image/从零开始构建LLM/1718358887750.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=-1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> encoded: [15496, 11, 314, 716]\n",
      ">> encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\">> encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\">> encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Output: tensor([[15496,    11,   314,   716, 17480, 23268,  2497, 19749,  1333, 15262]])\n",
      ">> Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor,\n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\">> Output:\", out)\n",
    "print(\">> Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Generated text:  Hello, I amINGTON vow saw bourgeois triBay\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(\">> Generated text: \", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 在未标记的数据上进行训练\n",
    "\n",
    "## 5.1 评估生成文本模型\n",
    "\n",
    "![1718851702204](image/从零开始构建LLM/1718851702204.png)\n",
    "\n",
    "5.1.1 使用GPT模型生成文本\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256, #A\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1, #B\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与之前的进行对比，context_length减少到256（之前为1024），这一改变减少了计算需求，使得能够在桌面版计算机上运行。\n",
    "在之后的训练中，将其更新回1024，以便于加载预训练模型。\n",
    "\n",
    "---\n",
    "\n",
    "三步生成文本的过程：\n",
    "1. tokenizer将输入文本转换为一系列token IDs\n",
    "2. 模型将token IDs转换为对应的logits，logits表示每个token在字典中可能的分布状况\n",
    "3. 将logits转换为token IDs，tokenizer再进行解码，生成文本\n",
    "\n",
    "![1718853446792](image/从零开始构建LLM/1718853446792.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> encoded: tensor([[6109, 3626, 6100,  345]])\n",
      ">> decoded_text: Every effort moves you Ya Primary Haleifacts rallying racing acronym employedliners quasi\n"
     ]
    }
   ],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    decoded = tokenizer.decode(token_ids.squeeze(0).tolist())\n",
    "    return decoded\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "encoded = text_to_token_ids(start_context, tokenizer)\n",
    "print(\">> encoded:\", encoded)\n",
    "\n",
    "token_ids = generate_text_simple(model=model, idx=encoded, max_new_tokens=10, context_size=GPT_CONFIG_124M['context_length'])\n",
    "\n",
    "decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "print(\">> decoded_text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 计算文本生成的损失\n",
    "\n",
    "![1718854323771](image/从零开始构建LLM/1718854323771.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> probas:  tensor([[[2.8377e-05, 7.2349e-06, 1.2548e-05,  ..., 5.9388e-05,\n",
      "          1.3404e-05, 1.2288e-05],\n",
      "         [1.3495e-05, 1.4862e-05, 2.8429e-05,  ..., 1.8806e-05,\n",
      "          1.5693e-05, 4.4732e-05],\n",
      "         [1.2664e-05, 1.3142e-05, 1.0387e-05,  ..., 4.5830e-05,\n",
      "          2.7469e-05, 6.0023e-06]],\n",
      "\n",
      "        [[1.3310e-05, 1.8276e-05, 2.6471e-05,  ..., 4.4993e-05,\n",
      "          1.4153e-05, 2.1337e-05],\n",
      "         [3.9846e-05, 1.4927e-05, 2.0788e-05,  ..., 1.3040e-05,\n",
      "          1.7489e-05, 4.1804e-05],\n",
      "         [1.8740e-05, 1.7283e-05, 1.5547e-05,  ..., 3.6920e-05,\n",
      "          2.2174e-05, 8.8161e-06]]])\n",
      ">> token_ids:  tensor([[[26729],\n",
      "         [ 6858],\n",
      "         [40186]],\n",
      "\n",
      "        [[11205],\n",
      "         [25483],\n",
      "         [38800]]])\n",
      ">> target batch:   effort moves you\n",
      ">> predicted batch:   Theme Andrew sluggish\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(\">> probas: \", probas)\n",
    "\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\">> token_ids: \", token_ids)\n",
    "\n",
    "print(\">> target batch: \", token_ids_to_text(targets[0], tokenizer))\n",
    "print(\">> predicted batch: \", token_ids_to_text(token_ids[0].flatten(), tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于还未被训练，因此产生的为随机文本。\n",
    "训练过程是不断减小目标与预测值之间的“距离”。\n",
    "\n",
    "![1718868480909](image/从零开始构建LLM/1718868480909.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Text 1: tensor([1.2227e-05, 1.6803e-05, 1.2385e-05])\n",
      ">> Text 2: tensor([1.2182e-05, 1.3089e-05, 4.1397e-06])\n",
      ">> log probas:  tensor([-11.3119, -10.9940, -11.2990, -11.3156, -11.2437, -12.3949])\n",
      ">> avg log probas:  tensor(-11.4265)\n",
      ">> neg avg log probas:  tensor(11.4265)\n"
     ]
    }
   ],
   "source": [
    "# 2-3\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\">> Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\">> Text 2:\", target_probas_2)\n",
    "\n",
    "# 4\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(\">> log probas: \", log_probas)\n",
    "\n",
    "# 5\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(\">> avg log probas: \", avg_log_probas)\n",
    "\n",
    "# 6\n",
    "neg_avg_log_probas = -avg_log_probas\n",
    "print(\">> neg avg log probas: \", neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交叉熵 Cross Entropy Loss， 是用来衡量两个概率分布之间的差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Logits shape: torch.Size([2, 3, 50257])\n",
      ">> Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\">> Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\">> Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在进行交叉熵之前，需要检查向量维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Flattened logits: torch.Size([6, 50257])\n",
      ">> Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\">> Flattened logits:\", logits_flat.shape)\n",
    "print(\">> Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loss:  tensor(11.4265)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(\">> Loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 困惑度</br>\n",
    "\n",
    "困惑度也是评价语言模型好坏的指标。它可以提供一种更可解释的方法来理解模型在预测序列中的下一个标记时的不确定性。</br>\n",
    "困惑度衡量了模型预测的概率分布与数据集中单词的实际分布的匹配程度。与损失相似，较低的困惑度表明模型的预测更接近实际分布。</br>\n",
    "困惑度的可解释性在于它表示模型在每一步中都不确定的有效词汇表大小。</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(91720.6797)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 计算训练和验证损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Characters: 20479\n",
      ">> Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "text_data = raw_text\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\">> Characters:\", total_characters)\n",
    "print(\">> Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1718868663879](image/从零开始构建LLM/1718868663879.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(len(text_data) * train_ratio)\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloader_v1(train_data, \n",
    "                                    batch_size=2, \n",
    "                                    max_length=GPT_CONFIG_124M['context_length'], \n",
    "                                    stride=GPT_CONFIG_124M['context_length'], \n",
    "                                    drop_last=True, \n",
    "                                    shuffle=True)\n",
    "val_loader = create_dataloader_v1(val_data, \n",
    "                                  batch_size=2, \n",
    "                                  max_length=GPT_CONFIG_124M['context_length'], \n",
    "                                  stride=GPT_CONFIG_124M['context_length'], \n",
    "                                  drop_last=False, \n",
    "                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(len(data_loader), num_batches)\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Train loss: 10.994715372721354\n",
      ">> Val loss: 11.020210266113281\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "train_loss = calc_loss_loader(train_loader, model, device)\n",
    "print(f\">> Train loss: {train_loss}\")\n",
    "\n",
    "val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(f\">> Val loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 训练一个LLM\n",
    "\n",
    "![1718875144870](image/从零开始构建LLM/1718875144870.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluete_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    excoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model, excoded, 50 , context_size)\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(f\">> {start_context} --> {decoded_text}\")\n",
    "    model.train()\n",
    "\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_token_seen = [], [], []\n",
    "    token_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            token_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluete_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_token_seen.append(token_seen)\n",
    "                print(f\">> Epoch {epoch + 1}, step {global_step: 06d}: train loss {train_loss:.4f}, val loss {val_loss:.4f}\")\n",
    "    \n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_token_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 1, step  00000: train loss 9.9413, val loss 10.0458\n",
      ">> Epoch 1, step  00005: train loss 8.1316, val loss 8.3626\n",
      ">> Every effort moves you --> Every effort moves you,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 1  # Change Here\n",
    "train_losses, val_losses, track_token_seen = train_model_simple(model, train_loader, val_loader, optimizer, device,\n",
    "                                                               num_epochs, 5, 5, \"Every effort moves you\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "# load model\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    ax.plot(epochs_seen, train_losses, label=\"train\")\n",
    "    ax.plot(epochs_seen, val_losses, linestyle='-.', label=\"val\")\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend()\n",
    "\n",
    "    ax1 = ax.twiny()\n",
    "    ax1.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax1.set_xlabel(\"Tokens Seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epoch_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epoch_tensor, track_token_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 控制随机性的解码策略\n",
    "\n",
    "主要介绍两个函数：`temperature scaling` 和 `top-k sampling`\n",
    "\n",
    "首先需要将模型转到cpu上，因为较小的模型在推理时不需要gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> generated text:  Every effort moves you,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(model=model,\n",
    "                                 idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "                                 max_new_tokens=25,\n",
    "                                 context_size=GPT_CONFIG_124M[\"context_length\"])\n",
    "print(\">> generated text: \", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Temperature scaling\n",
    "\n",
    "一种添加概率选择过程到向下一代标记生成任务的技术。</br>\n",
    "在前面的章节中，`generate_text_simple` 函数使用 `torch.argmax` 取最大概率，这一行为被称为贪婪解码 greedy decode。</br>\n",
    "为了使输出更加多样化，我们使用 **`从概率分布进行采样`** 来替换掉`argmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> inverse vocab (argmax):  forward\n",
      ">> inverse vocab (probability distribution):  toward\n"
     ]
    }
   ],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "print(\">> inverse vocab (argmax): \", inverse_vocab[next_token_id])\n",
    "\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(\">> inverse vocab (probability distribution): \", inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印出来的结果都是forward。`multinomial`是根据概率分数的比例来对下一个标记进行采样。因此在这里，forward仍然是最大的概率分数。在执行多次后我们统计一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> sampled 46 times: closer\n",
      ">> sampled 0 times: every\n",
      ">> sampled 0 times: effort\n",
      ">> sampled 578 times: forward\n",
      ">> sampled 4 times: inches\n",
      ">> sampled 0 times: moves\n",
      ">> sampled 0 times: pizza\n",
      ">> sampled 368 times: toward\n",
      ">> sampled 4 times: you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for _ in range(1000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))  \n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\">> sampled {freq} times: {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，与argmax不同，大部分情况下，会选择`forward`但是也有其他的可能。</br>\n",
    "我们可以通过一个叫做`temperature scaling`的概念来控制分布和选择过程。`temperature scaling`只是一个大于0的树。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temperature大于1会得到更加均匀的分布，小于1则会得到更尖锐的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, t) for t in temperatures]\n",
    "\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, T in enumerate(temperatures):\n",
    "    ax.bar(x + i * bar_width, scaled_probas[i], width=bar_width, label=f\"T={T}\")\n",
    "\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(list(vocab.keys()), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Top-k sampling\n",
    "\n",
    "上一节的温度采样和温度尺度可能会生成错误的结果，为了使结果更加准确，我们采用Tok-k采样。当结合概率采样和温度尺度时，可以提高文本生成结果。\n",
    "\n",
    "在top-k抽样中，我们可以将采样的标记限制在最可能的top-k标记中，并通过屏蔽其概率分数，从选择过程中排除所有其他标记，如下图所示。\n",
    "\n",
    "![1718954311719](image/从零开始构建LLM/1718954311719.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> top logits:  tensor([6.7500, 6.2800, 4.5100])\n",
      ">> top positions:  tensor([3, 7, 0])\n",
      ">> new logits:  tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n",
      ">> topk probas:  tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "# >> top k and position\n",
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\">> top logits: \", top_logits)\n",
    "print(\">> top positions: \", top_pos)\n",
    "\n",
    "# >> mask logits\n",
    "new_logits = torch.where(condition=next_token_logits < top_logits[-1],\n",
    "                         input=torch.tensor(float('-inf')),\n",
    "                         other=next_token_logits)\n",
    "print(\">> new logits: \", new_logits)\n",
    "\n",
    "# >> topk probas\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(\">> topk probas: \", topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此引入温度尺度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 修改文本生成函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        # >> context\n",
    "        idx_cond = idx if idx.size(0) <= context_size else idx[-context_size:]\n",
    "\n",
    "        # >> logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]  # last\n",
    "\n",
    "        # >> topk\n",
    "        if top_k is not None:\n",
    "            top_logits, top_pos = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]  # min value\n",
    "            # mask logits\n",
    "            logits = torch.where(condition=logits < min_val, input=torch.tensor(float('-inf')), other=logits)\n",
    "        \n",
    "        # >> temperature\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> generated text:  Every effort moves you.,\n",
      "\n",
      "\n",
      " the to.\"\n",
      " in it,. to,\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(model=model, idx=text_to_token_ids(\"Every effort moves you\", tokenizer), \n",
    "                     max_new_tokens=15, \n",
    "                     context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "                     top_k=25,\n",
    "                     temperature=1.4)\n",
    "print(\">> generated text: \", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 在PyTorch中加载和保存模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> model.eval()作用：**禁用dropout**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdamW使用历史数据来动态调整每个模型参数的学习速率。如果没有它，优化器就会重置，模型可能会学习次优，甚至不能正确收敛，这意味着它将失去生成连贯文本的能力。使用torch.save，我们可以保存模型和优化器的state_dict的内容如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model and optimizer\n",
    "torch.save({\n",
    "    \"model_states_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "}, \"model_and_optimizer.pth\")\n",
    "\n",
    "# load model and optimizer\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_states_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 从OpenAI中加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt_download.py\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def download_and_load_gpt2(model_size, models_dir):\n",
    "    # Validate model size\n",
    "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
    "    if model_size not in allowed_sizes:\n",
    "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
    "\n",
    "    # Define paths\n",
    "    model_dir = os.path.join(models_dir, model_size)\n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "    filenames = [\n",
    "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
    "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
    "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
    "    ]\n",
    "\n",
    "    # Download files\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    for filename in filenames:\n",
    "        file_url = os.path.join(base_url, model_size, filename)\n",
    "        file_path = os.path.join(model_dir, filename)\n",
    "        download_file(file_url, file_path)\n",
    "\n",
    "    # Load settings and params\n",
    "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
    "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "\n",
    "    return settings, params\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def download_file(url, destination):\n",
    "    # Send a GET request to download the file in streaming mode\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Get the total file size from headers, defaulting to 0 if not present\n",
    "    file_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "    # Check if file exists and has the same size\n",
    "    if os.path.exists(destination):\n",
    "        file_size_local = os.path.getsize(destination)\n",
    "        if file_size == file_size_local:\n",
    "            print(f\"File already exists and is up-to-date: {destination}\")\n",
    "            return\n",
    "\n",
    "    # Define the block size for reading the file\n",
    "    block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "    # Initialize the progress bar with total file size\n",
    "    progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
    "    with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "        # Open the destination file in binary write mode\n",
    "        with open(destination, \"wb\") as file:\n",
    "            # Iterate over the file data in chunks\n",
    "            for chunk in response.iter_content(block_size):\n",
    "                progress_bar.update(len(chunk))  # Update progress bar\n",
    "                file.write(chunk)  # Write the chunk to the file\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def download_file(url, destination):\n",
    "    # Send a GET request to download the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        # Get the total file size from headers, defaulting to 0 if not present\n",
    "        file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "\n",
    "        # Check if file exists and has the same size\n",
    "        if os.path.exists(destination):\n",
    "            file_size_local = os.path.getsize(destination)\n",
    "            if file_size == file_size_local:\n",
    "                print(f\"File already exists and is up-to-date: {destination}\")\n",
    "                return\n",
    "\n",
    "        # Define the block size for reading the file\n",
    "        block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "        # Initialize the progress bar with total file size\n",
    "        progress_bar_description = os.path.basename(url)  # Extract filename from URL\n",
    "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "            # Open the destination file in binary write mode\n",
    "            with open(destination, \"wb\") as file:\n",
    "                # Read the file in chunks and write to destination\n",
    "                while True:\n",
    "                    chunk = response.read(block_size)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    file.write(chunk)\n",
    "                    progress_bar.update(len(chunk))  # Update progress bar\n",
    "\n",
    "\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: models\\124M\\checkpoint\n",
      "File already exists and is up-to-date: models\\124M\\encoder.json\n",
      "File already exists and is up-to-date: models\\124M\\hparams.json\n",
      "File already exists and is up-to-date: models\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: models\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: models\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: models\\124M\\vocab.bpe\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb0 in position 16: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m settings, params \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_and_load_gpt2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m124M\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msettings: \u001b[39m\u001b[38;5;124m\"\u001b[39m, settings)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams: \u001b[39m\u001b[38;5;124m\"\u001b[39m, params)\n",
      "Cell \u001b[1;32mIn[107], line 38\u001b[0m, in \u001b[0;36mdownload_and_load_gpt2\u001b[1;34m(model_size, models_dir)\u001b[0m\n\u001b[0;32m     36\u001b[0m tf_ckpt_path \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mlatest_checkpoint(model_dir)\n\u001b[0;32m     37\u001b[0m settings \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhparams.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m---> 38\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mload_gpt2_params_from_tf_ckpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_ckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m settings, params\n",
      "Cell \u001b[1;32mIn[107], line 108\u001b[0m, in \u001b[0;36mload_gpt2_params_from_tf_ckpt\u001b[1;34m(ckpt_path, settings)\u001b[0m\n\u001b[0;32m    105\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblocks\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{} \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layer\u001b[39m\u001b[38;5;124m\"\u001b[39m])]}\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Iterate over each variable in the checkpoint\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# Load the variable and remove singleton dimensions\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     variable_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mload_variable(ckpt_path, name))\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# Process the variable name to extract relevant parts\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\training\\checkpoint_utils.py:141\u001b[0m, in \u001b[0;36mlist_variables\u001b[1;34m(ckpt_dir_or_file)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.list_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlist_variables\u001b[39m(ckpt_dir_or_file):\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Lists the checkpoint keys and shapes of variables in a checkpoint.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m  Checkpoint keys are paths in a checkpoint graph.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m    List of tuples `(key, shape)`.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m   reader \u001b[38;5;241m=\u001b[39m \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_dir_or_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m   variable_map \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mget_variable_to_shape_map()\n\u001b[0;32m    143\u001b[0m   names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(variable_map\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\training\\checkpoint_utils.py:76\u001b[0m, in \u001b[0;36mload_checkpoint\u001b[1;34m(ckpt_dir_or_file)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.load_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_checkpoint\u001b[39m(ckpt_dir_or_file):\n\u001b[0;32m     48\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns `CheckpointReader` for checkpoint found in `ckpt_dir_or_file`.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m  If `ckpt_dir_or_file` resolves to a directory with multiple checkpoints,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m      checkpoints.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m   filename \u001b[38;5;241m=\u001b[39m \u001b[43m_get_checkpoint_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_dir_or_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m file or checkpoints in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgiven directory \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m ckpt_dir_or_file)\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\training\\checkpoint_utils.py:479\u001b[0m, in \u001b[0;36m_get_checkpoint_filename\u001b[1;34m(ckpt_dir_or_file)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ckpt_dir_or_file, os\u001b[38;5;241m.\u001b[39mPathLike):\n\u001b[0;32m    478\u001b[0m   ckpt_dir_or_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(ckpt_dir_or_file)\n\u001b[1;32m--> 479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIsDirectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_dir_or_file\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    480\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m checkpoint_management\u001b[38;5;241m.\u001b[39mlatest_checkpoint(ckpt_dir_or_file)\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ckpt_dir_or_file\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:689\u001b[0m, in \u001b[0;36mis_directory\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgfile.IsDirectory\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_directory\u001b[39m(dirname):\n\u001b[0;32m    681\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns whether the path is a directory or not.\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \n\u001b[0;32m    683\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;124;03m    True, if the path is a directory; False otherwise\u001b[39;00m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 689\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mis_directory_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:703\u001b[0m, in \u001b[0;36mis_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns whether the path is a directory or not.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \n\u001b[0;32m    696\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;124;03m  True, if the path is a directory; False otherwise\u001b[39;00m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 703\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pywrap_file_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIsDirectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError:\n\u001b[0;32m    705\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb0 in position 16: invalid start byte"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(\"124M\", \"models\")\n",
    "print(\"settings: \", settings)\n",
    "print(\"params: \", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 上述代码出错，没有找到好的解决方案，因此使用其他方法来解决<br/>\n",
    "`pip install transformers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like gpt2 is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py:491\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    490\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[1;32m--> 491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py:1092\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1092\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connection.py:642\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    634\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    635\u001b[0m         (\n\u001b[0;32m    636\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSystem time is way off (before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRECENT_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). This will probably \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    639\u001b[0m         SystemTimeWarning,\n\u001b[0;32m    640\u001b[0m     )\n\u001b[1;32m--> 642\u001b[0m sock_and_verified \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39msocket\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connection.py:783\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[1;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[0;32m    781\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m normalized\n\u001b[1;32m--> 783\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\util\\ssl_.py:469\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 469\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\util\\ssl_.py:513\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m--> 513\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\ssl.py:501\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    496\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    498\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\ssl.py:1041\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1041\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\ssl.py:1310\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1309\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1310\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] 远程主机强迫关闭了一个现有的连接。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    842\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 844\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    847\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\util\\retry.py:470\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\util\\util.py:38\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py:491\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    490\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[1;32m--> 491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py:1092\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1092\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connection.py:642\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    634\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    635\u001b[0m         (\n\u001b[0;32m    636\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSystem time is way off (before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRECENT_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). This will probably \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    639\u001b[0m         SystemTimeWarning,\n\u001b[0;32m    640\u001b[0m     )\n\u001b[1;32m--> 642\u001b[0m sock_and_verified \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39msocket\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\connection.py:783\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[1;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[0;32m    781\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m normalized\n\u001b[1;32m--> 783\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\util\\ssl_.py:469\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 469\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\urllib3\\util\\ssl_.py:513\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m--> 513\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\ssl.py:501\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    496\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    498\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\ssl.py:1041\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1041\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\ssl.py:1310\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1309\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1310\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:1238\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1238\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:1631\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent)\u001b[0m\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1631\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1639\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1640\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:385\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 385\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m    386\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    387\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    388\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    390\u001b[0m     )\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:408\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[1;32m--> 408\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    409\u001b[0m hf_raise_for_status(response)\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:67\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[1;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\requests\\adapters.py:501\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mConnectionError\u001b[0m: (ProtocolError('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None)), '(Request ID: d8006615-0d23-4919-a39e-a95a4d3fe7f7)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mLocalEntryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\transformers\\utils\\hub.py:389\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 389\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:1371\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[0;32m   1369\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1370\u001b[0m         \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n\u001b[1;32m-> 1371\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[0;32m   1372\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error happened while trying to locate the file on the Hub and we cannot find the requested files\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1373\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the local cache. Please check your connection and try again or make sure your Internet connection\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1374\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is on.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1375\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhead_call_error\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;66;03m# From now on, etag and commit_hash are not None.\u001b[39;00m\n",
      "\u001b[1;31mLocalEntryNotFoundError\u001b[0m: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline, set_seed\n\u001b[1;32m----> 2\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m set_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      4\u001b[0m generator(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, I\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm a language model,\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, num_return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\transformers\\pipelines\\__init__.py:782\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    779\u001b[0m                 adapter_config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m    780\u001b[0m                 model \u001b[38;5;241m=\u001b[39m adapter_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_model_name_or_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 782\u001b[0m     config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    783\u001b[0m         model, _from_pipeline\u001b[38;5;241m=\u001b[39mtask, code_revision\u001b[38;5;241m=\u001b[39mcode_revision, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs\n\u001b[0;32m    784\u001b[0m     )\n\u001b[0;32m    785\u001b[0m     hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39m_commit_hash\n\u001b[0;32m    787\u001b[0m custom_tasks \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1082\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1080\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1082\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m PretrainedConfig\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1084\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\transformers\\configuration_utils.py:644\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    642\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    643\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 644\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[0;32m    646\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\transformers\\configuration_utils.py:699\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    695\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME)\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[1;32m--> 699\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Python39\\lib\\site-packages\\transformers\\utils\\hub.py:429\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_missing_entries \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_connection_errors:\n\u001b[0;32m    428\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    430\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt connect to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to load this file, couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find it in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    431\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m cached files and it looks like \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not the path to a directory containing a file named\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    432\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCheckout your internet connection or see how to run the library in offline mode at\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    433\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    434\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_missing_entries:\n",
      "\u001b[1;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like gpt2 is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 由于网络限制，也报错了\n",
    "\n",
    "移步[./download_huggingface_model.ipynb](./download_huggingface_model.ipynb)下载模型，这个下载方式有很多，可以通过git/网站直接下载都可以，本人通过阅读(官方连接)[https://huggingface.co/docs/transformers/installation#offline-mode]之后进行下载的。<br/>\n",
    "这一部分就不用跟着书看了，只能自己摸索，大致流程也是跟着书一起的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> config: GPT2Config {\n",
      "  \"_name_or_path\": \"./gpt2/config.json\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.36.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Model, GPT2Tokenizer, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"./gpt2/config.json\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"./gpt2/\")\n",
    "model = GPT2Model.from_pretrained(\"./gpt2/\")\n",
    "\n",
    "print(\">> config:\", config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> tokenizer: GPT2Tokenizer(name_or_path='./gpt2/', vocab_size=50257, model_max_length=1024, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\">> tokenizer:\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> model: GPT2Model(\n",
      "  (wte): Embedding(50257, 768)\n",
      "  (wpe): Embedding(1024, 768)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (h): ModuleList(\n",
      "    (0-11): 12 x GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (act): NewGELUActivation()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\">> model:\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1719213912457](image/从零开始构建LLM/1719213912457.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453],\n",
       "        [ 0.0403, -0.0486,  0.0462,  ...,  0.0861,  0.0025,  0.0432],\n",
       "        [-0.1275,  0.0479,  0.1841,  ...,  0.0899, -0.1297, -0.0879],\n",
       "        ...,\n",
       "        [-0.0445, -0.0548,  0.0123,  ...,  0.1044,  0.0978, -0.0695],\n",
       "        [ 0.1860,  0.0167,  0.0461,  ..., -0.0963,  0.0785, -0.0225],\n",
       "        [ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model's block weight\n",
    "model.wte.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来将模型参数加载至我们的GPTModel中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()\n",
    "gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the OpenAI weights to the corresponding weight tensors in our GPTModel instance\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights_into_gpt(gpt, model):\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, model.wte.weight)\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, model.wpe.weight)\n",
    "\n",
    "    for b in range(len(model.h)):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            model.h[b].attn.c_attn.weight, 3, axis=-1\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].att.W_query.weight =  assign(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight =  assign(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            model.h[b].attn.c_attn.bias, 3, axis=-1\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(gpt.trf_blocks[b].att.W_query.bias, q_b.T)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(gpt.trf_blocks[b].att.W_key.bias, k_b.T)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(gpt.trf_blocks[b].att.W_value.bias, v_b.T)\n",
    "\n",
    "        \n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(gpt.trf_blocks[b].att.out_proj.weight, model.h[b].attn.c_proj.weight)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(gpt.trf_blocks[b].att.out_proj.bias, model.h[b].attn.c_proj.bias)\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layer[0].weight = assign(gpt.trf_blocks[b].ff.layer[0].weight, model.h[b].mlp.c_fc.weight.T)\n",
    "        gpt.trf_blocks[b].ff.layer[0].bias = assign(gpt.trf_blocks[b].ff.layer[0].bias, model.h[b].mlp.c_fc.bias)\n",
    "        gpt.trf_blocks[b].ff.layer[2].weight = assign(gpt.trf_blocks[b].ff.layer[2].weight, model.h[b].mlp.c_proj.weight.T)\n",
    "        gpt.trf_blocks[b].ff.layer[2].bias = assign(gpt.trf_blocks[b].ff.layer[2].bias, model.h[b].mlp.c_proj.bias)\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(gpt.trf_blocks[b].norm1.scale, model.h[b].ln_1.weight)\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(gpt.trf_blocks[b].norm1.shift, model.h[b].ln_1.bias)\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(gpt.trf_blocks[b].norm2.scale, model.h[b].ln_2.weight)\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(gpt.trf_blocks[b].norm2.shift, model.h[b].ln_2.bias)\n",
    "    \n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, model.ln_f.weight)\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, model.ln_f.bias)\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, model.wte.weight)\n",
    "    return gpt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuexiaolei\\AppData\\Local\\Temp\\ipykernel_22208\\1292868022.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.nn.Parameter(torch.tensor(right))\n"
     ]
    }
   ],
   "source": [
    "gpt = load_weights_into_gpt(gpt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'allowed_special': {'<|endoftext|>'}} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> generated text By MyGPT: \n",
      " hello, my name is_- that to is the. to and is not ( was can in a a \" is can\n",
      "., the,\n"
     ]
    }
   ],
   "source": [
    "tokenids = generate(gpt, idx=text_to_token_ids(\"hello, my name is\", tokenizer).to(device),\n",
    "         max_new_tokens=25, context_size=NEW_CONFIG['context_length'],\n",
    "         top_k=50, temperature=1.5)\n",
    "print(\">> generated text By MyGPT: \\n\", token_ids_to_text(tokenids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a timeageageageageageageageageageageageageageageageageageageageageageageageageage\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"./gpt2/\")\n",
    "model = GPT2Model.from_pretrained(\"./gpt2/\")\n",
    "\n",
    "input_text = \"Once upon a time\"\n",
    "\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "def generate_by_gpt2(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        # >> context\n",
    "        idx_cond = idx if idx.size(0) <= context_size else idx[-context_size:]\n",
    "\n",
    "        # >> logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits.last_hidden_state[:, -1, :]  # last\n",
    "\n",
    "        # >> topk\n",
    "        if top_k is not None:\n",
    "            top_logits, top_pos = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]  # min value\n",
    "            # mask logits\n",
    "            logits = torch.where(condition=logits < min_val, input=torch.tensor(float('-inf')), other=logits)\n",
    "        \n",
    "        # >> temperature\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n",
    "\n",
    "model.eval()\n",
    "\n",
    "generated_ids = generate_by_gpt2(model, idx=input_ids,\n",
    "         max_new_tokens=25, context_size=NEW_CONFIG['context_length'],\n",
    "         top_k=50, temperature=1.5)\n",
    "# 解码生成的文本\n",
    "generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> GPT2Model 与 GPTLMHeadModel不一样， GPT2Model主要用于获取模型的隐藏状态，而GPTLMHeadModel集成了GPT2Model并添加了语言建模的头部，使其能够进行文本生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> generated text: \n",
      " Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('./gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('./gpt2')\n",
    "\n",
    "text = \"Once upon a time\"\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "\n",
    "output = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\">> generated text: \\n\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
